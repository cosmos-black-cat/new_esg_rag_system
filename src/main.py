#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESGå ±å‘Šæ›¸æå–å™¨ - ä¸»ç¨‹å¼ v2.0 å¢å¼·ç‰ˆ
æ”¯æŒæ–°é—œéµå­—é…ç½®ã€æé«˜æº–ç¢ºåº¦ã€Wordæ–‡æª”è¼¸å‡º
"""

import os
import sys
import argparse
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, List, Tuple

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# é…ç½®è¼‰å…¥
try:
    from config import (
        GOOGLE_API_KEY, DATA_PATH, RESULTS_PATH, 
        MAX_DOCS_PER_RUN, ENABLE_LLM_ENHANCEMENT
    )
    CONFIG_LOADED = True
    print("âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿config.pyæ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")
    CONFIG_LOADED = False

# =============================================================================
# ESGå ±å‘Šæ›¸æ¨™æº–åŒ–å‘½ååŠŸèƒ½ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================================================

class ESGFileNormalizer:
    """ESGå ±å‘Šæ›¸æª”æ¡ˆåç¨±æ¨™æº–åŒ–è™•ç†å™¨"""
    
    def __init__(self):
        self.standard_format = "{company_name}_{report_year}_ESGå ±å‘Šæ›¸.pdf"
        self.backup_suffix = "_backup"
        
    def scan_pdf_files(self) -> List[Path]:
        """æƒææ‰€æœ‰PDFæ–‡ä»¶"""
        if not CONFIG_LOADED:
            return []
            
        data_dir = Path(DATA_PATH)
        if not data_dir.exists():
            print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {DATA_PATH}")
            return []
            
        pdf_files = list(data_dir.glob("*.pdf"))
        return pdf_files
    
    def analyze_filename(self, pdf_path: Path) -> Dict[str, str]:
        """åˆ†ææª”æ¡ˆåç¨±ï¼Œæå–å…¬å¸å’Œå¹´åº¦ä¿¡æ¯"""
        try:
            from preprocess import DocumentMetadataExtractor
            
            # ä½¿ç”¨ç¾æœ‰çš„å…ƒæ•¸æ“šæå–å™¨
            extractor = DocumentMetadataExtractor()
            metadata = extractor.extract_metadata(str(pdf_path))
            
            # å¾æª”åä¹Ÿå˜—è©¦æå–ä¿¡æ¯ä½œç‚ºå‚™ç”¨
            filename_metadata = extractor._extract_from_filename(pdf_path.name)
            
            # é¸æ“‡æœ€ä½³çµæœ
            company_name = metadata.get('company_name', '')
            report_year = metadata.get('report_year', '')
            
            # å¦‚æœå¾å…§å®¹æå–å¤±æ•—ï¼Œä½¿ç”¨æª”åæå–çš„çµæœ
            if not company_name or company_name == "æœªçŸ¥å…¬å¸":
                company_name = filename_metadata.get('company_name', pdf_path.stem)
            
            if not report_year or report_year == "æœªçŸ¥å¹´åº¦":
                report_year = filename_metadata.get('report_year', 'æœªçŸ¥å¹´åº¦')
            
            # æ¸…ç†å…¬å¸åç¨±ï¼ˆç§»é™¤ä¸é©åˆæª”åçš„å­—ç¬¦ï¼‰
            company_name = self._clean_filename_part(company_name)
            
            return {
                'original_name': pdf_path.name,
                'company_name': company_name,
                'report_year': report_year,
                'confidence': 'high' if metadata.get('company_name') != "æœªçŸ¥å…¬å¸" else 'medium'
            }
            
        except Exception as e:
            print(f"âš ï¸ åˆ†ææª”æ¡ˆå¤±æ•— {pdf_path.name}: {e}")
            return {
                'original_name': pdf_path.name,
                'company_name': pdf_path.stem,
                'report_year': 'æœªçŸ¥å¹´åº¦',
                'confidence': 'low'
            }
    
    def _clean_filename_part(self, text: str) -> str:
        """æ¸…ç†æª”åéƒ¨åˆ†ï¼Œç§»é™¤ä¸é©åˆæª”åçš„å­—ç¬¦"""
        if not text:
            return "æœªçŸ¥"
        
        # ç§»é™¤æˆ–æ›¿æ›ä¸é©åˆæª”åçš„å­—ç¬¦
        import re
        
        # æ›¿æ›å¸¸è¦‹çš„å•é¡Œå­—ç¬¦
        replacements = {
            '/': '_',
            '\\': '_',
            ':': '_',
            '*': '_',
            '?': '_',
            '"': '_',
            '<': '_',
            '>': '_',
            '|': '_',
            '\n': '_',
            '\r': '_',
            '\t': '_'
        }
        
        cleaned = text
        for old, new in replacements.items():
            cleaned = cleaned.replace(old, new)
        
        # ç§»é™¤å¤šé¤˜ç©ºç™½å’Œä¸‹åŠƒç·š
        cleaned = re.sub(r'[_\s]+', '_', cleaned)
        cleaned = cleaned.strip('_')
        
        # é™åˆ¶é•·åº¦
        if len(cleaned) > 30:
            cleaned = cleaned[:30]
        
        return cleaned if cleaned else "æœªçŸ¥"
    
    def generate_standard_name(self, analysis: Dict[str, str]) -> str:
        """ç”Ÿæˆæ¨™æº–åŒ–æª”å"""
        company = analysis['company_name']
        year = analysis['report_year']
        
        # ç¢ºä¿å¹´åº¦æ ¼å¼æ­£ç¢º
        if year and year != "æœªçŸ¥å¹´åº¦":
            # åªä¿ç•™æ•¸å­—
            import re
            year_match = re.search(r'(20[12][0-9])', year)
            if year_match:
                year = year_match.group(1)
        
        return self.standard_format.format(
            company_name=company,
            report_year=year
        )
    
    def preview_renaming(self, pdf_files: List[Path]) -> List[Dict]:
        """é è¦½é‡å‘½åè¨ˆåŠƒ"""
        print("ğŸ” åˆ†æPDFæª”æ¡ˆåç¨±...")
        
        renaming_plan = []
        
        for pdf_file in pdf_files:
            print(f"   åˆ†æ: {pdf_file.name}")
            
            analysis = self.analyze_filename(pdf_file)
            new_name = self.generate_standard_name(analysis)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
            needs_rename = pdf_file.name != new_name
            
            # æª¢æŸ¥æ–°æª”åæ˜¯å¦æœƒè¡çª
            new_path = pdf_file.parent / new_name
            has_conflict = new_path.exists() and new_path != pdf_file
            
            plan_item = {
                'original_path': pdf_file,
                'original_name': pdf_file.name,
                'new_name': new_name,
                'new_path': new_path,
                'needs_rename': needs_rename,
                'has_conflict': has_conflict,
                'analysis': analysis
            }
            
            renaming_plan.append(plan_item)
        
        return renaming_plan
    
    def execute_renaming(self, renaming_plan: List[Dict], create_backup: bool = True) -> bool:
        """åŸ·è¡Œé‡å‘½åæ“ä½œ"""
        print("ğŸ”„ é–‹å§‹åŸ·è¡Œæª”æ¡ˆé‡å‘½å...")
        
        success_count = 0
        total_count = len([item for item in renaming_plan if item['needs_rename']])
        
        if total_count == 0:
            print("â„¹ï¸  æ‰€æœ‰æª”æ¡ˆåç¨±å·²ç¬¦åˆæ¨™æº–ï¼Œç„¡éœ€é‡å‘½å")
            return True
        
        # å‰µå»ºå‚™ä»½ç›®éŒ„ï¼ˆå¦‚æœéœ€è¦ï¼‰
        backup_dir = None
        if create_backup:
            backup_dir = Path(DATA_PATH) / f"å‚™ä»½_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            backup_dir.mkdir(exist_ok=True)
            print(f"ğŸ“ å‰µå»ºå‚™ä»½ç›®éŒ„: {backup_dir.name}")
        
        for item in renaming_plan:
            if not item['needs_rename']:
                continue
                
            try:
                original_path = item['original_path']
                new_path = item['new_path']
                
                # è™•ç†æª”åè¡çª
                if item['has_conflict']:
                    print(f"âš ï¸ æª”åè¡çª: {item['new_name']}")
                    # æ·»åŠ æ•¸å­—å¾Œç¶´
                    counter = 1
                    base_name = new_path.stem
                    while new_path.exists():
                        new_name_with_counter = f"{base_name}_{counter}.pdf"
                        new_path = new_path.parent / new_name_with_counter
                        counter += 1
                    
                    print(f"   è§£æ±ºè¡çª: ä½¿ç”¨ {new_path.name}")
                    item['new_path'] = new_path
                    item['new_name'] = new_path.name
                
                # å‰µå»ºå‚™ä»½
                if create_backup:
                    backup_path = backup_dir / original_path.name
                    shutil.copy2(original_path, backup_path)
                    print(f"   ğŸ’¾ å‚™ä»½: {original_path.name}")
                
                # åŸ·è¡Œé‡å‘½å
                original_path.rename(new_path)
                success_count += 1
                
                print(f"   âœ… é‡å‘½å: {original_path.name} â†’ {new_path.name}")
                
            except Exception as e:
                print(f"   âŒ é‡å‘½åå¤±æ•— {item['original_name']}: {e}")
                continue
        
        print(f"\nğŸ“Š é‡å‘½åå®Œæˆ: {success_count}/{total_count} å€‹æª”æ¡ˆ")
        
        if create_backup and backup_dir:
            print(f"ğŸ“ å‚™ä»½æª”æ¡ˆå·²ä¿å­˜è‡³: {backup_dir}")
        
        return success_count > 0

def run_filename_standardization() -> Optional[Dict[str, str]]:
    """åŸ·è¡ŒPDFæª”åæ¨™æº–åŒ–"""
    try:
        # ç›´æ¥å¾ preprocess æ¨¡çµ„å°å…¥æ¨™æº–åŒ–å‡½æ•¸
        from preprocess import standardize_pdf_filenames
        
        print("\nğŸ“ é–‹å§‹PDFæª”åæ¨™æº–åŒ–...")
        print("ğŸ¯ ä½¿ç”¨æ™ºèƒ½æª”ååˆ†æ + PDFå…§å®¹æå–é›™é‡ç­–ç•¥")
        print("ğŸ“‹ æ”¯æ´å°ç£ä¸Šå¸‚æ«ƒå…¬å¸ä»£è™Ÿè­˜åˆ¥")
        
        if not CONFIG_LOADED:
            print("âŒ é…ç½®æœªè¼‰å…¥")
            return None
        
        # æª¢æŸ¥æ•¸æ“šç›®éŒ„
        if not os.path.exists(DATA_PATH):
            print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {DATA_PATH}")
            return None
        
        # åŸ·è¡Œæ¨™æº–åŒ–ï¼ˆèª¿ç”¨ preprocess.py çš„å‡½æ•¸ï¼‰
        rename_mapping = standardize_pdf_filenames(DATA_PATH)
        
        if rename_mapping:
            print(f"âœ… æª”åæ¨™æº–åŒ–å®Œæˆï¼Œå…±é‡å‘½å {len(rename_mapping)} å€‹æª”æ¡ˆ")
            return rename_mapping
        else:
            print("â„¹ï¸  æ‰€æœ‰æª”æ¡ˆå·²ç¬¦åˆæ¨™æº–æ ¼å¼ï¼Œç„¡éœ€é‡å‘½å")
            return {}
            
    except ImportError as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥æ¨™æº–åŒ–æ¨¡çµ„: {e}")
        print("ğŸ’¡ è«‹ç¢ºä¿ preprocess.py æ–‡ä»¶å­˜åœ¨ä¸”åŒ…å« standardize_pdf_filenames å‡½æ•¸")
        return None
    except Exception as e:
        print(f"âŒ æª”åæ¨™æº–åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

# =============================================================================
# ç³»çµ±æª¢æŸ¥å‡½æ•¸ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================================================

def check_environment():
    """æª¢æŸ¥ç³»çµ±ç’°å¢ƒ"""
    print("ğŸ”§ æª¢æŸ¥ç³»çµ±ç’°å¢ƒ...")
    
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æ–‡ä»¶è¼‰å…¥å¤±æ•—")
        return False
    
    if not GOOGLE_API_KEY:
        print("âŒ Google API Keyæœªè¨­ç½®")
        print("è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®GOOGLE_API_KEY=your_api_key")
        return False
    
    print(f"âœ… Google API Key: {GOOGLE_API_KEY[:10]}...")
    
    # æª¢æŸ¥ä¸¦å‰µå»ºç›®éŒ„
    directories = {
        "æ•¸æ“šç›®éŒ„": DATA_PATH,
        "çµæœç›®éŒ„": RESULTS_PATH
    }
    
    for name, path in directories.items():
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)
            print(f"âœ… å‰µå»º{name}: {path}")
        else:
            print(f"âœ… {name}: {path}")
    
    return True

def find_pdf_files() -> tuple[bool, list]:
    """æ‰¾åˆ°æ‰€æœ‰PDFæ–‡ä»¶"""
    if not CONFIG_LOADED:
        return False, []
    
    try:
        data_dir = Path(DATA_PATH)
        pdf_files = list(data_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"âŒ åœ¨ {DATA_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
            print("è«‹å°‡ESGå ±å‘ŠPDFæ–‡ä»¶æ”¾å…¥dataç›®éŒ„ä¸­")
            return False, []
        
        print(f"âœ… æ‰¾åˆ° {len(pdf_files)} å€‹PDFæ–‡ä»¶:")
        for pdf_file in pdf_files:
            print(f"   - {pdf_file.name}")
        
        return True, pdf_files
        
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾PDFæ–‡ä»¶å¤±æ•—: {e}")
        return False, []

# =============================================================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ - æ›´æ–°æ”¯æŒå¢å¼·ç‰ˆæå–å™¨
# =============================================================================

def run_preprocessing(pdf_files: list = None, force: bool = False) -> Optional[Dict]:
    """åŸ·è¡Œé è™•ç†"""
    try:
        from preprocess import preprocess_multiple_documents, DocumentMetadataExtractor
        
        if pdf_files is None:
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                return None
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é è™•ç†
        if not force:
            from config import VECTOR_DB_PATH
            existing_dbs = []
            for pdf_file in pdf_files:
                pdf_name = pdf_file.stem
                db_path = os.path.join(
                    os.path.dirname(VECTOR_DB_PATH),
                    f"esg_db_{pdf_name}"
                )
                if os.path.exists(db_path):
                    existing_dbs.append(pdf_file.name)
            
            if existing_dbs and len(existing_dbs) == len(pdf_files):
                print("â„¹ï¸  æ‰€æœ‰æ–‡ä»¶çš„å‘é‡è³‡æ–™åº«å·²å­˜åœ¨ï¼Œè·³éé è™•ç†")
                print("   å¦‚éœ€é‡æ–°è™•ç†ï¼Œè«‹ä½¿ç”¨ --force åƒæ•¸")
                
                # è¿”å›ç¾æœ‰çš„æ–‡æª”ä¿¡æ¯
                metadata_extractor = DocumentMetadataExtractor()
                docs_info = {}
                for pdf_file in pdf_files:
                    pdf_name = pdf_file.stem
                    metadata = metadata_extractor.extract_metadata(str(pdf_file))
                    docs_info[str(pdf_file)] = {
                        'db_path': os.path.join(os.path.dirname(VECTOR_DB_PATH), f"esg_db_{pdf_name}"),
                        'metadata': metadata,
                        'pdf_name': pdf_name
                    }
                return docs_info
        
        print("ğŸ”„ é–‹å§‹é è™•ç†...")
        print("   é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å¾…...")
        
        # åŸ·è¡Œé è™•ç†
        results = preprocess_multiple_documents([str(f) for f in pdf_files])
        
        if results:
            print("âœ… é è™•ç†å®Œæˆ")
            return results
        else:
            print("âŒ é è™•ç†å¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ é è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_extraction(docs_info: Dict, max_docs: int = None) -> Optional[Dict]:
    """åŸ·è¡ŒESGæ•¸æ“šæå– - å¢å¼·ç‰ˆ"""
    try:
        # ä½¿ç”¨å¢å¼·ç‰ˆæå–å™¨
        from esg_extractor import EnhancedESGExtractor, DocumentInfo
        
        print("ğŸ“Š åˆå§‹åŒ–å¢å¼·ç‰ˆESGå ±å‘Šæ›¸æå–å™¨...")
        print("ğŸ”§ æ–°åŠŸèƒ½ï¼šæ“´å±•é—œéµå­—ã€æé«˜æº–ç¢ºåº¦ã€Wordæ–‡æª”è¼¸å‡º")
        extractor = EnhancedESGExtractor(enable_llm=ENABLE_LLM_ENHANCEMENT)
        
        # ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§æ–‡æª”æ•¸
        if max_docs is None:
            max_docs = MAX_DOCS_PER_RUN
        
        # è½‰æ›æ–‡æª”ä¿¡æ¯æ ¼å¼
        document_infos = {}
        for pdf_path, info in docs_info.items():
            metadata = info['metadata']
            document_infos[pdf_path] = DocumentInfo(
                company_name=metadata['company_name'],
                report_year=metadata['report_year'],
                pdf_name=info['pdf_name'],
                db_path=info['db_path']
            )
        
        print("ğŸ“Š é–‹å§‹å¢å¼·ç‰ˆESGæ•¸æ“šæå–...")
        print(f"   æœ€å¤§è™•ç†æ–‡æª”æ•¸: {max_docs}")
        print(f"   LLMå¢å¼·: {'å•Ÿç”¨' if ENABLE_LLM_ENHANCEMENT else 'åœç”¨'}")
        print(f"   è¼¸å‡ºæ ¼å¼: Excel + Wordæ–‡æª”")
        
        results = extractor.process_multiple_documents(document_infos, max_docs)
        
        return results
        
    except Exception as e:
        print(f"âŒ ESGæ•¸æ“šæå–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_consolidation() -> Optional[str]:
    """åŸ·è¡Œå½™æ•´åŠŸèƒ½"""
    try:
        from consolidator import consolidate_esg_results
        
        print("\nğŸ“Š é–‹å§‹å½™æ•´ESGçµæœ...")
        print("âš ï¸ æ³¨æ„ï¼šæª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå°‡è¢«è‡ªå‹•æ’é™¤")
        
        if not CONFIG_LOADED:
            print("âŒ é…ç½®æœªè¼‰å…¥")
            return None
        
        # æª¢æŸ¥çµæœç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(RESULTS_PATH):
            print(f"âŒ çµæœç›®éŒ„ä¸å­˜åœ¨: {RESULTS_PATH}")
            return None
        
        # æª¢æŸ¥æ˜¯å¦æœ‰Excelæª”æ¡ˆ
        results_dir = Path(RESULTS_PATH)
        excel_files = list(results_dir.glob("*.xlsx"))
        
        if not excel_files:
            print(f"âŒ åœ¨ {RESULTS_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°Excelçµæœæª”æ¡ˆ")
            print("è«‹å…ˆåŸ·è¡Œè³‡æ–™æå–åŠŸèƒ½ç”Ÿæˆçµæœæª”æ¡ˆ")
            return None
        
        # çµ±è¨ˆæœ‰æ•ˆæª”æ¡ˆï¼ˆæ’é™¤'ç„¡æå–'ï¼‰
        valid_files = [f for f in excel_files if "ç„¡æå–" not in f.name]
        excluded_files = [f for f in excel_files if "ç„¡æå–" in f.name]
        
        print(f"ğŸ“„ æƒæåˆ° {len(excel_files)} å€‹Excelæª”æ¡ˆ")
        if excluded_files:
            print(f"âŠ— å°‡æ’é™¤ {len(excluded_files)} å€‹'ç„¡æå–'æª”æ¡ˆ")
        
        print(f"âœ… å°‡è™•ç† {len(valid_files)} å€‹æœ‰æ•ˆæª”æ¡ˆ")
        
        if not valid_files:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„æª”æ¡ˆå¯å½™æ•´ï¼ˆæ‰€æœ‰æª”æ¡ˆéƒ½åŒ…å«'ç„¡æå–'ï¼‰")
            return None
        
        # åŸ·è¡Œå½™æ•´
        result_path = consolidate_esg_results(RESULTS_PATH)
        
        if result_path:
            print(f"âœ… å½™æ•´å®Œæˆ: {Path(result_path).name}")
            return result_path
        else:
            print("âŒ å½™æ•´å¤±æ•—")
            return None
            
    except ImportError as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥å½™æ•´æ¨¡çµ„: {e}")
        print("è«‹ç¢ºä¿consolidator.pyæ–‡ä»¶å­˜åœ¨")
        return None
    except Exception as e:
        print(f"âŒ å½™æ•´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

# =============================================================================
# é¡¯ç¤ºå‡½æ•¸ - æ›´æ–°æ”¯æŒWordæ–‡æª”
# =============================================================================

def show_latest_results():
    """é¡¯ç¤ºæœ€æ–°çµæœ"""
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æœªè¼‰å…¥")
        return
    
    try:
        import pandas as pd
        
        results_dir = Path(RESULTS_PATH)
        if not results_dir.exists():
            print("âŒ çµæœç›®éŒ„ä¸å­˜åœ¨")
            return
        
        # æŸ¥æ‰¾Excelå’ŒWordæ–‡ä»¶
        excel_files = list(results_dir.glob("*.xlsx"))
        word_files = list(results_dir.glob("*.docx"))
        
        if not excel_files and not word_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ°çµæœæ–‡ä»¶")
            return
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
        excel_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        word_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        print("ğŸ“Š æœ€æ–°çµæœæ–‡ä»¶")
        print("=" * 50)
        
        # åˆ†é¡é¡¯ç¤ºExcelæ–‡ä»¶
        consolidated_files = [f for f in excel_files if "å½™æ•´å ±å‘Š" in f.name]
        extraction_files = [f for f in excel_files if "å½™æ•´å ±å‘Š" not in f.name]
        
        if consolidated_files:
            print("\nğŸ“Š å½™æ•´å ±å‘Š:")
            for file in consolidated_files[:3]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        if extraction_files:
            print("\nğŸ“Š æå–çµæœ (Excel):")
            for file in extraction_files[:5]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        # é¡¯ç¤ºWordæ–‡ä»¶
        if word_files:
            print("\nğŸ“ æå–çµ±æ•´ (Word):")
            for file in word_files[:5]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        # çµ±è¨ˆä¿¡æ¯
        print(f"\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:")
        print(f"   ç¸½Excelæª”æ¡ˆ: {len(excel_files)}")
        print(f"   ç¸½Wordæª”æ¡ˆ: {len(word_files)}")
        print(f"   å½™æ•´å ±å‘Š: {len(consolidated_files)} å€‹")
        print(f"   æå–çµæœ: {len(extraction_files)} å€‹")
            
    except Exception as e:
        print(f"âŒ æŸ¥çœ‹çµæœå¤±æ•—: {e}")

def show_system_info():
    """é¡¯ç¤ºç³»çµ±é…ç½®ä¿¡æ¯"""
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æœªè¼‰å…¥")
        return
    
    from config import (
        GEMINI_MODEL, EMBEDDING_MODEL, VECTOR_DB_PATH,
        CHUNK_SIZE, SEARCH_K, CONFIDENCE_THRESHOLD
    )
    
    print("ğŸ“‹ ESGå ±å‘Šæ›¸æå–å™¨é…ç½®ä¿¡æ¯ v2.0")
    print("=" * 50)
    print(f"ğŸ¤– Geminiæ¨¡å‹: {GEMINI_MODEL}")
    print(f"ğŸ§  Embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
    print(f"ğŸ“š å‘é‡è³‡æ–™åº«: {VECTOR_DB_PATH}")
    print(f"ğŸ“ æ•¸æ“šç›®éŒ„: {DATA_PATH}")
    print(f"ğŸ“Š çµæœç›®éŒ„: {RESULTS_PATH}")
    print(f"ğŸ”¢ æ–‡æœ¬å¡Šå¤§å°: {CHUNK_SIZE}")
    print(f"ğŸ” æœç´¢æ•¸é‡: {SEARCH_K}")
    print(f"ğŸ“ ä¿¡å¿ƒåˆ†æ•¸é–¾å€¼: {CONFIDENCE_THRESHOLD}")
    print(f"ğŸ“„ æœ€å¤§è™•ç†æ–‡æª”æ•¸: {MAX_DOCS_PER_RUN}")
    print(f"ğŸ¤– LLMå¢å¼·: {'å•Ÿç”¨' if ENABLE_LLM_ENHANCEMENT else 'åœç”¨'}")
    print(f"ğŸ“ Wordæ–‡æª”è¼¸å‡º: âœ… æ”¯æŒ")
    print(f"ğŸ”§ æå–å™¨ç‰ˆæœ¬: v2.0 å¢å¼·ç‰ˆ")

def show_usage_guide():
    """é¡¯ç¤ºä½¿ç”¨èªªæ˜"""
    print("\nğŸ“š ESGå ±å‘Šæ›¸æå–å™¨ä½¿ç”¨èªªæ˜ v2.0")
    print("=" * 60)
    print("""
ğŸ¯ ä¸»è¦åŠŸèƒ½ï¼š
   â€¢ è‡ªå‹•æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿå¡‘è† å’Œæ°¸çºŒææ–™ç›¸é—œæ•¸æ“š
   â€¢ æ”¯æ´æ‰¹é‡è™•ç†å¤šä»½å ±å‘Š
   â€¢ æ™ºèƒ½è­˜åˆ¥é—œéµæ•¸å€¼å’Œç›¸é—œæè¿°
   â€¢ å¤šå…¬å¸å¤šå¹´åº¦çµæœå½™æ•´åˆ†æ
   â€¢ PDFæª”æ¡ˆåç¨±æ¨™æº–åŒ–ç®¡ç†
   â€¢ ğŸ†• Wordæ–‡æª”çµ±æ•´å ±å‘Šè¼¸å‡º

ğŸ”§ v2.0 æ–°åŠŸèƒ½ï¼š
   â€¢ æ“´å±•é—œéµå­—é…ç½®ï¼ˆææ–™å¾ªç’°ç‡ã€å†ç”Ÿèƒ½æºä½¿ç”¨ç‡ç­‰ï¼‰
   â€¢ æé«˜æå–æº–ç¢ºåº¦ï¼ˆæ›´åš´æ ¼çš„ç›¸é—œæ€§æª¢æŸ¥ï¼‰
   â€¢ Wordæ–‡æª”è¼¸å‡ºï¼ˆæ ¼å¼åŒ–çš„æå–çµ±æ•´å ±å‘Šï¼‰
   â€¢ å¢å¼·çš„æ’é™¤è¦å‰‡ï¼ˆé¿å…ç„¡é—œå…§å®¹ï¼‰

ğŸ“‹ è™•ç†æµç¨‹ï¼š
   1. å°‡ESGå ±å‘ŠPDFæ”¾å…¥dataç›®éŒ„
   2. ï¼ˆæ¨è–¦ï¼‰åŸ·è¡ŒåŠŸèƒ½2æ¨™æº–åŒ–æª”æ¡ˆåç¨±
   3. åŸ·è¡ŒåŠŸèƒ½1é€²è¡Œæ•¸æ“šæå–
   4. åŸ·è¡ŒåŠŸèƒ½4ç”Ÿæˆå½™æ•´å ±å‘Š
   5. æŸ¥çœ‹resultsç›®éŒ„ä¸­çš„çµæœæª”æ¡ˆ

ğŸ”§ æ ¸å¿ƒç‰¹è‰²ï¼š
   â€¢ ç²¾ç¢ºçš„é—œéµå­—èˆ‡æ•¸å€¼é—œè¯æ€§åˆ†æ
   â€¢ æ™ºèƒ½æ’é™¤ç„¡é—œå…§å®¹ï¼ˆè·æ¥­ç½å®³ã€è³½äº‹ã€è¨“ç·´ç­‰ï¼‰
   â€¢ é é¢ç´šå»é‡ç¢ºä¿è³‡æ–™å“è³ª
   â€¢ è‡ªå‹•å…¬å¸åç¨±å’Œè‚¡ç¥¨ä»£è™Ÿè­˜åˆ¥
   â€¢ å°ˆæ¥­çš„Excelå ±è¡¨è¼¸å‡º
   â€¢ ğŸ†• æ ¼å¼åŒ–çš„Wordæ–‡æª”çµ±æ•´å ±å‘Š

ğŸ“Š è¼¸å‡ºå…§å®¹ï¼š
   â€¢ å†ç”Ÿå¡‘è† ç›¸é—œæ•¸å€¼æ•¸æ“š
   â€¢ å›æ”¶ç”¢èƒ½å’Œä½¿ç”¨é‡
   â€¢ ç’°ä¿æ•ˆç›Šå’Œæ¸›ç¢³è³‡æ–™
   â€¢ å¾ªç’°ç¶“æ¿Ÿç›¸é—œæŒ‡æ¨™
   â€¢ ğŸ†• ææ–™å¾ªç’°ç‡ã€å†ç”Ÿèƒ½æºä½¿ç”¨ç‡ç­‰æ–°æŒ‡æ¨™

ğŸ“ è¼¸å‡ºæ ¼å¼ï¼š
   â€¢ Excel: è‚¡ç¥¨ä»£è™Ÿ_å…¬å¸ç°¡ç¨±_å¹´åº¦.xlsx
   â€¢ Word: è‚¡ç¥¨ä»£è™Ÿ_å…¬å¸ç°¡ç¨±_å¹´åº¦_æå–çµ±æ•´.docx

âš¡ å¿«é€Ÿé–‹å§‹ï¼š
   1. è¨­ç½®API Keyï¼ˆåœ¨.envæª”æ¡ˆä¸­ï¼‰
   2. å®‰è£ä¾è³´ï¼špip install -r requirements.txt
   3. æ”¾å…¥PDFæª”æ¡ˆåˆ°dataç›®éŒ„
   4. åŸ·è¡ŒåŠŸèƒ½2æ¨™æº–åŒ–æª”æ¡ˆåç¨±ï¼ˆå»ºè­°ï¼‰
   5. åŸ·è¡ŒåŠŸèƒ½1æå–æ•¸æ“š
   6. åŸ·è¡ŒåŠŸèƒ½4å½™æ•´çµæœ
""")

# =============================================================================
# æ›´æ–°å¾Œçš„ç”¨æˆ¶ç•Œé¢
# =============================================================================

def interactive_menu():
    """äº’å‹•å¼ä¸»é¸å–®"""
    while True:
        print("\n" + "ğŸ“Š" * 20)
        print("ğŸ¢ ESGå ±å‘Šæ›¸æå–å™¨ v1.0")
        print("å°ˆæ¥­æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿå¡‘è† ç›¸é—œæ•¸æ“š")
        print("ğŸ“Š" * 20)
        print("1. ğŸ“Š åŸ·è¡ŒESGæ•¸æ“šæå–ï¼ˆä¸»è¦åŠŸèƒ½ï¼‰")
        print("2. ğŸ“ æ¨™æº–åŒ–PDFæª”å")  # é‡å‘½ååŠŸèƒ½
        print("3. ğŸ”„ é‡æ–°é è™•ç†PDF")
        print("4. ğŸ”— å½™æ•´å¤šå…¬å¸çµæœ")
        print("5. ğŸ“‹ æŸ¥çœ‹æœ€æ–°çµæœ")
        print("6. âš™ï¸  é¡¯ç¤ºç³»çµ±ä¿¡æ¯")
        print("7. ğŸ’¡ ä½¿ç”¨èªªæ˜")
        print("8. ğŸšª é€€å‡ºç³»çµ±")
        
        choice = input("\nè«‹é¸æ“‡åŠŸèƒ½ (1-8): ").strip()
        
        if choice == "1":
            # åŸ·è¡ŒESGæ•¸æ“šæå– (ä¿æŒåŸæœ‰é‚è¼¯)
            print("\nğŸ“Š æº–å‚™åŸ·è¡ŒESGæ•¸æ“šæå–...")
            
            if not check_environment():
                print("âŒ ç’°å¢ƒæª¢æŸ¥å¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæå–")
                continue
            
            # æ‰¾åˆ°æ‰€æœ‰PDFæ–‡ä»¶
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                continue
            
            # é è™•ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
            docs_info = run_preprocessing(pdf_files)
            if not docs_info:
                print("âŒ é è™•ç†å¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæå–")
                continue
            
            # åŸ·è¡Œæå–
            results = run_extraction(docs_info)
            if results:
                print(f"\nğŸ‰ æå–å®Œæˆï¼ç”Ÿæˆäº† {len(results)} å€‹çµæœæ–‡ä»¶")
                for pdf_path, (extractions, summary, excel_path) in results.items():
                    print(f"ğŸ“Š {summary.company_name} - {summary.report_year}: {len(extractions)} å€‹çµæœ")
                    print(f"   æ–‡ä»¶: {Path(excel_path).name}")
                
                # è©¢å•æ˜¯å¦ç«‹å³å½™æ•´
                if len(results) > 1:
                    consolidate_now = input("\næ˜¯å¦ç«‹å³åŸ·è¡Œå½™æ•´åŠŸèƒ½ï¼Ÿ(y/n): ").strip().lower()
                    if consolidate_now == 'y':
                        result_path = run_consolidation()
                        if result_path:
                            print(f"ğŸ”— å½™æ•´å®Œæˆ: {Path(result_path).name}")
        
        elif choice == "2":
            # ğŸ“ æ¨™æº–åŒ–PDFæª”å (æ–°çš„é‡å‘½ååŠŸèƒ½)
            print("\nğŸ“ æº–å‚™æ¨™æº–åŒ–PDFæª”å...")
            
            rename_mapping = run_filename_standardization()
            if rename_mapping is not None:
                if rename_mapping:
                    print(f"\nğŸ‰ æª”åæ¨™æº–åŒ–å®Œæˆï¼")
                    print(f"ğŸ“ é‡å‘½åäº† {len(rename_mapping)} å€‹æª”æ¡ˆ")
                    
                    # è©¢å•æ˜¯å¦ç«‹å³åŸ·è¡Œæ•¸æ“šæå–
                    extract_now = input("\næª”åå·²æ¨™æº–åŒ–ï¼Œæ˜¯å¦ç«‹å³åŸ·è¡Œæ•¸æ“šæå–ï¼Ÿ(y/n): ").strip().lower()
                    if extract_now == 'y':
                        # é‡æ–°æ‰¾åˆ°PDFæ–‡ä»¶ï¼ˆå› ç‚ºæª”åå·²æ”¹è®Šï¼‰
                        has_pdfs, pdf_files = find_pdf_files()
                        if has_pdfs:
                            docs_info = run_preprocessing(pdf_files)
                            if docs_info:
                                results = run_extraction(docs_info)
                                if results:
                                    print(f"ğŸ‰ æå–å®Œæˆï¼ç”Ÿæˆäº† {len(results)} å€‹çµæœæ–‡ä»¶")
                else:
                    print("âœ… æ‰€æœ‰æª”æ¡ˆæª”åå·²ç¬¦åˆæ¨™æº–")
        
        elif choice == "3":
            # é‡æ–°é è™•ç†PDF (åŸä¾†çš„é¸é …2)
            print("\nğŸ”„ é‡æ–°é è™•ç†PDF...")
            
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                continue
            
            print(f"å°‡è™•ç† {len(pdf_files)} å€‹PDFæ–‡ä»¶ï¼š")
            for pdf_file in pdf_files:
                print(f"  - {pdf_file.name}")
            
            confirm = input("é€™å°‡é‡æ–°å»ºç«‹æ‰€æœ‰å‘é‡è³‡æ–™åº«ï¼Œç¢ºå®šç¹¼çºŒï¼Ÿ(y/n): ").strip().lower()
            if confirm == 'y':
                docs_info = run_preprocessing(pdf_files, force=True)
                if docs_info:
                    print("âœ… é è™•ç†å®Œæˆï¼Œç¾åœ¨å¯ä»¥åŸ·è¡Œæ•¸æ“šæå–")
            
        elif choice == "4":
            # å½™æ•´å¤šå…¬å¸çµæœ (åŸä¾†çš„é¸é …3)
            print("\nğŸ”— æº–å‚™å½™æ•´å¤šå…¬å¸çµæœ...")
            
            result_path = run_consolidation()
            if result_path:
                print(f"\nğŸ‰ å½™æ•´åŠŸèƒ½åŸ·è¡Œå®Œæˆï¼")
                print(f"ğŸ“Š å½™æ•´æª”æ¡ˆ: {Path(result_path).name}")
                print(f"ğŸ“ å­˜æ”¾ä½ç½®: {RESULTS_PATH}")
            else:
                print("âŒ å½™æ•´åŠŸèƒ½åŸ·è¡Œå¤±æ•—")
                print("ğŸ’¡ è«‹ç¢ºä¿å·²åŸ·è¡Œéè³‡æ–™æå–åŠŸèƒ½")
            
        elif choice == "5":
            # æŸ¥çœ‹æœ€æ–°çµæœ (åŸä¾†çš„é¸é …4)
            show_latest_results()
            
        elif choice == "6":
            # é¡¯ç¤ºç³»çµ±ä¿¡æ¯ (åŸä¾†çš„é¸é …5)
            show_system_info()
            
        elif choice == "7":
            # ä½¿ç”¨èªªæ˜ (åŸä¾†çš„é¸é …6)
            show_usage_guide()
            
        elif choice == "8":
            # é€€å‡ºç³»çµ± (åŸä¾†çš„é¸é …7)
            print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ESGå ±å‘Šæ›¸æå–å™¨ï¼")
            break
            
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥1-8ä¹‹é–“çš„æ•¸å­—")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ“Š ESGå ±å‘Šæ›¸æå–å™¨ v2.0 å¢å¼·ç‰ˆ")
    print("å°ˆæ¥­æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿå¡‘è† å’Œæ°¸çºŒææ–™ç›¸é—œæ•¸æ“š")
    print("ğŸ†• æ–°åŠŸèƒ½ï¼šæ“´å±•é—œéµå­—ã€æé«˜æº–ç¢ºåº¦ã€Wordæ–‡æª”è¼¸å‡º")
    print("=" * 70)
    
    # æ ¹æ“šå‘½ä»¤è¡Œåƒæ•¸æ±ºå®šé‹è¡Œæ¨¡å¼
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        command_line_mode()
    else:
        # äº’å‹•æ¨¡å¼
        try:
            interactive_menu()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·ï¼Œç³»çµ±é€€å‡º")
        except Exception as e:
            print(f"\nâŒ ç³»çµ±éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()