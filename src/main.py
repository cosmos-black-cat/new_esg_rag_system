#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESGå ±å‘Šæ›¸æå–å™¨ - ä¸»ç¨‹å¼ v1.0
å°ˆæ³¨æ–¼ESGå ±å‘Šæ›¸ä¸­å†ç”Ÿå¡‘è† ç›¸é—œæ•¸æ“šçš„æå–å’Œå½™æ•´
"""

import os
import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# é…ç½®è¼‰å…¥
try:
    from config import (
        GOOGLE_API_KEY, DATA_PATH, RESULTS_PATH, 
        MAX_DOCS_PER_RUN, ENABLE_LLM_ENHANCEMENT
    )
    CONFIG_LOADED = True
    print("âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿config.pyæ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")
    CONFIG_LOADED = False

# =============================================================================
# ç³»çµ±æª¢æŸ¥å‡½æ•¸
# =============================================================================

def check_environment():
    """æª¢æŸ¥ç³»çµ±ç’°å¢ƒ"""
    print("ğŸ”§ æª¢æŸ¥ç³»çµ±ç’°å¢ƒ...")
    
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æ–‡ä»¶è¼‰å…¥å¤±æ•—")
        return False
    
    if not GOOGLE_API_KEY:
        print("âŒ Google API Keyæœªè¨­ç½®")
        print("è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®GOOGLE_API_KEY=your_api_key")
        return False
    
    print(f"âœ… Google API Key: {GOOGLE_API_KEY[:10]}...")
    
    # æª¢æŸ¥ä¸¦å‰µå»ºç›®éŒ„
    directories = {
        "æ•¸æ“šç›®éŒ„": DATA_PATH,
        "çµæœç›®éŒ„": RESULTS_PATH
    }
    
    for name, path in directories.items():
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)
            print(f"âœ… å‰µå»º{name}: {path}")
        else:
            print(f"âœ… {name}: {path}")
    
    return True

def find_pdf_files() -> tuple[bool, list]:
    """æ‰¾åˆ°æ‰€æœ‰PDFæ–‡ä»¶"""
    if not CONFIG_LOADED:
        return False, []
    
    try:
        data_dir = Path(DATA_PATH)
        pdf_files = list(data_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"âŒ åœ¨ {DATA_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
            print("è«‹å°‡ESGå ±å‘ŠPDFæ–‡ä»¶æ”¾å…¥dataç›®éŒ„ä¸­")
            return False, []
        
        print(f"âœ… æ‰¾åˆ° {len(pdf_files)} å€‹PDFæ–‡ä»¶:")
        for pdf_file in pdf_files:
            print(f"   - {pdf_file.name}")
        
        return True, pdf_files
        
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾PDFæ–‡ä»¶å¤±æ•—: {e}")
        return False, []

# =============================================================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸
# =============================================================================

def run_preprocessing(pdf_files: list = None, force: bool = False) -> Optional[Dict]:
    """åŸ·è¡Œé è™•ç†"""
    try:
        from preprocess import preprocess_multiple_documents, DocumentMetadataExtractor
        
        if pdf_files is None:
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                return None
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é è™•ç†
        if not force:
            from config import VECTOR_DB_PATH
            existing_dbs = []
            for pdf_file in pdf_files:
                pdf_name = pdf_file.stem
                db_path = os.path.join(
                    os.path.dirname(VECTOR_DB_PATH),
                    f"esg_db_{pdf_name}"
                )
                if os.path.exists(db_path):
                    existing_dbs.append(pdf_file.name)
            
            if existing_dbs and len(existing_dbs) == len(pdf_files):
                print("â„¹ï¸  æ‰€æœ‰æ–‡ä»¶çš„å‘é‡è³‡æ–™åº«å·²å­˜åœ¨ï¼Œè·³éé è™•ç†")
                print("   å¦‚éœ€é‡æ–°è™•ç†ï¼Œè«‹ä½¿ç”¨ --force åƒæ•¸")
                
                # è¿”å›ç¾æœ‰çš„æ–‡æª”ä¿¡æ¯
                metadata_extractor = DocumentMetadataExtractor()
                docs_info = {}
                for pdf_file in pdf_files:
                    pdf_name = pdf_file.stem
                    metadata = metadata_extractor.extract_metadata(str(pdf_file))
                    docs_info[str(pdf_file)] = {
                        'db_path': os.path.join(os.path.dirname(VECTOR_DB_PATH), f"esg_db_{pdf_name}"),
                        'metadata': metadata,
                        'pdf_name': pdf_name
                    }
                return docs_info
        
        print("ğŸ”„ é–‹å§‹é è™•ç†...")
        print("   é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å¾…...")
        
        # åŸ·è¡Œé è™•ç†
        results = preprocess_multiple_documents([str(f) for f in pdf_files])
        
        if results:
            print("âœ… é è™•ç†å®Œæˆ")
            return results
        else:
            print("âŒ é è™•ç†å¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ é è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_extraction(docs_info: Dict, max_docs: int = None) -> Optional[Dict]:
    """åŸ·è¡ŒESGæ•¸æ“šæå–"""
    try:
        from esg_extractor import ESGExtractor, DocumentInfo
        
        print("ğŸ“Š åˆå§‹åŒ–ESGå ±å‘Šæ›¸æå–å™¨...")
        extractor = ESGExtractor(enable_llm=ENABLE_LLM_ENHANCEMENT)
        
        # ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§æ–‡æª”æ•¸
        if max_docs is None:
            max_docs = MAX_DOCS_PER_RUN
        
        # è½‰æ›æ–‡æª”ä¿¡æ¯æ ¼å¼
        document_infos = {}
        for pdf_path, info in docs_info.items():
            metadata = info['metadata']
            document_infos[pdf_path] = DocumentInfo(
                company_name=metadata['company_name'],
                report_year=metadata['report_year'],
                pdf_name=info['pdf_name'],
                db_path=info['db_path']
            )
        
        print("ğŸ“Š é–‹å§‹ESGæ•¸æ“šæå–...")
        print(f"   æœ€å¤§è™•ç†æ–‡æª”æ•¸: {max_docs}")
        print(f"   LLMå¢å¼·: {'å•Ÿç”¨' if ENABLE_LLM_ENHANCEMENT else 'åœç”¨'}")
        
        results = extractor.process_multiple_documents(document_infos, max_docs)
        
        return results
        
    except Exception as e:
        print(f"âŒ ESGæ•¸æ“šæå–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_consolidation() -> Optional[str]:
    """åŸ·è¡Œå½™æ•´åŠŸèƒ½"""
    try:
        from consolidator import consolidate_esg_results
        
        print("\nğŸ“Š é–‹å§‹å½™æ•´ESGçµæœ...")
        print("âš ï¸ æ³¨æ„ï¼šæª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå°‡è¢«è‡ªå‹•æ’é™¤")
        
        if not CONFIG_LOADED:
            print("âŒ é…ç½®æœªè¼‰å…¥")
            return None
        
        # æª¢æŸ¥çµæœç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(RESULTS_PATH):
            print(f"âŒ çµæœç›®éŒ„ä¸å­˜åœ¨: {RESULTS_PATH}")
            return None
        
        # æª¢æŸ¥æ˜¯å¦æœ‰Excelæª”æ¡ˆ
        results_dir = Path(RESULTS_PATH)
        excel_files = list(results_dir.glob("*.xlsx"))
        
        if not excel_files:
            print(f"âŒ åœ¨ {RESULTS_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°Excelçµæœæª”æ¡ˆ")
            print("è«‹å…ˆåŸ·è¡Œè³‡æ–™æå–åŠŸèƒ½ç”Ÿæˆçµæœæª”æ¡ˆ")
            return None
        
        # çµ±è¨ˆæœ‰æ•ˆæª”æ¡ˆï¼ˆæ’é™¤'ç„¡æå–'ï¼‰
        valid_files = [f for f in excel_files if "ç„¡æå–" not in f.name]
        excluded_files = [f for f in excel_files if "ç„¡æå–" in f.name]
        
        print(f"ğŸ“„ æƒæåˆ° {len(excel_files)} å€‹Excelæª”æ¡ˆ")
        if excluded_files:
            print(f"âŠ— å°‡æ’é™¤ {len(excluded_files)} å€‹'ç„¡æå–'æª”æ¡ˆ")
        
        print(f"âœ… å°‡è™•ç† {len(valid_files)} å€‹æœ‰æ•ˆæª”æ¡ˆ")
        
        if not valid_files:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„æª”æ¡ˆå¯å½™æ•´ï¼ˆæ‰€æœ‰æª”æ¡ˆéƒ½åŒ…å«'ç„¡æå–'ï¼‰")
            return None
        
        # åŸ·è¡Œå½™æ•´
        result_path = consolidate_esg_results(RESULTS_PATH)
        
        if result_path:
            print(f"âœ… å½™æ•´å®Œæˆ: {Path(result_path).name}")
            return result_path
        else:
            print("âŒ å½™æ•´å¤±æ•—")
            return None
            
    except ImportError as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥å½™æ•´æ¨¡çµ„: {e}")
        print("è«‹ç¢ºä¿consolidator.pyæ–‡ä»¶å­˜åœ¨")
        return None
    except Exception as e:
        print(f"âŒ å½™æ•´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

# =============================================================================
# é¡¯ç¤ºå‡½æ•¸
# =============================================================================

def show_latest_results():
    """é¡¯ç¤ºæœ€æ–°çµæœ"""
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æœªè¼‰å…¥")
        return
    
    try:
        import pandas as pd
        
        results_dir = Path(RESULTS_PATH)
        if not results_dir.exists():
            print("âŒ çµæœç›®éŒ„ä¸å­˜åœ¨")
            return
        
        # æŸ¥æ‰¾Excelæ–‡ä»¶
        excel_files = list(results_dir.glob("ESG*.xlsx"))
        if not excel_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ°çµæœæ–‡ä»¶")
            return
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
        excel_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        print("ğŸ“Š æœ€æ–°çµæœæ–‡ä»¶")
        print("=" * 50)
        
        # åˆ†é¡é¡¯ç¤º
        consolidated_files = [f for f in excel_files if "å½™æ•´å ±å‘Š" in f.name]
        extraction_files = [f for f in excel_files if "å½™æ•´å ±å‘Š" not in f.name]
        
        if consolidated_files:
            print("\nğŸ“Š å½™æ•´å ±å‘Š:")
            for file in consolidated_files[:3]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        if extraction_files:
            print("\nğŸ“Š æå–çµæœ:")
            for file in extraction_files[:5]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        # çµ±è¨ˆä¿¡æ¯
        print(f"\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:")
        print(f"   ç¸½æª”æ¡ˆæ•¸: {len(excel_files)}")
        print(f"   å½™æ•´å ±å‘Š: {len(consolidated_files)} å€‹")
        print(f"   æå–çµæœ: {len(extraction_files)} å€‹")
            
    except Exception as e:
        print(f"âŒ æŸ¥çœ‹çµæœå¤±æ•—: {e}")

def show_system_info():
    """é¡¯ç¤ºç³»çµ±é…ç½®ä¿¡æ¯"""
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æœªè¼‰å…¥")
        return
    
    from config import (
        GEMINI_MODEL, EMBEDDING_MODEL, VECTOR_DB_PATH,
        CHUNK_SIZE, SEARCH_K, CONFIDENCE_THRESHOLD
    )
    
    print("ğŸ“‹ ESGå ±å‘Šæ›¸æå–å™¨é…ç½®ä¿¡æ¯")
    print("=" * 50)
    print(f"ğŸ¤– Geminiæ¨¡å‹: {GEMINI_MODEL}")
    print(f"ğŸ§  Embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
    print(f"ğŸ“š å‘é‡è³‡æ–™åº«: {VECTOR_DB_PATH}")
    print(f"ğŸ“ æ•¸æ“šç›®éŒ„: {DATA_PATH}")
    print(f"ğŸ“Š çµæœç›®éŒ„: {RESULTS_PATH}")
    print(f"ğŸ”¢ æ–‡æœ¬å¡Šå¤§å°: {CHUNK_SIZE}")
    print(f"ğŸ” æœç´¢æ•¸é‡: {SEARCH_K}")
    print(f"ğŸ“ ä¿¡å¿ƒåˆ†æ•¸é–¾å€¼: {CONFIDENCE_THRESHOLD}")
    print(f"ğŸ“„ æœ€å¤§è™•ç†æ–‡æª”æ•¸: {MAX_DOCS_PER_RUN}")
    print(f"ğŸ¤– LLMå¢å¼·: {'å•Ÿç”¨' if ENABLE_LLM_ENHANCEMENT else 'åœç”¨'}")

def show_usage_guide():
    """é¡¯ç¤ºä½¿ç”¨èªªæ˜"""
    print("\nğŸ“š ESGå ±å‘Šæ›¸æå–å™¨ä½¿ç”¨èªªæ˜")
    print("=" * 60)
    print("""
ğŸ¯ ä¸»è¦åŠŸèƒ½ï¼š
   â€¢ è‡ªå‹•æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿå¡‘è† ç›¸é—œæ•¸æ“š
   â€¢ æ”¯æ´æ‰¹é‡è™•ç†å¤šä»½å ±å‘Š
   â€¢ æ™ºèƒ½è­˜åˆ¥é—œéµæ•¸å€¼å’Œç›¸é—œæè¿°
   â€¢ å¤šå…¬å¸å¤šå¹´åº¦çµæœå½™æ•´åˆ†æ

ğŸ“‹ è™•ç†æµç¨‹ï¼š
   1. å°‡ESGå ±å‘ŠPDFæ”¾å…¥dataç›®éŒ„
   2. åŸ·è¡ŒåŠŸèƒ½1é€²è¡Œæ•¸æ“šæå–
   3. åŸ·è¡ŒåŠŸèƒ½2ç”Ÿæˆå½™æ•´å ±å‘Š
   4. æŸ¥çœ‹resultsç›®éŒ„ä¸­çš„çµæœæª”æ¡ˆ

ğŸ”§ æ ¸å¿ƒç‰¹è‰²ï¼š
   â€¢ ç²¾ç¢ºçš„é—œéµå­—èˆ‡æ•¸å€¼é—œè¯æ€§åˆ†æ
   â€¢ æ™ºèƒ½æ’é™¤ç„¡é—œå…§å®¹ï¼ˆè·æ¥­ç½å®³ã€è³½äº‹ç­‰ï¼‰
   â€¢ é é¢ç´šå»é‡ç¢ºä¿è³‡æ–™å“è³ª
   â€¢ è‡ªå‹•å…¬å¸åç¨±æ¨™æº–åŒ–
   â€¢ å°ˆæ¥­çš„Excelå ±è¡¨è¼¸å‡º

ğŸ“Š è¼¸å‡ºå…§å®¹ï¼š
   â€¢ å†ç”Ÿå¡‘è† ç›¸é—œæ•¸å€¼æ•¸æ“š
   â€¢ å›æ”¶ç”¢èƒ½å’Œä½¿ç”¨é‡
   â€¢ ç’°ä¿æ•ˆç›Šå’Œæ¸›ç¢³è³‡æ–™
   â€¢ å¾ªç’°ç¶“æ¿Ÿç›¸é—œæŒ‡æ¨™

âš¡ å¿«é€Ÿé–‹å§‹ï¼š
   1. è¨­ç½®API Keyï¼ˆåœ¨.envæª”æ¡ˆä¸­ï¼‰
   2. æ”¾å…¥PDFæª”æ¡ˆåˆ°dataç›®éŒ„
   3. åŸ·è¡ŒåŠŸèƒ½1æå–æ•¸æ“š
   4. åŸ·è¡ŒåŠŸèƒ½2å½™æ•´çµæœ
""")

# =============================================================================
# ç”¨æˆ¶ç•Œé¢
# =============================================================================

def interactive_menu():
    """äº’å‹•å¼ä¸»é¸å–®"""
    while True:
        print("\n" + "ğŸ“Š" * 20)
        print("ğŸ¢ ESGå ±å‘Šæ›¸æå–å™¨ v1.0")
        print("å°ˆæ¥­æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿå¡‘è† ç›¸é—œæ•¸æ“š")
        print("ğŸ“Š" * 20)
        print("1. ğŸ“Š åŸ·è¡ŒESGæ•¸æ“šæå–ï¼ˆä¸»è¦åŠŸèƒ½ï¼‰")
        print("2. ğŸ”„ é‡æ–°é è™•ç†PDF")
        print("3. ğŸ”— å½™æ•´å¤šå…¬å¸çµæœ")
        print("4. ğŸ“‹ æŸ¥çœ‹æœ€æ–°çµæœ")
        print("5. âš™ï¸  é¡¯ç¤ºç³»çµ±ä¿¡æ¯")
        print("6. ğŸ’¡ ä½¿ç”¨èªªæ˜")
        print("7. ğŸšª é€€å‡ºç³»çµ±")
        
        choice = input("\nè«‹é¸æ“‡åŠŸèƒ½ (1-7): ").strip()
        
        if choice == "1":
            # åŸ·è¡ŒESGæ•¸æ“šæå–
            print("\nğŸ“Š æº–å‚™åŸ·è¡ŒESGæ•¸æ“šæå–...")
            
            if not check_environment():
                print("âŒ ç’°å¢ƒæª¢æŸ¥å¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæå–")
                continue
            
            # æ‰¾åˆ°æ‰€æœ‰PDFæ–‡ä»¶
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                continue
            
            # é è™•ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
            docs_info = run_preprocessing(pdf_files)
            if not docs_info:
                print("âŒ é è™•ç†å¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæå–")
                continue
            
            # åŸ·è¡Œæå–
            results = run_extraction(docs_info)
            if results:
                print(f"\nğŸ‰ æå–å®Œæˆï¼ç”Ÿæˆäº† {len(results)} å€‹çµæœæ–‡ä»¶")
                for pdf_path, (extractions, summary, excel_path) in results.items():
                    print(f"ğŸ“Š {summary.company_name} - {summary.report_year}: {len(extractions)} å€‹çµæœ")
                    print(f"   æ–‡ä»¶: {Path(excel_path).name}")
                
                # è©¢å•æ˜¯å¦ç«‹å³å½™æ•´
                if len(results) > 1:
                    consolidate_now = input("\næ˜¯å¦ç«‹å³åŸ·è¡Œå½™æ•´åŠŸèƒ½ï¼Ÿ(y/n): ").strip().lower()
                    if consolidate_now == 'y':
                        result_path = run_consolidation()
                        if result_path:
                            print(f"ğŸ”— å½™æ•´å®Œæˆ: {Path(result_path).name}")
            
        elif choice == "2":
            # é‡æ–°é è™•ç†PDF
            print("\nğŸ”„ é‡æ–°é è™•ç†PDF...")
            
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                continue
            
            print(f"å°‡è™•ç† {len(pdf_files)} å€‹PDFæ–‡ä»¶ï¼š")
            for pdf_file in pdf_files:
                print(f"  - {pdf_file.name}")
            
            confirm = input("é€™å°‡é‡æ–°å»ºç«‹æ‰€æœ‰å‘é‡è³‡æ–™åº«ï¼Œç¢ºå®šç¹¼çºŒï¼Ÿ(y/n): ").strip().lower()
            if confirm == 'y':
                docs_info = run_preprocessing(pdf_files, force=True)
                if docs_info:
                    print("âœ… é è™•ç†å®Œæˆï¼Œç¾åœ¨å¯ä»¥åŸ·è¡Œæ•¸æ“šæå–")
            
        elif choice == "3":
            # å½™æ•´å¤šå…¬å¸çµæœ
            print("\nğŸ”— æº–å‚™å½™æ•´å¤šå…¬å¸çµæœ...")
            
            result_path = run_consolidation()
            if result_path:
                print(f"\nğŸ‰ å½™æ•´åŠŸèƒ½åŸ·è¡Œå®Œæˆï¼")
                print(f"ğŸ“Š å½™æ•´æª”æ¡ˆ: {Path(result_path).name}")
                print(f"ğŸ“ å­˜æ”¾ä½ç½®: {RESULTS_PATH}")
            else:
                print("âŒ å½™æ•´åŠŸèƒ½åŸ·è¡Œå¤±æ•—")
                print("ğŸ’¡ è«‹ç¢ºä¿å·²åŸ·è¡Œéè³‡æ–™æå–åŠŸèƒ½")
            
        elif choice == "4":
            # æŸ¥çœ‹æœ€æ–°çµæœ
            show_latest_results()
            
        elif choice == "5":
            # é¡¯ç¤ºç³»çµ±ä¿¡æ¯
            show_system_info()
            
        elif choice == "6":
            # ä½¿ç”¨èªªæ˜
            show_usage_guide()
            
        elif choice == "7":
            # é€€å‡º
            print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ESGå ±å‘Šæ›¸æå–å™¨ï¼")
            break
            
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥1-7ä¹‹é–“çš„æ•¸å­—")

def command_line_mode():
    """å‘½ä»¤è¡Œæ¨¡å¼"""
    parser = argparse.ArgumentParser(
        description="ESGå ±å‘Šæ›¸æå–å™¨ v1.0 - å°ˆæ¥­æå–å†ç”Ÿå¡‘è† ç›¸é—œæ•¸æ“š",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python main.py                      # äº’å‹•æ¨¡å¼
  python main.py --auto               # è‡ªå‹•åŸ·è¡Œå®Œæ•´æµç¨‹
  python main.py --preprocess         # åƒ…é è™•ç†
  python main.py --extract            # åƒ…æ•¸æ“šæå–
  python main.py --consolidate        # åƒ…å½™æ•´åŠŸèƒ½
  python main.py --force              # å¼·åˆ¶é‡æ–°é è™•ç†
  python main.py --results            # æŸ¥çœ‹çµæœ
        """
    )
    
    parser.add_argument("--auto", action="store_true", help="è‡ªå‹•åŸ·è¡Œå®Œæ•´æµç¨‹")
    parser.add_argument("--preprocess", action="store_true", help="é è™•ç†æ‰€æœ‰PDFæ–‡ä»¶")
    parser.add_argument("--extract", action="store_true", help="åŸ·è¡ŒESGæ•¸æ“šæå–")
    parser.add_argument("--consolidate", action="store_true", help="åŸ·è¡Œå½™æ•´åŠŸèƒ½")
    parser.add_argument("--force", action="store_true", help="å¼·åˆ¶é‡æ–°é è™•ç†")
    parser.add_argument("--results", action="store_true", help="æŸ¥çœ‹æœ€æ–°çµæœ")
    parser.add_argument("--max-docs", type=int, default=None, help="æœ€å¤§è™•ç†æ–‡æª”æ•¸")
    
    args = parser.parse_args()
    
    # æ ¹æ“šåƒæ•¸åŸ·è¡Œå°æ‡‰åŠŸèƒ½
    if args.auto:
        # è‡ªå‹•åŸ·è¡Œå®Œæ•´æµç¨‹
        print("ğŸ“Š è‡ªå‹•åŸ·è¡Œæ¨¡å¼")
        if not check_environment():
            sys.exit(1)
        
        has_pdfs, pdf_files = find_pdf_files()
        if not has_pdfs:
            sys.exit(1)
        
        print("åŸ·è¡Œé è™•ç†...")
        docs_info = run_preprocessing(pdf_files, force=args.force)
        if not docs_info:
            sys.exit(1)
        
        print("åŸ·è¡ŒESGæ•¸æ“šæå–...")
        results = run_extraction(docs_info, args.max_docs)
        if results:
            print(f"âœ… æå–å®Œæˆï¼ç”Ÿæˆäº† {len(results)} å€‹çµæœæ–‡ä»¶")
            
            # è‡ªå‹•åŸ·è¡Œå½™æ•´
            if len(results) > 1:
                print("\nåŸ·è¡Œå½™æ•´åŠŸèƒ½...")
                result_path = run_consolidation()
                if result_path:
                    print(f"ğŸ”— å½™æ•´å®Œæˆ: {Path(result_path).name}")
        else:
            sys.exit(1)
            
    elif args.preprocess:
        has_pdfs, pdf_files = find_pdf_files()
        if not has_pdfs:
            sys.exit(1)
        
        docs_info = run_preprocessing(pdf_files, force=args.force)
        if docs_info:
            print("âœ… é è™•ç†å®Œæˆ")
        else:
            sys.exit(1)
            
    elif args.extract:
        has_pdfs, pdf_files = find_pdf_files()
        if not has_pdfs:
            sys.exit(1)
        
        docs_info = run_preprocessing(pdf_files, force=False)
        if not docs_info:
            print("âŒ éœ€è¦å…ˆåŸ·è¡Œé è™•ç†")
            sys.exit(1)
        
        results = run_extraction(docs_info, args.max_docs)
        if not results:
            sys.exit(1)
    
    elif args.consolidate:
        # åƒ…åŸ·è¡Œå½™æ•´
        print("ğŸ”— å½™æ•´åŠŸèƒ½æ¨¡å¼")
        result_path = run_consolidation()
        if result_path:
            print(f"âœ… å½™æ•´å®Œæˆ: {Path(result_path).name}")
        else:
            sys.exit(1)
            
    elif args.results:
        show_latest_results()
        
    else:
        # æ²’æœ‰åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©
        parser.print_help()

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ“Š ESGå ±å‘Šæ›¸æå–å™¨ v1.0")
    print("å°ˆæ¥­æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿå¡‘è† ç›¸é—œæ•¸æ“š")
    print("=" * 60)
    
    # æ ¹æ“šå‘½ä»¤è¡Œåƒæ•¸æ±ºå®šé‹è¡Œæ¨¡å¼
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        command_line_mode()
    else:
        # äº’å‹•æ¨¡å¼
        try:
            interactive_menu()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·ï¼Œç³»çµ±é€€å‡º")
        except Exception as e:
            print(f"\nâŒ ç³»çµ±éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()