#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESGå ±å‘Šæ›¸æå–å™¨ - ä¸»ç¨‹å¼ v2.0
æ”¯æŒå¢å¼·é—œéµå­—é…ç½®å’ŒWordæ–‡ä»¶è¼¸å‡º
"""

import os
import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# é…ç½®è¼‰å…¥
try:
    from config import (
        GOOGLE_API_KEY, DATA_PATH, RESULTS_PATH, 
        MAX_DOCS_PER_RUN, ENABLE_LLM_ENHANCEMENT
    )
    CONFIG_LOADED = True
    print("âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿config.pyæ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")
    CONFIG_LOADED = False

# =============================================================================
# ç³»çµ±æª¢æŸ¥å‡½æ•¸
# =============================================================================

def check_environment():
    """æª¢æŸ¥ç³»çµ±ç’°å¢ƒ"""
    print("ğŸ”§ æª¢æŸ¥ç³»çµ±ç’°å¢ƒ...")
    
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æ–‡ä»¶è¼‰å…¥å¤±æ•—")
        return False
    
    if not GOOGLE_API_KEY:
        print("âŒ Google API Keyæœªè¨­ç½®")
        print("è«‹åœ¨.envæ–‡ä»¶ä¸­è¨­ç½®GOOGLE_API_KEY=your_api_key")
        return False
    
    print(f"âœ… Google API Key: {GOOGLE_API_KEY[:10]}...")
    
    # æª¢æŸ¥ä¸¦å‰µå»ºç›®éŒ„
    directories = {
        "æ•¸æ“šç›®éŒ„": DATA_PATH,
        "çµæœç›®éŒ„": RESULTS_PATH
    }
    
    for name, path in directories.items():
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)
            print(f"âœ… å‰µå»º{name}: {path}")
        else:
            print(f"âœ… {name}: {path}")
    
    # æª¢æŸ¥Wordè™•ç†ä¾è³´
    try:
        import docx
        print("âœ… Wordæ–‡æª”è™•ç†ä¾è³´å·²å®‰è£")
    except ImportError:
        print("âš ï¸ Wordæ–‡æª”è™•ç†ä¾è³´æœªå®‰è£")
        print("è«‹é‹è¡Œ: pip install python-docx")
        return False
    
    return True

def find_pdf_files() -> tuple[bool, list]:
    """æ‰¾åˆ°æ‰€æœ‰PDFæ–‡ä»¶"""
    if not CONFIG_LOADED:
        return False, []
    
    try:
        data_dir = Path(DATA_PATH)
        pdf_files = list(data_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"âŒ åœ¨ {DATA_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
            print("è«‹å°‡ESGå ±å‘ŠPDFæ–‡ä»¶æ”¾å…¥dataç›®éŒ„ä¸­")
            return False, []
        
        print(f"âœ… æ‰¾åˆ° {len(pdf_files)} å€‹PDFæ–‡ä»¶:")
        for pdf_file in pdf_files:
            print(f"   - {pdf_file.name}")
        
        return True, pdf_files
        
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾PDFæ–‡ä»¶å¤±æ•—: {e}")
        return False, []

# =============================================================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸
# =============================================================================

def run_preprocessing(pdf_files: list = None, force: bool = False) -> Optional[Dict]:
    """åŸ·è¡Œé è™•ç†"""
    try:
        from preprocess import preprocess_multiple_documents, DocumentMetadataExtractor
        
        if pdf_files is None:
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                return None
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é è™•ç†
        if not force:
            from config import VECTOR_DB_PATH
            existing_dbs = []
            for pdf_file in pdf_files:
                pdf_name = pdf_file.stem
                db_path = os.path.join(
                    os.path.dirname(VECTOR_DB_PATH),
                    f"esg_db_{pdf_name}"
                )
                if os.path.exists(db_path):
                    existing_dbs.append(pdf_file.name)
            
            if existing_dbs and len(existing_dbs) == len(pdf_files):
                print("â„¹ï¸  æ‰€æœ‰æ–‡ä»¶çš„å‘é‡è³‡æ–™åº«å·²å­˜åœ¨ï¼Œè·³éé è™•ç†")
                print("   å¦‚éœ€é‡æ–°è™•ç†ï¼Œè«‹ä½¿ç”¨ --force åƒæ•¸")
                
                # è¿”å›ç¾æœ‰çš„æ–‡æª”ä¿¡æ¯
                metadata_extractor = DocumentMetadataExtractor()
                docs_info = {}
                for pdf_file in pdf_files:
                    pdf_name = pdf_file.stem
                    metadata = metadata_extractor.extract_metadata(str(pdf_file))
                    docs_info[str(pdf_file)] = {
                        'db_path': os.path.join(os.path.dirname(VECTOR_DB_PATH), f"esg_db_{pdf_name}"),
                        'metadata': metadata,
                        'pdf_name': pdf_name
                    }
                return docs_info
        
        print("ğŸ”„ é–‹å§‹é è™•ç†...")
        print("   é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å¾…...")
        
        # åŸ·è¡Œé è™•ç†
        results = preprocess_multiple_documents([str(f) for f in pdf_files])
        
        if results:
            print("âœ… é è™•ç†å®Œæˆ")
            return results
        else:
            print("âŒ é è™•ç†å¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ é è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_enhanced_extraction(docs_info: Dict, max_docs: int = None) -> Optional[Dict]:
    """åŸ·è¡Œå¢å¼·ç‰ˆESGæ•¸æ“šæå–"""
    try:
        from esg_extractor import EnhancedESGExtractor, DocumentInfo
        
        print("ğŸ“Š åˆå§‹åŒ–å¢å¼·ç‰ˆESGå ±å‘Šæ›¸æå–å™¨...")
        print("ğŸ†• æ–°åŠŸèƒ½:")
        print("   â€¢ æ”¯æŒæ–°çš„ESGé—œéµå­—é…ç½®")
        print("   â€¢ è‡ªå‹•è­˜åˆ¥è‚¡ç¥¨ä»£è™Ÿ")
        print("   â€¢ è¼¸å‡ºWordæ–‡æª”æ ¼å¼")
        print("   â€¢ æå‡æå–æº–ç¢ºæ€§")
        
        extractor = EnhancedESGExtractor(enable_llm=ENABLE_LLM_ENHANCEMENT)
        
        # ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§æ–‡æª”æ•¸
        if max_docs is None:
            max_docs = MAX_DOCS_PER_RUN
        
        # è½‰æ›æ–‡æª”ä¿¡æ¯æ ¼å¼
        document_infos = {}
        for pdf_path, info in docs_info.items():
            metadata = info['metadata']
            document_infos[pdf_path] = DocumentInfo(
                company_name=metadata['company_name'],
                report_year=metadata['report_year'],
                pdf_name=info['pdf_name'],
                db_path=info['db_path'],
                stock_code=""  # å°‡åœ¨è™•ç†éç¨‹ä¸­è‡ªå‹•æå–
            )
        
        print("ğŸ“Š é–‹å§‹å¢å¼·ç‰ˆESGæ•¸æ“šæå–...")
        print(f"   æœ€å¤§è™•ç†æ–‡æª”æ•¸: {max_docs}")
        print(f"   LLMå¢å¼·: {'å•Ÿç”¨' if ENABLE_LLM_ENHANCEMENT else 'åœç”¨'}")
        
        # æ‰¹é‡è™•ç†æ–‡æª”
        results = {}
        
        for pdf_path, doc_info in document_infos.items():
            try:
                print(f"\nğŸ“„ è™•ç†: {doc_info.company_name} - {doc_info.report_year}")
                
                extractions, summary, excel_path, word_path = extractor.process_single_document(doc_info, max_docs)
                
                results[pdf_path] = (extractions, summary, excel_path, word_path)
                
                print(f"âœ… å®Œæˆ: ç”Ÿæˆ {len(extractions)} å€‹çµæœ")
                print(f"ğŸ“Š Excelæ–‡ä»¶: {Path(excel_path).name}")
                if word_path:
                    print(f"ğŸ“„ Wordæ–‡ä»¶: {Path(word_path).name}")
                
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•— {doc_info.company_name}: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        return results
        
    except Exception as e:
        print(f"âŒ å¢å¼·ç‰ˆESGæ•¸æ“šæå–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_consolidation() -> Optional[str]:
    """åŸ·è¡Œå½™æ•´åŠŸèƒ½"""
    try:
        from consolidator import consolidate_esg_results
        
        print("\nğŸ“Š é–‹å§‹å½™æ•´ESGçµæœ...")
        print("âš ï¸ æ³¨æ„ï¼šæª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå°‡è¢«è‡ªå‹•æ’é™¤")
        
        if not CONFIG_LOADED:
            print("âŒ é…ç½®æœªè¼‰å…¥")
            return None
        
        # æª¢æŸ¥çµæœç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(RESULTS_PATH):
            print(f"âŒ çµæœç›®éŒ„ä¸å­˜åœ¨: {RESULTS_PATH}")
            return None
        
        # æª¢æŸ¥æ˜¯å¦æœ‰Excelæª”æ¡ˆ
        results_dir = Path(RESULTS_PATH)
        excel_files = list(results_dir.glob("*.xlsx"))
        
        if not excel_files:
            print(f"âŒ åœ¨ {RESULTS_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°Excelçµæœæª”æ¡ˆ")
            print("è«‹å…ˆåŸ·è¡Œè³‡æ–™æå–åŠŸèƒ½ç”Ÿæˆçµæœæª”æ¡ˆ")
            return None
        
        # çµ±è¨ˆæœ‰æ•ˆæª”æ¡ˆï¼ˆæ’é™¤'ç„¡æå–'ï¼‰
        valid_files = [f for f in excel_files if "ç„¡æå–" not in f.name]
        excluded_files = [f for f in excel_files if "ç„¡æå–" in f.name]
        
        print(f"ğŸ“„ æƒæåˆ° {len(excel_files)} å€‹Excelæª”æ¡ˆ")
        if excluded_files:
            print(f"âŠ— å°‡æ’é™¤ {len(excluded_files)} å€‹'ç„¡æå–'æª”æ¡ˆ")
        
        print(f"âœ… å°‡è™•ç† {len(valid_files)} å€‹æœ‰æ•ˆæª”æ¡ˆ")
        
        if not valid_files:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„æª”æ¡ˆå¯å½™æ•´ï¼ˆæ‰€æœ‰æª”æ¡ˆéƒ½åŒ…å«'ç„¡æå–'ï¼‰")
            return None
        
        # åŸ·è¡Œå½™æ•´
        result_path = consolidate_esg_results(RESULTS_PATH)
        
        if result_path:
            print(f"âœ… å½™æ•´å®Œæˆ: {Path(result_path).name}")
            return result_path
        else:
            print("âŒ å½™æ•´å¤±æ•—")
            return None
            
    except ImportError as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥å½™æ•´æ¨¡çµ„: {e}")
        print("è«‹ç¢ºä¿consolidator.pyæ–‡ä»¶å­˜åœ¨")
        return None
    except Exception as e:
        print(f"âŒ å½™æ•´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

# =============================================================================
# é¡¯ç¤ºå‡½æ•¸
# =============================================================================

def show_latest_results():
    """é¡¯ç¤ºæœ€æ–°çµæœ"""
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æœªè¼‰å…¥")
        return
    
    try:
        import pandas as pd
        
        results_dir = Path(RESULTS_PATH)
        if not results_dir.exists():
            print("âŒ çµæœç›®éŒ„ä¸å­˜åœ¨")
            return
        
        # æŸ¥æ‰¾Excelæ–‡ä»¶å’ŒWordæ–‡ä»¶
        excel_files = list(results_dir.glob("ESG*.xlsx"))
        word_files = list(results_dir.glob("*.docx"))
        
        if not excel_files and not word_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ°çµæœæ–‡ä»¶")
            return
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
        all_files = excel_files + word_files
        all_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        print("ğŸ“Š æœ€æ–°çµæœæ–‡ä»¶")
        print("=" * 50)
        
        # åˆ†é¡é¡¯ç¤º
        consolidated_files = [f for f in all_files if "å½™æ•´å ±å‘Š" in f.name]
        extraction_files = [f for f in all_files if "å½™æ•´å ±å‘Š" not in f.name]
        word_files_filtered = [f for f in extraction_files if f.suffix == '.docx']
        excel_files_filtered = [f for f in extraction_files if f.suffix == '.xlsx']
        
        if consolidated_files:
            print("\nğŸ“Š å½™æ•´å ±å‘Š:")
            for file in consolidated_files[:3]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        if word_files_filtered:
            print("\nğŸ“„ Wordæ–‡æª”:")
            for file in word_files_filtered[:5]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        if excel_files_filtered:
            print("\nğŸ“Š Excelçµæœ:")
            for file in excel_files_filtered[:5]:
                file_time = datetime.fromtimestamp(file.stat().st_mtime)
                file_size = file.stat().st_size / 1024
                print(f"   ğŸ“„ {file.name}")
                print(f"      ğŸ•’ {file_time.strftime('%Y-%m-%d %H:%M:%S')} | ğŸ“ {file_size:.1f}KB")
        
        # çµ±è¨ˆä¿¡æ¯
        print(f"\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:")
        print(f"   ç¸½æª”æ¡ˆæ•¸: {len(all_files)}")
        print(f"   å½™æ•´å ±å‘Š: {len(consolidated_files)} å€‹")
        print(f"   Excelçµæœ: {len(excel_files_filtered)} å€‹")
        print(f"   Wordæ–‡æª”: {len(word_files_filtered)} å€‹")
            
    except Exception as e:
        print(f"âŒ æŸ¥çœ‹çµæœå¤±æ•—: {e}")

def show_system_info():
    """é¡¯ç¤ºç³»çµ±é…ç½®ä¿¡æ¯"""
    if not CONFIG_LOADED:
        print("âŒ é…ç½®æœªè¼‰å…¥")
        return
    
    from config import (
        GEMINI_MODEL, EMBEDDING_MODEL, VECTOR_DB_PATH,
        CHUNK_SIZE, SEARCH_K, CONFIDENCE_THRESHOLD
    )
    
    print("ğŸ“‹ ESGå ±å‘Šæ›¸æå–å™¨é…ç½®ä¿¡æ¯ v2.0")
    print("=" * 50)
    print(f"ğŸ¤– Geminiæ¨¡å‹: {GEMINI_MODEL}")
    print(f"ğŸ§  Embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
    print(f"ğŸ“š å‘é‡è³‡æ–™åº«: {VECTOR_DB_PATH}")
    print(f"ğŸ“ æ•¸æ“šç›®éŒ„: {DATA_PATH}")
    print(f"ğŸ“Š çµæœç›®éŒ„: {RESULTS_PATH}")
    print(f"ğŸ”¢ æ–‡æœ¬å¡Šå¤§å°: {CHUNK_SIZE}")
    print(f"ğŸ” æœç´¢æ•¸é‡: {SEARCH_K}")
    print(f"ğŸ“ ä¿¡å¿ƒåˆ†æ•¸é–¾å€¼: {CONFIDENCE_THRESHOLD}")
    print(f"ğŸ“„ æœ€å¤§è™•ç†æ–‡æª”æ•¸: {MAX_DOCS_PER_RUN}")
    print(f"ğŸ¤– LLMå¢å¼·: {'å•Ÿç”¨' if ENABLE_LLM_ENHANCEMENT else 'åœç”¨'}")
    
    print(f"\nğŸ†• å¢å¼·ç‰ˆæ–°åŠŸèƒ½:")
    print(f"   â€¢ æ–°çš„é—œéµå­—é…ç½®ï¼ˆææ–™å¾ªç’°ç‡ã€å†ç”Ÿèƒ½æºä½¿ç”¨ç‡ç­‰ï¼‰")
    print(f"   â€¢ è‡ªå‹•è‚¡ç¥¨ä»£è™Ÿè­˜åˆ¥")
    print(f"   â€¢ Wordæ–‡æª”è¼¸å‡ºï¼ˆ.docxæ ¼å¼ï¼‰")
    print(f"   â€¢ æå‡çš„æå–æº–ç¢ºæ€§")

def show_usage_guide():
    """é¡¯ç¤ºä½¿ç”¨èªªæ˜"""
    print("\nğŸ“š ESGå ±å‘Šæ›¸æå–å™¨ä½¿ç”¨èªªæ˜ v2.0")
    print("=" * 60)
    print("""
ğŸ¯ ä¸»è¦åŠŸèƒ½ï¼š
   â€¢ è‡ªå‹•æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿææ–™å’Œå¾ªç’°ç¶“æ¿Ÿç›¸é—œæ•¸æ“š
   â€¢ æ”¯æ´æ–°çš„é—œéµå­—é¡å‹ï¼ˆæ¯”ç‡é¡ã€æ•¸é‡é¡ã€æŠ€è¡“é¡ï¼‰
   â€¢ è‡ªå‹•è­˜åˆ¥å…¬å¸è‚¡ç¥¨ä»£è™Ÿ
   â€¢ æ‰¹é‡è™•ç†å¤šä»½å ±å‘Š
   â€¢ æ™ºèƒ½è­˜åˆ¥é—œéµæ•¸å€¼å’Œç›¸é—œæè¿°
   â€¢ å¤šå…¬å¸å¤šå¹´åº¦çµæœå½™æ•´åˆ†æ

ğŸ“‹ è™•ç†æµç¨‹ï¼š
   1. å°‡ESGå ±å‘ŠPDFæ”¾å…¥dataç›®éŒ„
   2. åŸ·è¡ŒåŠŸèƒ½1é€²è¡Œæ•¸æ“šæå–
   3. åŸ·è¡ŒåŠŸèƒ½3ç”Ÿæˆå½™æ•´å ±å‘Š
   4. æŸ¥çœ‹resultsç›®éŒ„ä¸­çš„çµæœæª”æ¡ˆ

ğŸ†• æ–°å¢åŠŸèƒ½ï¼š
   â€¢ Wordæ–‡æª”è¼¸å‡ºï¼šæ ¼å¼ç‚º{è‚¡ç¥¨ä»£è™Ÿ}_{å…¬å¸åç¨±}_{å¹´åº¦}_æå–çµ±æ•´.docx
   â€¢ æ–°é—œéµå­—æ”¯æŒï¼šææ–™å¾ªç’°ç‡ã€å†ç”Ÿèƒ½æºä½¿ç”¨ç‡ã€ç¶ é›»æ†‘è­‰ç­‰
   â€¢ è‡ªå‹•è‚¡ç¥¨ä»£è™Ÿè­˜åˆ¥ï¼šæ”¯æ´å°è‚¡ä»£è™Ÿæ ¼å¼
   â€¢ å¢å¼·æº–ç¢ºæ€§ï¼šæ›´ç²¾ç¢ºçš„é—œéµå­—-æ•¸å€¼é—œè¯æ€§åˆ†æ

ğŸ”§ æ ¸å¿ƒç‰¹è‰²ï¼š
   â€¢ ç²¾ç¢ºçš„é—œéµå­—èˆ‡æ•¸å€¼é—œè¯æ€§åˆ†æ
   â€¢ æ™ºèƒ½æ’é™¤ç„¡é—œå…§å®¹ï¼ˆè·æ¥­ç½å®³ã€è³½äº‹ç­‰ï¼‰
   â€¢ é é¢ç´šå»é‡ç¢ºä¿è³‡æ–™å“è³ª
   â€¢ å‹•æ…‹ä¿¡å¿ƒåˆ†æ•¸é–¾å€¼èª¿æ•´
   â€¢ è‡ªå‹•å…¬å¸åç¨±æ¨™æº–åŒ–
   â€¢ é›™æ ¼å¼è¼¸å‡ºï¼ˆExcel + Wordï¼‰

ğŸ“Š æ–°å¢æå–å…§å®¹ï¼š
   â€¢ ææ–™å¾ªç’°ç‡ã€ææ–™å¯å›æ”¶ç‡
   â€¢ å†ç”Ÿèƒ½æºä½¿ç”¨ç‡ã€ç¶ é›»æ†‘è­‰æ•¸é‡
   â€¢ å†ç”Ÿææ–™ä½¿ç”¨é‡ã€ç¢³æ’æ¸›é‡æ•¸æ“š
   â€¢ åˆ†é¸è¾¨è¦–æŠ€è¡“ã€å–®ä¸€ææ–™è™•ç†
   â€¢ è³¼é›»å”è­°ã€å¤ªé™½èƒ½é›»åŠ›ç›¸é—œæ•¸æ“š

ğŸ“„ Wordæ–‡æª”æ ¼å¼ï¼š
   é ç¢¼ï¼šç¬¬Xé 
   é—œéµå­—ï¼š[é—œéµå­—åç¨±]
   æ•¸å€¼ï¼š[æå–çš„æ•¸å€¼å’Œå–®ä½]
   ä¿¡å¿ƒåˆ†æ•¸ï¼š[0.000-1.000]
   æ•´å€‹æ®µè½å…§å®¹ï¼š[å®Œæ•´æ®µè½å…§å®¹]

âš¡ å¿«é€Ÿé–‹å§‹ï¼š
   1. è¨­ç½®API Keyï¼ˆåœ¨.envæª”æ¡ˆä¸­ï¼‰
   2. å®‰è£æ–°ä¾è³´ï¼špip install python-docx
   3. æ”¾å…¥PDFæª”æ¡ˆåˆ°dataç›®éŒ„
   4. åŸ·è¡ŒåŠŸèƒ½1é€²è¡Œå¢å¼·æå–
   5. åŸ·è¡ŒåŠŸèƒ½3å½™æ•´çµæœ
   6. æŸ¥çœ‹Excelå’ŒWordé›™æ ¼å¼è¼¸å‡º
""")

# =============================================================================
# ç”¨æˆ¶ç•Œé¢
# =============================================================================

def interactive_menu():
    """äº’å‹•å¼ä¸»é¸å–®"""
    while True:
        print("\n" + "ğŸ“Š" * 20)
        print("ğŸ¢ ESGå ±å‘Šæ›¸æå–å™¨ v2.0 (å¢å¼·ç‰ˆ)")
        print("å°ˆæ¥­æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿææ–™å’Œå¾ªç’°ç¶“æ¿Ÿæ•¸æ“š")
        print("ğŸ†• æ–°å¢ï¼šè‚¡ç¥¨ä»£è™Ÿè­˜åˆ¥ + Wordæ–‡æª”è¼¸å‡º")
        print("ğŸ“Š" * 20)
        print("1. ğŸ“Š åŸ·è¡Œå¢å¼·ç‰ˆESGæ•¸æ“šæå–ï¼ˆä¸»è¦åŠŸèƒ½ï¼‰")
        print("2. ğŸ”„ é‡æ–°é è™•ç†PDF")
        print("3. ğŸ”— å½™æ•´å¤šå…¬å¸çµæœ")
        print("4. ğŸ“‹ æŸ¥çœ‹æœ€æ–°çµæœ")
        print("5. âš™ï¸  é¡¯ç¤ºç³»çµ±ä¿¡æ¯")
        print("6. ğŸ’¡ ä½¿ç”¨èªªæ˜")
        print("7. ğŸšª é€€å‡ºç³»çµ±")
        
        choice = input("\nè«‹é¸æ“‡åŠŸèƒ½ (1-7): ").strip()
        
        if choice == "1":
            # åŸ·è¡Œå¢å¼·ç‰ˆESGæ•¸æ“šæå–
            print("\nğŸ“Š æº–å‚™åŸ·è¡Œå¢å¼·ç‰ˆESGæ•¸æ“šæå–...")
            
            if not check_environment():
                print("âŒ ç’°å¢ƒæª¢æŸ¥å¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæå–")
                continue
            
            # æ‰¾åˆ°æ‰€æœ‰PDFæ–‡ä»¶
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                continue
            
            # é è™•ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
            docs_info = run_preprocessing(pdf_files)
            if not docs_info:
                print("âŒ é è™•ç†å¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæå–")
                continue
            
            # åŸ·è¡Œå¢å¼·ç‰ˆæå–
            results = run_enhanced_extraction(docs_info)
            if results:
                print(f"\nğŸ‰ å¢å¼·ç‰ˆæå–å®Œæˆï¼ç”Ÿæˆäº† {len(results)} å€‹çµæœæ–‡ä»¶")
                
                excel_count = 0
                word_count = 0
                
                for pdf_path, (extractions, summary, excel_path, word_path) in results.items():
                    print(f"ğŸ“Š {summary.company_name} ({summary.stock_code}) - {summary.report_year}: {len(extractions)} å€‹çµæœ")
                    print(f"   ğŸ“„ Excel: {Path(excel_path).name}")
                    if word_path:
                        print(f"   ğŸ“„ Word: {Path(word_path).name}")
                        word_count += 1
                    excel_count += 1
                
                print(f"\nğŸ“ˆ ç¸½è¨ˆè¼¸å‡º: {excel_count} å€‹Excelæ–‡ä»¶, {word_count} å€‹Wordæ–‡ä»¶")
                
                # è©¢å•æ˜¯å¦ç«‹å³å½™æ•´
                if len(results) > 1:
                    consolidate_now = input("\næ˜¯å¦ç«‹å³åŸ·è¡Œå½™æ•´åŠŸèƒ½ï¼Ÿ(y/n): ").strip().lower()
                    if consolidate_now == 'y':
                        result_path = run_consolidation()
                        if result_path:
                            print(f"ğŸ”— å½™æ•´å®Œæˆ: {Path(result_path).name}")
            
        elif choice == "2":
            # é‡æ–°é è™•ç†PDF
            print("\nğŸ”„ é‡æ–°é è™•ç†PDF...")
            
            has_pdfs, pdf_files = find_pdf_files()
            if not has_pdfs:
                continue
            
            print(f"å°‡è™•ç† {len(pdf_files)} å€‹PDFæ–‡ä»¶ï¼š")
            for pdf_file in pdf_files:
                print(f"  - {pdf_file.name}")
            
            confirm = input("é€™å°‡é‡æ–°å»ºç«‹æ‰€æœ‰å‘é‡è³‡æ–™åº«ï¼Œç¢ºå®šç¹¼çºŒï¼Ÿ(y/n): ").strip().lower()
            if confirm == 'y':
                docs_info = run_preprocessing(pdf_files, force=True)
                if docs_info:
                    print("âœ… é è™•ç†å®Œæˆï¼Œç¾åœ¨å¯ä»¥åŸ·è¡Œæ•¸æ“šæå–")
            
        elif choice == "3":
            # å½™æ•´å¤šå…¬å¸çµæœ
            print("\nğŸ”— æº–å‚™å½™æ•´å¤šå…¬å¸çµæœ...")
            
            result_path = run_consolidation()
            if result_path:
                print(f"\nğŸ‰ å½™æ•´åŠŸèƒ½åŸ·è¡Œå®Œæˆï¼")
                print(f"ğŸ“Š å½™æ•´æª”æ¡ˆ: {Path(result_path).name}")
                print(f"ğŸ“ å­˜æ”¾ä½ç½®: {RESULTS_PATH}")
            else:
                print("âŒ å½™æ•´åŠŸèƒ½åŸ·è¡Œå¤±æ•—")
                print("ğŸ’¡ è«‹ç¢ºä¿å·²åŸ·è¡Œéè³‡æ–™æå–åŠŸèƒ½")
            
        elif choice == "4":
            # æŸ¥çœ‹æœ€æ–°çµæœ
            show_latest_results()
            
        elif choice == "5":
            # é¡¯ç¤ºç³»çµ±ä¿¡æ¯
            show_system_info()
            
        elif choice == "6":
            # ä½¿ç”¨èªªæ˜
            show_usage_guide()
            
        elif choice == "7":
            # é€€å‡º
            print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ESGå ±å‘Šæ›¸æå–å™¨ v2.0ï¼")
            break
            
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥1-7ä¹‹é–“çš„æ•¸å­—")

def command_line_mode():
    """å‘½ä»¤è¡Œæ¨¡å¼"""
    parser = argparse.ArgumentParser(
        description="ESGå ±å‘Šæ›¸æå–å™¨ v2.0 - å¢å¼·ç‰ˆï¼Œæ”¯æŒæ–°é—œéµå­—å’ŒWordè¼¸å‡º",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python main.py                      # äº’å‹•æ¨¡å¼
  python main.py --auto               # è‡ªå‹•åŸ·è¡Œå®Œæ•´æµç¨‹
  python main.py --preprocess         # åƒ…é è™•ç†
  python main.py --extract            # åƒ…æ•¸æ“šæå–ï¼ˆå¢å¼·ç‰ˆï¼‰
  python main.py --consolidate        # åƒ…å½™æ•´åŠŸèƒ½
  python main.py --force              # å¼·åˆ¶é‡æ–°é è™•ç†
  python main.py --results            # æŸ¥çœ‹çµæœ
        """
    )
    
    parser.add_argument("--auto", action="store_true", help="è‡ªå‹•åŸ·è¡Œå®Œæ•´æµç¨‹")
    parser.add_argument("--preprocess", action="store_true", help="é è™•ç†æ‰€æœ‰PDFæ–‡ä»¶")
    parser.add_argument("--extract", action="store_true", help="åŸ·è¡Œå¢å¼·ç‰ˆESGæ•¸æ“šæå–")
    parser.add_argument("--consolidate", action="store_true", help="åŸ·è¡Œå½™æ•´åŠŸèƒ½")
    parser.add_argument("--force", action="store_true", help="å¼·åˆ¶é‡æ–°é è™•ç†")
    parser.add_argument("--results", action="store_true", help="æŸ¥çœ‹æœ€æ–°çµæœ")
    parser.add_argument("--max-docs", type=int, default=None, help="æœ€å¤§è™•ç†æ–‡æª”æ•¸")
    
    args = parser.parse_args()
    
    # æ ¹æ“šåƒæ•¸åŸ·è¡Œå°æ‡‰åŠŸèƒ½
    if args.auto:
        # è‡ªå‹•åŸ·è¡Œå®Œæ•´æµç¨‹
        print("ğŸ“Š å¢å¼·ç‰ˆè‡ªå‹•åŸ·è¡Œæ¨¡å¼")
        if not check_environment():
            sys.exit(1)
        
        has_pdfs, pdf_files = find_pdf_files()
        if not has_pdfs:
            sys.exit(1)
        
        print("åŸ·è¡Œé è™•ç†...")
        docs_info = run_preprocessing(pdf_files, force=args.force)
        if not docs_info:
            sys.exit(1)
        
        print("åŸ·è¡Œå¢å¼·ç‰ˆESGæ•¸æ“šæå–...")
        results = run_enhanced_extraction(docs_info, args.max_docs)
        if results:
            excel_count = sum(1 for _ in results)
            word_count = sum(1 for _, (_, _, _, word_path) in results.items() if word_path)
            print(f"âœ… å¢å¼·ç‰ˆæå–å®Œæˆï¼ç”Ÿæˆäº† {excel_count} å€‹Excelæ–‡ä»¶å’Œ {word_count} å€‹Wordæ–‡ä»¶")
            
            # è‡ªå‹•åŸ·è¡Œå½™æ•´
            if len(results) > 1:
                print("\nåŸ·è¡Œå½™æ•´åŠŸèƒ½...")
                result_path = run_consolidation()
                if result_path:
                    print(f"ğŸ”— å½™æ•´å®Œæˆ: {Path(result_path).name}")
        else:
            sys.exit(1)
            
    elif args.preprocess:
        has_pdfs, pdf_files = find_pdf_files()
        if not has_pdfs:
            sys.exit(1)
        
        docs_info = run_preprocessing(pdf_files, force=args.force)
        if docs_info:
            print("âœ… é è™•ç†å®Œæˆ")
        else:
            sys.exit(1)
            
    elif args.extract:
        has_pdfs, pdf_files = find_pdf_files()
        if not has_pdfs:
            sys.exit(1)
        
        docs_info = run_preprocessing(pdf_files, force=False)
        if not docs_info:
            print("âŒ éœ€è¦å…ˆåŸ·è¡Œé è™•ç†")
            sys.exit(1)
        
        results = run_enhanced_extraction(docs_info, args.max_docs)
        if not results:
            sys.exit(1)
    
    elif args.consolidate:
        # åƒ…åŸ·è¡Œå½™æ•´
        print("ğŸ”— å½™æ•´åŠŸèƒ½æ¨¡å¼")
        result_path = run_consolidation()
        if result_path:
            print(f"âœ… å½™æ•´å®Œæˆ: {Path(result_path).name}")
        else:
            sys.exit(1)
            
    elif args.results:
        show_latest_results()
        
    else:
        # æ²’æœ‰åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©
        parser.print_help()

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ“Š ESGå ±å‘Šæ›¸æå–å™¨ v2.0 (å¢å¼·ç‰ˆ)")
    print("å°ˆæ¥­æå–ESGå ±å‘Šä¸­çš„å†ç”Ÿææ–™å’Œå¾ªç’°ç¶“æ¿Ÿæ•¸æ“š")
    print("ğŸ†• æ–°åŠŸèƒ½ï¼šæ–°é—œéµå­—é…ç½® + è‚¡ç¥¨ä»£è™Ÿè­˜åˆ¥ + Wordè¼¸å‡º")
    print("=" * 60)
    
    # æ ¹æ“šå‘½ä»¤è¡Œåƒæ•¸æ±ºå®šé‹è¡Œæ¨¡å¼
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        command_line_mode()
    else:
        # äº’å‹•æ¨¡å¼
        try:
            interactive_menu()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·ï¼Œç³»çµ±é€€å‡º")
        except Exception as e:
            print(f"\nâŒ ç³»çµ±éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()