import time
import random
from typing import List, Optional
from datetime import datetime, timedelta
from langchain_google_genai import ChatGoogleGenerativeAI
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted, ServiceUnavailable, TooManyRequests

class GeminiAPIManager:
    """Gemini APIå¤škeyç®¡ç†å™¨ï¼Œæ”¯æŒè‡ªå‹•è¼ªæ›å’Œé€Ÿç‡é™åˆ¶è™•ç†"""
    
    def __init__(self, api_keys: List[str], model_name: str = "models/gemini-1.5-flash"):
        """
        åˆå§‹åŒ–APIç®¡ç†å™¨
        
        Args:
            api_keys: API keyåˆ—è¡¨
            model_name: Geminiæ¨¡å‹åç¨±
        """
        self.api_keys = api_keys
        self.model_name = model_name
        self.current_key_index = 0
        self.key_cooldowns = {}  # è¨˜éŒ„æ¯å€‹keyçš„å†·å»æ™‚é–“
        self.key_usage_count = {key: 0 for key in api_keys}  # è¨˜éŒ„æ¯å€‹keyçš„ä½¿ç”¨æ¬¡æ•¸
        self.last_request_time = 0
        self.min_request_interval = 1.0  # æœ€å°è«‹æ±‚é–“éš”ï¼ˆç§’ï¼‰
        
        print(f"ğŸ”‘ åˆå§‹åŒ–Gemini APIç®¡ç†å™¨ï¼Œå…±æœ‰ {len(api_keys)} å€‹API key")
        self._initialize_current_llm()
    
    def _initialize_current_llm(self):
        """åˆå§‹åŒ–ç•¶å‰çš„LLMå¯¦ä¾‹"""
        current_key = self.api_keys[self.current_key_index]
        self.current_llm = ChatGoogleGenerativeAI(
            model=self.model_name,
            google_api_key=current_key,
            temperature=0,
            convert_system_message_to_human=True
        )
        print(f"ğŸ¯ ç•¶å‰ä½¿ç”¨API key: {current_key[:10]}... (ç¬¬{self.current_key_index + 1}å€‹)")
    
    def _is_key_available(self, key_index: int) -> bool:
        """æª¢æŸ¥æŒ‡å®šçš„API keyæ˜¯å¦å¯ç”¨"""
        key = self.api_keys[key_index]
        
        # æª¢æŸ¥æ˜¯å¦åœ¨å†·å»æœŸ
        if key in self.key_cooldowns:
            if datetime.now() < self.key_cooldowns[key]:
                remaining = (self.key_cooldowns[key] - datetime.now()).total_seconds()
                print(f"â³ API key {key[:10]}... é‚„åœ¨å†·å»æœŸï¼Œå‰©é¤˜ {remaining:.1f} ç§’")
                return False
        
        return True
    
    def _get_next_available_key(self) -> Optional[int]:
        """ç²å–ä¸‹ä¸€å€‹å¯ç”¨çš„API keyç´¢å¼•"""
        # å¾ç•¶å‰keyçš„ä¸‹ä¸€å€‹é–‹å§‹å°‹æ‰¾
        for i in range(len(self.api_keys)):
            key_index = (self.current_key_index + i + 1) % len(self.api_keys)
            if self._is_key_available(key_index):
                return key_index
        
        return None
    
    def _switch_to_next_key(self) -> bool:
        """åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å¯ç”¨çš„API key"""
        next_key_index = self._get_next_available_key()
        
        if next_key_index is None:
            print("âš ï¸ æ‰€æœ‰API keyéƒ½ä¸å¯ç”¨")
            return False
        
        old_index = self.current_key_index
        self.current_key_index = next_key_index
        self._initialize_current_llm()
        
        print(f"ğŸ”„ åˆ‡æ›API key: ç¬¬{old_index + 1}å€‹ â†’ ç¬¬{next_key_index + 1}å€‹")
        return True
    
    def _set_key_cooldown(self, key_index: int, cooldown_minutes: int = 1):
        """è¨­ç½®API keyçš„å†·å»æ™‚é–“"""
        key = self.api_keys[key_index]
        cooldown_until = datetime.now() + timedelta(minutes=cooldown_minutes)
        self.key_cooldowns[key] = cooldown_until
        
        print(f"â„ï¸ API key {key[:10]}... é€²å…¥å†·å»æœŸ {cooldown_minutes} åˆ†é˜")
    
    def _wait_for_all_keys_available(self):
        """ç­‰å¾…æ‰€æœ‰API keyå¯ç”¨"""
        print("ğŸ›‘ æ‰€æœ‰API keyéƒ½å·²é”åˆ°é™åˆ¶")
        
        # è¨ˆç®—æœ€çŸ­ç­‰å¾…æ™‚é–“
        min_wait_time = 10 * 60  # é è¨­10åˆ†é˜
        
        if self.key_cooldowns:
            # æ‰¾åˆ°æœ€å¿«å¯ç”¨çš„keyçš„æ™‚é–“
            min_cooldown = min(self.key_cooldowns.values())
            wait_seconds = max((min_cooldown - datetime.now()).total_seconds(), min_wait_time)
        else:
            wait_seconds = min_wait_time
        
        print(f"â° ç­‰å¾… {wait_seconds/60:.1f} åˆ†é˜å¾Œé‡è©¦...")
        
        # é¡¯ç¤ºå€’è¨ˆæ™‚
        for remaining in range(int(wait_seconds), 0, -30):
            print(f"â³ å‰©é¤˜ç­‰å¾…æ™‚é–“: {remaining//60}åˆ†{remaining%60}ç§’...")
            time.sleep(min(30, remaining))
        
        # æ¸…é™¤æ‰€æœ‰å†·å»æ™‚é–“
        self.key_cooldowns.clear()
        print("âœ… ç­‰å¾…å®Œæˆï¼Œé‡ç½®æ‰€æœ‰API keyç‹€æ…‹")
    
    def _handle_rate_limit_error(self, error):
        """è™•ç†é€Ÿç‡é™åˆ¶éŒ¯èª¤"""
        error_str = str(error).lower()
        
        if "quota exceeded" in error_str or "rate limit" in error_str:
            print(f"ğŸš« API keyé”åˆ°é€Ÿç‡é™åˆ¶: {error}")
            
            # è¨­ç½®ç•¶å‰keyçš„å†·å»æ™‚é–“
            self._set_key_cooldown(self.current_key_index, cooldown_minutes=2)
            
            # å˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹key
            if self._switch_to_next_key():
                return True
            else:
                # æ‰€æœ‰keyéƒ½ä¸å¯ç”¨ï¼Œç­‰å¾…
                self._wait_for_all_keys_available()
                self.current_key_index = 0
                self._initialize_current_llm()
                return True
        
        return False
    
    def _add_request_delay(self):
        """æ·»åŠ è«‹æ±‚é–“éš”ä»¥é¿å…éæ–¼é »ç¹çš„è«‹æ±‚"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            sleep_time = self.min_request_interval - time_since_last
            # æ·»åŠ éš¨æ©Ÿå»¶é²ä»¥é¿å…æ‰€æœ‰è«‹æ±‚åŒæ™‚ç™¼é€
            sleep_time += random.uniform(0, 0.5)
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def invoke(self, prompt: str, max_retries: int = 3) -> str:
        """
        èª¿ç”¨Gemini APIï¼Œæ”¯æŒè‡ªå‹•é‡è©¦å’Œkeyè¼ªæ›
        
        Args:
            prompt: è¼¸å…¥æç¤º
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            
        Returns:
            APIéŸ¿æ‡‰å…§å®¹
        """
        
        for attempt in range(max_retries):
            try:
                # æ·»åŠ è«‹æ±‚å»¶é²
                self._add_request_delay()
                
                # è¨˜éŒ„ä½¿ç”¨æ¬¡æ•¸
                current_key = self.api_keys[self.current_key_index]
                self.key_usage_count[current_key] += 1
                
                # èª¿ç”¨API
                response = self.current_llm.invoke(prompt)
                
                # æˆåŠŸå‰‡è¿”å›çµæœ
                print(f"âœ… APIèª¿ç”¨æˆåŠŸ (key {self.current_key_index + 1}, ç¬¬{self.key_usage_count[current_key]}æ¬¡ä½¿ç”¨)")
                return response
                
            except (ResourceExhausted, TooManyRequests, ServiceUnavailable) as e:
                print(f"âš ï¸ APIé™åˆ¶éŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{max_retries}): {e}")
                
                # è™•ç†é€Ÿç‡é™åˆ¶
                if self._handle_rate_limit_error(e):
                    continue
                else:
                    raise e
                    
            except Exception as e:
                print(f"âŒ APIèª¿ç”¨éŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{max_retries}): {e}")
                
                if attempt == max_retries - 1:
                    raise e
                
                # ç­‰å¾…å¾Œé‡è©¦
                wait_time = (attempt + 1) * 2
                print(f"â³ ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                time.sleep(wait_time)
        
        raise Exception("æ‰€æœ‰é‡è©¦å˜—è©¦éƒ½å¤±æ•—äº†")
    
    def get_usage_statistics(self) -> dict:
        """ç²å–APIä½¿ç”¨çµ±è¨ˆ"""
        total_usage = sum(self.key_usage_count.values())
        
        stats = {
            "total_requests": total_usage,
            "keys_usage": {}
        }
        
        for i, key in enumerate(self.api_keys):
            usage = self.key_usage_count[key]
            stats["keys_usage"][f"key_{i+1}"] = {
                "key_preview": key[:10] + "...",
                "usage_count": usage,
                "usage_percentage": (usage / total_usage * 100) if total_usage > 0 else 0,
                "is_cooling": key in self.key_cooldowns
            }
        
        return stats
    
    def print_usage_statistics(self):
        """æ‰“å°APIä½¿ç”¨çµ±è¨ˆ"""
        stats = self.get_usage_statistics()
        
        print("\n" + "="*50)
        print("ğŸ“Š APIä½¿ç”¨çµ±è¨ˆ")
        print("="*50)
        print(f"ç¸½è«‹æ±‚æ¬¡æ•¸: {stats['total_requests']}")
        
        for key_name, key_stats in stats["keys_usage"].items():
            status = "â„ï¸ å†·å»ä¸­" if key_stats["is_cooling"] else "âœ… å¯ç”¨"
            print(f"{key_name}: {key_stats['usage_count']} æ¬¡ ({key_stats['usage_percentage']:.1f}%) {status}")
        
        print("="*50)

# é…ç½®ä½ çš„API keys
GEMINI_API_KEYS = [
    "AIzaSyAR8oJDZrvL6C44opQrm23xfepIZEVJyGI",
    "AIzaSyDQs4bJr4VHcO5XZMHM5Gg3GKVSi7hifoU", 
    "AIzaSyBP3g6Ovbi0tgH2cekw3oUdrF-HoC3MLRQ",
    "AIzaSyAM3Bn9USN6lIymEW9BwZfscY2H8eKPPvw"
]

def create_api_manager(model_name: str = "models/gemini-1.5-flash") -> GeminiAPIManager:
    """å‰µå»ºAPIç®¡ç†å™¨å¯¦ä¾‹"""
    return GeminiAPIManager(GEMINI_API_KEYS, model_name)