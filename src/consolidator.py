#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESGè³‡æ–™å½™æ•´æ¨¡çµ„ v1.0
å°‡å¤šå€‹Excelæª”æ¡ˆå½™æ•´æˆä¸€å€‹ç¸½è¦½è¡¨
"""

import os
import re
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from difflib import SequenceMatcher

class CompanyNameStandardizer:
    """å…¬å¸åç¨±æ¨™æº–åŒ–è™•ç†å™¨"""
    
    def __init__(self):
        # å¸¸è¦‹çš„å…¬å¸å¾Œç¶´è©ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰
        self.company_suffixes = [
            "è‚¡ä»½æœ‰é™å…¬å¸", "æœ‰é™å…¬å¸", "è‚¡ä»½", "å…¬å¸", 
            "å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "å·¥æ¥­æœ‰é™å…¬å¸", "å·¥æ¥­è‚¡ä»½", "å·¥æ¥­å…¬å¸", "å·¥æ¥­",
            "åŒ–å­¸å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "åŒ–å­¸å·¥æ¥­æœ‰é™å…¬å¸", "åŒ–å­¸å·¥æ¥­è‚¡ä»½", "åŒ–å­¸å·¥æ¥­", "åŒ–å­¸",
            "å¡‘è† å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "å¡‘è† å·¥æ¥­æœ‰é™å…¬å¸", "å¡‘è† å·¥æ¥­è‚¡ä»½", "å¡‘è† å·¥æ¥­", "å¡‘è† ",
            "é›»å­è‚¡ä»½æœ‰é™å…¬å¸", "é›»å­æœ‰é™å…¬å¸", "é›»å­è‚¡ä»½", "é›»å­å…¬å¸", "é›»å­",
            "ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸", "ç§‘æŠ€æœ‰é™å…¬å¸", "ç§‘æŠ€è‚¡ä»½", "ç§‘æŠ€å…¬å¸", "ç§‘æŠ€"
        ]
        
        # æ¨™æº–åŒ–æ˜ å°„è¡¨ï¼ˆæ‰‹å‹•å®šç¾©çš„ç‰¹æ®Šæ¡ˆä¾‹ï¼‰
        self.manual_mappings = {
            # å¯ä»¥åœ¨é€™è£¡æ·»åŠ ç‰¹æ®Šçš„æ‰‹å‹•æ˜ å°„
            # "åŸå§‹åç¨±": "æ¨™æº–åç¨±"
        }
        
        # å…¬å¸åç¨±ç·©å­˜
        self.standardization_cache = {}
    
    def extract_core_name(self, company_name: str) -> str:
        """æå–å…¬å¸æ ¸å¿ƒåç¨±ï¼ˆå»é™¤å¾Œç¶´ï¼‰"""
        if not company_name or company_name == "æœªçŸ¥å…¬å¸":
            return company_name
        
        # æ¸…ç†ç©ºç™½
        name = company_name.strip()
        
        # æª¢æŸ¥æ‰‹å‹•æ˜ å°„
        if name in self.manual_mappings:
            return self.manual_mappings[name]
        
        # æŒ‰å„ªå…ˆç´šå»é™¤å¾Œç¶´
        for suffix in self.company_suffixes:
            if name.endswith(suffix):
                core_name = name[:-len(suffix)].strip()
                if core_name:  # ç¢ºä¿å»é™¤å¾Œç¶´å¾Œé‚„æœ‰å…§å®¹
                    return core_name
        
        return name
    
    def calculate_similarity(self, name1: str, name2: str) -> float:
        """è¨ˆç®—å…©å€‹å…¬å¸åç¨±çš„ç›¸ä¼¼åº¦"""
        if not name1 or not name2:
            return 0.0
        
        # æå–æ ¸å¿ƒåç¨±
        core1 = self.extract_core_name(name1)
        core2 = self.extract_core_name(name2)
        
        # å®Œå…¨åŒ¹é…
        if core1 == core2:
            return 1.0
        
        # ä¸€å€‹æ˜¯å¦ä¸€å€‹çš„å­å­—ç¬¦ä¸²
        if core1 in core2 or core2 in core1:
            return 0.9
        
        # è¨ˆç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, core1, core2).ratio()
        
        return similarity
    
    def find_best_match(self, target_name: str, existing_names: List[str], threshold: float = 0.8) -> Tuple[str, float]:
        """æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„ç¾æœ‰å…¬å¸åç¨±"""
        if not existing_names:
            return target_name, 1.0
        
        best_match = target_name
        best_similarity = 0.0
        
        for existing_name in existing_names:
            similarity = self.calculate_similarity(target_name, existing_name)
            if similarity > best_similarity and similarity >= threshold:
                best_similarity = similarity
                best_match = existing_name
        
        return best_match, best_similarity
    
    def choose_standard_name(self, similar_names: List[str]) -> str:
        """å¾ç›¸ä¼¼çš„åç¨±ä¸­é¸æ“‡æ¨™æº–åç¨±ï¼ˆæœ€å®Œæ•´çš„ï¼‰"""
        if not similar_names:
            return "æœªçŸ¥å…¬å¸"
        
        if len(similar_names) == 1:
            return similar_names[0]
        
        # å„ªå…ˆé¸æ“‡æœ€é•·çš„åç¨±ï¼ˆé€šå¸¸æœ€å®Œæ•´ï¼‰
        longest_name = max(similar_names, key=len)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åŒ…å«"è‚¡ä»½æœ‰é™å…¬å¸"çš„å®Œæ•´åç¨±
        for name in similar_names:
            if "è‚¡ä»½æœ‰é™å…¬å¸" in name:
                return name
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åŒ…å«"æœ‰é™å…¬å¸"çš„åç¨±
        for name in similar_names:
            if "æœ‰é™å…¬å¸" in name:
                return name
        
        return longest_name

class ESGDataConsolidator:
    """
    ESGè³‡æ–™å½™æ•´å™¨
    
    åŠŸèƒ½ï¼š
    - è‡ªå‹•æƒæresultsç›®éŒ„ä¸‹çš„æ‰€æœ‰Excelæª”æ¡ˆ
    - æ’é™¤æª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆ
    - æ™ºèƒ½è­˜åˆ¥åŒä¸€å…¬å¸çš„ä¸åŒå‘½åæ–¹å¼
    - æŒ‰å¹´åº¦å’Œå…¬å¸åˆ†çµ„ç”Ÿæˆå½™æ•´å ±å‘Š
    - åŒ…å«çµ±è¨ˆæ‘˜è¦å’Œç¾åŒ–æ ¼å¼
    """
    
    def __init__(self, results_path: str):
        self.results_path = Path(results_path)
        self.name_standardizer = CompanyNameStandardizer()
        self.company_mapping = {}  # åŸå§‹åç¨± -> æ¨™æº–åç¨±çš„æ˜ å°„
        
        print(f"ğŸ“Š åˆå§‹åŒ–ESGè³‡æ–™å½™æ•´å™¨")
        print(f"ğŸ“ çµæœç›®éŒ„: {self.results_path}")
        print(f"âš ï¸ æ³¨æ„ï¼šæª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå°‡è¢«è‡ªå‹•æ’é™¤")
        print(f"ğŸ¢ æ™ºèƒ½è­˜åˆ¥ï¼šåŒä¸€å…¬å¸çš„ä¸åŒå‘½åå°‡è‡ªå‹•çµ±ä¸€")
    
    def _standardize_company_names(self, all_data: List[Dict]) -> List[Dict]:
        """æ¨™æº–åŒ–æ‰€æœ‰å…¬å¸åç¨±ï¼Œå°‡ç›¸ä¼¼çš„å…¬å¸åç¨±çµ±ä¸€"""
        if not all_data:
            return all_data
        
        print("ğŸ¢ é–‹å§‹æ¨™æº–åŒ–å…¬å¸åç¨±...")
        
        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„å…¬å¸åç¨±
        unique_companies = list(set(item['company_name'] for item in all_data if item['company_name'] != "æœªçŸ¥å…¬å¸"))
        
        if not unique_companies:
            return all_data
        
        print(f"   ç™¼ç¾ {len(unique_companies)} å€‹ä¸åŒçš„å…¬å¸åç¨±")
        
        # å»ºç«‹æ¨™æº–åŒ–æ˜ å°„
        processed_companies = []
        
        for company in unique_companies:
            if company in self.company_mapping:
                continue  # å·²è™•ç†é
            
            # å°‹æ‰¾ç›¸ä¼¼çš„å…¬å¸åç¨±
            similar_companies = [company]
            
            for other_company in unique_companies:
                if other_company != company and other_company not in processed_companies:
                    similarity = self.name_standardizer.calculate_similarity(company, other_company)
                    if similarity >= 0.8:  # ç›¸ä¼¼åº¦é–¾å€¼
                        similar_companies.append(other_company)
            
            # é¸æ“‡æ¨™æº–åç¨±
            standard_name = self.name_standardizer.choose_standard_name(similar_companies)
            
            # å»ºç«‹æ˜ å°„
            for similar_company in similar_companies:
                self.company_mapping[similar_company] = standard_name
                processed_companies.append(similar_company)
                
                # å¦‚æœæœ‰çµ±ä¸€ï¼Œé¡¯ç¤ºä¿¡æ¯
                if similar_company != standard_name:
                    print(f"   ğŸ”— {similar_company} â†’ {standard_name}")
        
        # æ‡‰ç”¨æ¨™æº–åŒ–
        standardized_data = []
        for item in all_data:
            new_item = item.copy()
            original_name = item['company_name']
            if original_name in self.company_mapping:
                new_item['company_name'] = self.company_mapping[original_name]
                # ä¿ç•™åŸå§‹åç¨±ç”¨æ–¼è¿½è¸ª
                new_item['original_company_name'] = original_name
            standardized_data.append(new_item)
        
        # çµ±è¨ˆæ¨™æº–åŒ–çµæœ
        final_companies = set(item['company_name'] for item in standardized_data if item['company_name'] != "æœªçŸ¥å…¬å¸")
        print(f"   âœ… æ¨™æº–åŒ–å®Œæˆ: {len(unique_companies)} â†’ {len(final_companies)} å€‹å…¬å¸")
        
        return standardized_data
        """å½™æ•´æ‰€æœ‰çµæœåˆ°ä¸€å€‹Excelæª”æ¡ˆï¼Œæ’é™¤'ç„¡æå–'æª”æ¡ˆ"""
        print("\nğŸš€ é–‹å§‹å½™æ•´æ‰€æœ‰ESGæå–çµæœ...")
        print("=" * 60)
        
        # 1. æƒæä¸¦åˆ†ææ‰€æœ‰Excelæª”æ¡ˆï¼ˆæ’é™¤'ç„¡æå–'ï¼‰
        excel_files = self._scan_excel_files()
        if not excel_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„Excelçµæœæª”æ¡ˆ")
            print("ğŸ’¡ æç¤ºï¼šåŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå·²è‡ªå‹•æ’é™¤")
            return None
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(excel_files)} å€‹æœ‰æ•ˆExcelçµæœæª”æ¡ˆï¼ˆå·²æ’é™¤'ç„¡æå–'æª”æ¡ˆï¼‰")
        
        # 2. è§£ææª”æ¡ˆä¿¡æ¯
        parsed_files = self._parse_file_info(excel_files)
        print(f"âœ… æˆåŠŸè§£æ {len(parsed_files)} å€‹æª”æ¡ˆ")
        
        # 3. è¼‰å…¥æ‰€æœ‰è³‡æ–™
        all_data = self._load_all_data(parsed_files)
        print(f"ğŸ“š è¼‰å…¥å®Œæˆï¼Œå…± {len(all_data)} ç­†è³‡æ–™")
        
        # 4. ç”Ÿæˆå½™æ•´å ±å‘Š
        output_path = self._create_consolidated_excel(all_data, parsed_files)
        
        print(f"âœ… å½™æ•´å®Œæˆï¼")
        print(f"ğŸ“Š è¼¸å‡ºæª”æ¡ˆ: {output_path}")
        
        return output_path
    
    def _scan_excel_files(self) -> List[Path]:
        """æƒææ‰€æœ‰Excelæª”æ¡ˆï¼Œæ’é™¤åŒ…å«'ç„¡æå–'çš„æª”æ¡ˆ"""
        excel_files = []
        excluded_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæª”æ¡ˆï¼ˆåŒ…æ‹¬ä¸åŒç‰ˆæœ¬ï¼‰
        patterns = [
            "ESGæå–çµæœ_*.xlsx",
            "*å¹³è¡¡ç‰ˆ*.xlsx", 
            "*é«˜ç²¾åº¦*.xlsx"
        ]
        
        for pattern in patterns:
            files = list(self.results_path.glob(pattern))
            for file in files:
                # æª¢æŸ¥æª”åæ˜¯å¦åŒ…å«"ç„¡æå–"
                if "ç„¡æå–" in file.name:
                    excluded_files.append(file)
                    print(f"   âŠ— æ’é™¤æª”æ¡ˆ: {file.name} (åŒ…å«'ç„¡æå–')")
                else:
                    excel_files.append(file)
        
        # é¡¯ç¤ºæ’é™¤çµ±è¨ˆ
        if excluded_files:
            print(f"ğŸ“‹ æ’é™¤äº† {len(excluded_files)} å€‹'ç„¡æå–'æª”æ¡ˆ")
        
        # å»é‡ä¸¦æ’åº
        unique_files = list(set(excel_files))
        unique_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        return unique_files
    
    def _parse_file_info(self, excel_files: List[Path]) -> List[Dict]:
        """è§£ææª”æ¡ˆä¿¡æ¯"""
        parsed_files = []
        
        for file_path in excel_files:
            try:
                # å¾æª”åè§£æåŸºæœ¬ä¿¡æ¯
                filename = file_path.stem
                
                # è§£æå¹´åº¦
                year_match = re.search(r'(202[0-9])', filename)
                year = year_match.group(1) if year_match else "æœªçŸ¥å¹´åº¦"
                
                # è§£æç‰ˆæœ¬
                if "å¹³è¡¡ç‰ˆ" in filename:
                    version = "å¹³è¡¡ç‰ˆ"
                elif "é«˜ç²¾åº¦" in filename:
                    version = "é«˜ç²¾åº¦ç‰ˆ"
                else:
                    version = "æ¨™æº–ç‰ˆ"
                
                # å˜—è©¦å¾Excelå…§å®¹ä¸­è®€å–æ›´è©³ç´°çš„ä¿¡æ¯
                company_name, report_year = self._extract_company_info_from_excel(file_path)
                
                parsed_files.append({
                    'file_path': file_path,
                    'filename': filename,
                    'company_name': company_name,
                    'report_year': report_year or year,
                    'version': version,
                    'file_time': datetime.fromtimestamp(file_path.stat().st_mtime)
                })
                
                print(f"   âœ“ {company_name} - {report_year or year} ({version})")
                
            except Exception as e:
                print(f"   âš ï¸ è§£æå¤±æ•— {file_path.name}: {e}")
                continue
        
        return parsed_files
    
    def _extract_company_info_from_excel(self, file_path: Path) -> Tuple[str, str]:
        """å¾Excelæª”æ¡ˆä¸­æå–å…¬å¸åç¨±å’Œå¹´åº¦"""
        try:
            # è®€å–ç¬¬ä¸€å€‹å·¥ä½œè¡¨çš„å‰å¹¾è¡Œ
            df = pd.read_excel(file_path, nrows=5)
            
            company_name = "æœªçŸ¥å…¬å¸"
            report_year = ""
            
            # æŸ¥æ‰¾å…¬å¸ä¿¡æ¯
            for col in df.columns:
                for idx, row in df.iterrows():
                    cell_value = str(row[col])
                    
                    # æå–å…¬å¸åç¨±
                    if "å…¬å¸:" in cell_value:
                        company_match = re.search(r'å…¬å¸:\s*(.+)', cell_value)
                        if company_match:
                            company_name = company_match.group(1).strip()
                    
                    # æå–å ±å‘Šå¹´åº¦
                    if "å ±å‘Šå¹´åº¦:" in cell_value:
                        year_match = re.search(r'å ±å‘Šå¹´åº¦:\s*(202[0-9])', cell_value)
                        if year_match:
                            report_year = year_match.group(1)
            
            return company_name, report_year
            
        except Exception as e:
            print(f"   âš ï¸ è®€å–Excelå¤±æ•—: {e}")
            return "æœªçŸ¥å…¬å¸", ""
    
    def _load_all_data(self, parsed_files: List[Dict]) -> List[Dict]:
        """è¼‰å…¥æ‰€æœ‰è³‡æ–™"""
        all_data = []
        
        for file_info in parsed_files:
            try:
                file_path = file_info['file_path']
                
                # å˜—è©¦è®€å–ä¸åŒçš„å·¥ä½œè¡¨åç¨±
                sheet_names_to_try = [
                    'å¹³è¡¡ç‰ˆæå–çµæœ', 'æå–çµæœ', 'Sheet1', 0
                ]
                
                df = None
                for sheet_name in sheet_names_to_try:
                    try:
                        df = pd.read_excel(file_path, sheet_name=sheet_name)
                        break
                    except:
                        continue
                
                if df is None:
                    print(f"   âš ï¸ ç„¡æ³•è®€å– {file_path.name}")
                    continue
                
                # è·³éæ¨™é¡Œè¡Œï¼ˆå‰2è¡Œé€šå¸¸æ˜¯å…¬å¸ä¿¡æ¯å’Œç©ºè¡Œï¼‰
                data_start_row = 0
                for idx, row in df.iterrows():
                    if idx < 5:  # æª¢æŸ¥å‰5è¡Œ
                        first_cell = str(row.iloc[0]) if len(row) > 0 else ""
                        if "å…¬å¸:" not in first_cell and first_cell.strip() and first_cell != "nan":
                            data_start_row = idx
                            break
                
                if data_start_row < len(df):
                    df = df.iloc[data_start_row:]
                
                # ç‚ºæ¯ä¸€è¡Œæ·»åŠ æª”æ¡ˆä¿¡æ¯
                for idx, row in df.iterrows():
                    if len(row) > 0 and str(row.iloc[0]).strip() and str(row.iloc[0]) != "nan":
                        data_row = {
                            'company_name': file_info['company_name'],
                            'report_year': file_info['report_year'],
                            'version': file_info['version'],
                            'file_name': file_info['filename'],
                            'source_file': file_path.name
                        }
                        
                        # æ·»åŠ åŸå§‹æ•¸æ“šåˆ—
                        for col_idx, col_name in enumerate(df.columns):
                            if col_idx < len(row):
                                data_row[col_name] = row.iloc[col_idx]
                        
                        all_data.append(data_row)
                
                print(f"   âœ“ è¼‰å…¥ {file_info['company_name']} - {file_info['report_year']} ({len(df)} ç­†)")
                
            except Exception as e:
                print(f"   âŒ è¼‰å…¥å¤±æ•— {file_info['file_path'].name}: {e}")
                continue
        
        return all_data
    
    def _create_consolidated_excel(self, all_data: List[Dict], parsed_files: List[Dict]) -> str:
        """å‰µå»ºå½™æ•´çš„Excelæª”æ¡ˆ"""
        output_filename = f"ESGå½™æ•´å ±å‘Š.xlsx"
        output_path = self.results_path / output_filename
        
        print(f"ğŸ“Š ç”Ÿæˆå½™æ•´Excel: {output_filename}")
        
        # è½‰æ›ç‚ºDataFrame
        df_all = pd.DataFrame(all_data)
        
        if df_all.empty:
            print("âŒ æ²’æœ‰æœ‰æ•ˆæ•¸æ“šå¯å½™æ•´")
            return None
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # æŒ‰å¹´åº¦åˆ†çµ„çš„å·¥ä½œè¡¨
            years = sorted(set(item['report_year'] for item in all_data if item['report_year'] != "æœªçŸ¥å¹´åº¦"), reverse=True)
            
            for year in years:
                year_data = [item for item in all_data if item['report_year'] == year]
                if year_data:
                    year_df = pd.DataFrame(year_data)
                    sheet_name = f"{year}å¹´ç¸½è¦½"
                    year_df.to_excel(writer, sheet_name=sheet_name, index=False)
                    print(f"   âœ“ å‰µå»ºå·¥ä½œè¡¨: {sheet_name} ({len(year_data)} ç­†)")
            
            # æŒ‰å…¬å¸åˆ†çµ„çš„å·¥ä½œè¡¨
            companies = sorted(set(item['company_name'] for item in all_data if item['company_name'] != "æœªçŸ¥å…¬å¸"))
            
            for company in companies:
                company_data = [item for item in all_data if item['company_name'] == company]
                if company_data:
                    company_df = pd.DataFrame(company_data)
                    # æŒ‰å¹´åº¦æ’åº
                    company_df = company_df.sort_values('report_year', ascending=False)
                    
                    # æ¸…ç†å…¬å¸åç¨±ä½œç‚ºå·¥ä½œè¡¨åç¨±
                    safe_company_name = re.sub(r'[^\w\s-]', '', company)[:25]  # Excelå·¥ä½œè¡¨åç¨±é™åˆ¶
                    sheet_name = f"{safe_company_name}ç¸½è¦½"
                    
                    company_df.to_excel(writer, sheet_name=sheet_name, index=False)
                    print(f"   âœ“ å‰µå»ºå·¥ä½œè¡¨: {sheet_name} ({len(company_data)} ç­†)")
            
            # ç¸½è¦½æ‘˜è¦å·¥ä½œè¡¨
            summary_data = self._create_summary_data(parsed_files, all_data)
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='å½™æ•´æ‘˜è¦', index=False)
            print(f"   âœ“ å‰µå»ºå·¥ä½œè¡¨: å½™æ•´æ‘˜è¦")
        
        # ç¾åŒ–Excelæ ¼å¼
        self._format_excel(output_path)
        
        return str(output_path)
    
    def _create_summary_data(self, parsed_files: List[Dict], all_data: List[Dict]) -> List[Dict]:
        """å‰µå»ºæ‘˜è¦æ•¸æ“šï¼ŒåŒ…å«å…¬å¸åç¨±æ¨™æº–åŒ–ä¿¡æ¯"""
        summary_data = []
        
        # ç¸½é«”çµ±è¨ˆ
        total_files = len(parsed_files)
        total_records = len(all_data)
        companies = set(item['company_name'] for item in all_data if item['company_name'] != "æœªçŸ¥å…¬å¸")
        years = set(item['report_year'] for item in all_data if item['report_year'] != "æœªçŸ¥å¹´åº¦")
        
        # å…¬å¸åç¨±æ¨™æº–åŒ–çµ±è¨ˆ
        original_companies = len(self.company_mapping) if self.company_mapping else 0
        standardized_companies = len(companies)
        mappings_count = len([k for k, v in self.company_mapping.items() if k != v]) if self.company_mapping else 0
        
        # æŒ‰å…¬å¸çµ±è¨ˆ
        company_stats = {}
        for item in all_data:
            company = item['company_name']
            if company != "æœªçŸ¥å…¬å¸":
                if company not in company_stats:
                    company_stats[company] = {'years': set(), 'records': 0, 'original_names': set()}
                company_stats[company]['years'].add(item['report_year'])
                company_stats[company]['records'] += 1
                # è¨˜éŒ„åŸå§‹åç¨±
                if 'original_company_name' in item:
                    company_stats[company]['original_names'].add(item['original_company_name'])
                else:
                    company_stats[company]['original_names'].add(company)
        
        # æŒ‰å¹´åº¦çµ±è¨ˆ
        year_stats = {}
        for item in all_data:
            year = item['report_year']
            if year != "æœªçŸ¥å¹´åº¦":
                if year not in year_stats:
                    year_stats[year] = {'companies': set(), 'records': 0}
                year_stats[year]['companies'].add(item['company_name'])
                year_stats[year]['records'] += 1
        
        # ç”Ÿæˆæ‘˜è¦
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'å½™æ•´ç¸½è¦½',
            'æ•¸å€¼': f'æª”æ¡ˆæ•¸: {total_files}, ç¸½ç­†æ•¸: {total_records}',
            'è©³ç´°èªªæ˜': f'æ¶µè“‹ {standardized_companies} å®¶å…¬å¸, {len(years)} å€‹å¹´åº¦',
            'å½™æ•´æ™‚é–“': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
        # å…¬å¸åç¨±æ¨™æº–åŒ–çµ±è¨ˆ
        if mappings_count > 0:
            summary_data.append({
                'çµ±è¨ˆé …ç›®': 'åç¨±æ¨™æº–åŒ–',
                'æ•¸å€¼': f'{mappings_count} å€‹åç¨±è®Šé«”å·²çµ±ä¸€',
                'è©³ç´°èªªæ˜': f'åŸå§‹: {original_companies} â†’ æ¨™æº–åŒ–: {standardized_companies}',
                'å½™æ•´æ™‚é–“': ''
            })
        
        summary_data.append({'çµ±è¨ˆé …ç›®': '', 'æ•¸å€¼': '', 'è©³ç´°èªªæ˜': '', 'å½™æ•´æ™‚é–“': ''})
        
        # å…¬å¸çµ±è¨ˆï¼ˆé¡¯ç¤ºæ¨™æº–åŒ–ä¿¡æ¯ï¼‰
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'å…¬å¸çµ±è¨ˆ', 'æ•¸å€¼': 'å¹´åº¦ç¯„åœ', 'è©³ç´°èªªæ˜': 'æå–ç­†æ•¸', 'å½™æ•´æ™‚é–“': 'åŸå§‹åç¨±'
        })
        
        for company, stats in company_stats.items():
            years_range = f"{min(stats['years'])}-{max(stats['years'])}" if len(stats['years']) > 1 else list(stats['years'])[0]
            original_names = ', '.join(stats['original_names']) if len(stats['original_names']) > 1 else ''
            
            summary_data.append({
                'çµ±è¨ˆé …ç›®': company,
                'æ•¸å€¼': years_range,
                'è©³ç´°èªªæ˜': f"{stats['records']} ç­†",
                'å½™æ•´æ™‚é–“': original_names[:100] + ('...' if len(original_names) > 100 else '') if original_names else f"{len(stats['years'])} å€‹å¹´åº¦"
            })
        
        summary_data.append({'çµ±è¨ˆé …ç›®': '', 'æ•¸å€¼': '', 'è©³ç´°èªªæ˜': '', 'å½™æ•´æ™‚é–“': ''})
        
        # å¹´åº¦çµ±è¨ˆ
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'å¹´åº¦çµ±è¨ˆ', 'æ•¸å€¼': 'å…¬å¸æ•¸é‡', 'è©³ç´°èªªæ˜': 'æå–ç­†æ•¸', 'å½™æ•´æ™‚é–“': ''
        })
        
        for year in sorted(year_stats.keys(), reverse=True):
            stats = year_stats[year]
            summary_data.append({
                'çµ±è¨ˆé …ç›®': f"{year}å¹´",
                'æ•¸å€¼': f"{len(stats['companies'])} å®¶å…¬å¸",
                'è©³ç´°èªªæ˜': f"{stats['records']} ç­†",
                'å½™æ•´æ™‚é–“': ', '.join(sorted(stats['companies']))[:50] + ('...' if len(', '.join(stats['companies'])) > 50 else '')
            })
        
        # å¦‚æœæœ‰åç¨±æ˜ å°„ï¼Œæ·»åŠ æ˜ å°„è©³æƒ…
        if self.company_mapping and mappings_count > 0:
            summary_data.append({'çµ±è¨ˆé …ç›®': '', 'æ•¸å€¼': '', 'è©³ç´°èªªæ˜': '', 'å½™æ•´æ™‚é–“': ''})
            summary_data.append({
                'çµ±è¨ˆé …ç›®': 'åç¨±æ˜ å°„è©³æƒ…', 'æ•¸å€¼': 'åŸå§‹åç¨±', 'è©³ç´°èªªæ˜': 'æ¨™æº–åç¨±', 'å½™æ•´æ™‚é–“': ''
            })
            
            for original, standard in self.company_mapping.items():
                if original != standard:  # åªé¡¯ç¤ºæœ‰è®Šæ›´çš„
                    summary_data.append({
                        'çµ±è¨ˆé …ç›®': '',
                        'æ•¸å€¼': original,
                        'è©³ç´°èªªæ˜': standard,
                        'å½™æ•´æ™‚é–“': ''
                    })
        
        return summary_data
    
    def _format_excel(self, output_path: str):
        """ç¾åŒ–Excelæ ¼å¼"""
        try:
            workbook = openpyxl.load_workbook(output_path)
            
            # å®šç¾©æ¨£å¼
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            for sheet_name in workbook.sheetnames:
                worksheet = workbook[sheet_name]
                
                # è¨­ç½®æ¨™é¡Œè¡Œæ ¼å¼
                if worksheet.max_row > 0:
                    for cell in worksheet[1]:
                        cell.font = header_font
                        cell.fill = header_fill
                        cell.alignment = Alignment(horizontal='center')
                        cell.border = border
                    
                    # è‡ªå‹•èª¿æ•´åˆ—å¯¬
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
            
            workbook.save(output_path)
            print(f"âœ¨ Excelæ ¼å¼ç¾åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ Excelæ ¼å¼åŒ–å¤±æ•—: {e}")

def consolidate_esg_results(results_path: str) -> str:
    """å½™æ•´ESGçµæœçš„ä¸»å‡½æ•¸"""
    consolidator = ESGDataConsolidator(results_path)
    return consolidator.consolidate_all_results()

# =============================================================================
# æ¸¬è©¦åŠŸèƒ½
# =============================================================================

def test_consolidation():
    """æ¸¬è©¦å½™æ•´åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦ESGè³‡æ–™å½™æ•´åŠŸèƒ½")
    
    # å‡è¨­æœ‰ä¸€äº›æ¸¬è©¦æª”æ¡ˆ
    test_results_path = "./test_results"
    
    try:
        consolidator = ESGDataConsolidator(test_results_path)
        result_path = consolidator.consolidate_all_results()
        
        if result_path:
            print(f"âœ… æ¸¬è©¦æˆåŠŸ: {result_path}")
        else:
            print("âŒ æ¸¬è©¦å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éŒ¯èª¤: {e}")

def test_company_name_standardization():
    """æ¸¬è©¦å…¬å¸åç¨±æ¨™æº–åŒ–åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦å…¬å¸åç¨±æ¨™æº–åŒ–åŠŸèƒ½")
    print("=" * 50)
    
    standardizer = CompanyNameStandardizer()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_companies = [
        ["ä¸‰èŠ³", "ä¸‰èŠ³åŒ–å­¸", "ä¸‰èŠ³åŒ–å­¸å·¥æ¥­", "ä¸‰èŠ³åŒ–å­¸å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸"],
        ["å°ç£å¡‘è† å·¥æ¥­", "å°ç£å¡‘è† å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "å°ç£å¡‘è† "],
        ["å—äºå¡‘è† å·¥æ¥­", "å—äºå¡‘è† ", "å—äº"],
        ["å°ç©é›»", "å°ç£ç©é«”é›»è·¯è£½é€ ", "å°ç£ç©é«”é›»è·¯è£½é€ è‚¡ä»½æœ‰é™å…¬å¸"],
        ["ä¸­è¯é›»ä¿¡", "ä¸­è¯é›»ä¿¡è‚¡ä»½æœ‰é™å…¬å¸"],
    ]
    
    for i, company_group in enumerate(test_companies, 1):
        print(f"\næ¸¬è©¦çµ„ {i}:")
        print(f"åŸå§‹åç¨±: {company_group}")
        
        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        print("ç›¸ä¼¼åº¦åˆ†æ:")
        for j, name1 in enumerate(company_group):
            for k, name2 in enumerate(company_group):
                if j < k:  # åªè¨ˆç®—ä¸Šä¸‰è§’
                    similarity = standardizer.calculate_similarity(name1, name2)
                    print(f"  {name1} â†” {name2}: {similarity:.2f}")
        
        # é¸æ“‡æ¨™æº–åç¨±
        standard_name = standardizer.choose_standard_name(company_group)
        print(f"æ¨™æº–åç¨±: {standard_name}")
        
        # é¡¯ç¤ºæ˜ å°„
        for name in company_group:
            if name != standard_name:
                print(f"  ğŸ”— {name} â†’ {standard_name}")

def test_consolidation():
    """æ¸¬è©¦å½™æ•´åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦ESGè³‡æ–™å½™æ•´åŠŸèƒ½")
    
    # å‡è¨­æœ‰ä¸€äº›æ¸¬è©¦æª”æ¡ˆ
    test_results_path = "./test_results"
    
    try:
        consolidator = ESGDataConsolidator(test_results_path)
        result_path = consolidator.consolidate_all_results()
        
        if result_path:
            print(f"âœ… æ¸¬è©¦æˆåŠŸ: {result_path}")
        else:
            print("âŒ æ¸¬è©¦å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éŒ¯èª¤: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--test-names":
            test_company_name_standardization()
        elif sys.argv[1] == "--test-consolidation":
            test_consolidation()
        else:
            print("ç”¨æ³•:")
            print("  python consolidator.py --test-names      # æ¸¬è©¦åç¨±æ¨™æº–åŒ–")
            print("  python consolidator.py --test-consolidation  # æ¸¬è©¦å½™æ•´åŠŸèƒ½")
    else:
        test_company_name_standardization()