#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESGè³‡æ–™å½™æ•´æ¨¡çµ„ v1.0
å°‡å¤šå€‹Excelæª”æ¡ˆå½™æ•´æˆä¸€å€‹ç¸½è¦½è¡¨
"""

import os
import re
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side

class ESGDataConsolidator:
    """
    ESGè³‡æ–™å½™æ•´å™¨
    
    åŠŸèƒ½ï¼š
    - è‡ªå‹•æƒæresultsç›®éŒ„ä¸‹çš„æ‰€æœ‰Excelæª”æ¡ˆ
    - æ’é™¤æª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆ
    - å¾æª”åä¸­æå–æ¨™æº–åŒ–çš„å…¬å¸åç¨±
    - æŒ‰å¹´åº¦å’Œå…¬å¸åˆ†çµ„ç”Ÿæˆå½™æ•´å ±å‘Š
    - åŒ…å«çµ±è¨ˆæ‘˜è¦å’Œç¾åŒ–æ ¼å¼
    """
    
    def __init__(self, results_path: str):
        self.results_path = Path(results_path)
        
        print(f"ğŸ“Š åˆå§‹åŒ–ESGè³‡æ–™å½™æ•´å™¨")
        print(f"ğŸ“ çµæœç›®éŒ„: {self.results_path}")
        print(f"âš ï¸ æ³¨æ„ï¼šæª”ååŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå°‡è¢«è‡ªå‹•æ’é™¤")
        print(f"ğŸ¢ å„ªå…ˆä½¿ç”¨æª”åä¸­çš„å…¬å¸è³‡è¨Šï¼ˆæ”¯æ´æ¨™æº–åŒ–æ ¼å¼ï¼‰")
    
    def consolidate_all_results(self) -> str:
        """å½™æ•´æ‰€æœ‰çµæœåˆ°ä¸€å€‹Excelæª”æ¡ˆï¼Œæ’é™¤'ç„¡æå–'æª”æ¡ˆ"""
        print("\nğŸš€ é–‹å§‹å½™æ•´æ‰€æœ‰ESGæå–çµæœ...")
        print("=" * 60)
        
        # 1. æƒæä¸¦åˆ†ææ‰€æœ‰Excelæª”æ¡ˆï¼ˆæ’é™¤'ç„¡æå–'ï¼‰
        excel_files = self._scan_excel_files()
        if not excel_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„Excelçµæœæª”æ¡ˆ")
            print("ğŸ’¡ æç¤ºï¼šåŒ…å«'ç„¡æå–'çš„æª”æ¡ˆå·²è‡ªå‹•æ’é™¤")
            return None
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(excel_files)} å€‹æœ‰æ•ˆExcelçµæœæª”æ¡ˆï¼ˆå·²æ’é™¤'ç„¡æå–'æª”æ¡ˆï¼‰")
        
        # 2. è§£ææª”æ¡ˆä¿¡æ¯
        parsed_files = self._parse_file_info(excel_files)
        print(f"âœ… æˆåŠŸè§£æ {len(parsed_files)} å€‹æª”æ¡ˆ")
        
        # 3. è¼‰å…¥æ‰€æœ‰è³‡æ–™
        all_data = self._load_all_data(parsed_files)
        print(f"ğŸ“š è¼‰å…¥å®Œæˆï¼Œå…± {len(all_data)} ç­†è³‡æ–™")
        
        # 4. ç”Ÿæˆå½™æ•´å ±å‘Š
        output_path = self._create_consolidated_excel(all_data, parsed_files)
        
        print(f"âœ… å½™æ•´å®Œæˆï¼")
        print(f"ğŸ“Š è¼¸å‡ºæª”æ¡ˆ: {output_path}")
        
        return output_path
    
    def _scan_excel_files(self) -> List[Path]:
        """æƒææ‰€æœ‰Excelæª”æ¡ˆï¼Œæ’é™¤åŒ…å«'ç„¡æå–'çš„æª”æ¡ˆ"""
        excel_files = []
        excluded_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæª”æ¡ˆ
        patterns = [
            "æå–çµæœ_*.xlsx",
            "*å¹³è¡¡ç‰ˆ*.xlsx", 
            "*é«˜ç²¾åº¦*.xlsx"
        ]
        
        for pattern in patterns:
            files = list(self.results_path.glob(pattern))
            for file in files:
                # æª¢æŸ¥æª”åæ˜¯å¦åŒ…å«"ç„¡æå–"
                if "ç„¡æå–" in file.name:
                    excluded_files.append(file)
                    print(f"   âŠ— æ’é™¤æª”æ¡ˆ: {file.name} (åŒ…å«'ç„¡æå–')")
                else:
                    excel_files.append(file)
        
        # é¡¯ç¤ºæ’é™¤çµ±è¨ˆ
        if excluded_files:
            print(f"ğŸ“‹ æ’é™¤äº† {len(excluded_files)} å€‹'ç„¡æå–'æª”æ¡ˆ")
        
        # å»é‡ä¸¦æ’åº
        unique_files = list(set(excel_files))
        unique_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        return unique_files
    
    def _extract_company_from_filename(self, filename: str) -> Tuple[str, str, str]:
        """
        å¾æª”åä¸­æå–å…¬å¸è³‡è¨Š
        
        æ”¯æ´æ ¼å¼ï¼š
        - ESGæå–çµæœ_4303_ä¿¡ç«‹_2024.xlsx (æ¨™æº–åŒ–æ ¼å¼)
        - ESGæå–çµæœ_ä¿¡ç«‹_2024.xlsx (èˆŠæ ¼å¼)
        - ESGæå–çµæœ_å—äºå¡‘è† å·¥æ¥­_2023.xlsx (èˆŠæ ¼å¼)
        
        Returns:
            Tuple[è‚¡ç¥¨ä»£è™Ÿ, å…¬å¸åç¨±, å¹´åº¦]
        """
        # ç§»é™¤å‰ç¶´å’Œå‰¯æª”å
        clean_name = filename.replace('ESGæå–çµæœ_', '').replace('.xlsx', '')
        
        stock_code = ""
        company_name = ""
        year = ""
        
        # æå–å¹´åº¦
        year_match = re.search(r'(202[0-9])', clean_name)
        if year_match:
            year = year_match.group(1)
            clean_name = clean_name.replace(f'_{year}', '').replace(year, '')
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™æº–åŒ–æ ¼å¼ï¼ˆåŒ…å«è‚¡ç¥¨ä»£è™Ÿï¼‰
        # æ ¼å¼: ä»£è™Ÿ_å…¬å¸å æˆ– ä»£è™Ÿ_å…¬å¸å_å…¶ä»–
        stock_code_pattern = r'^(\d{4}A?|[A-Z]+\d+)_(.+?)(?:_.*)?$'
        stock_match = re.match(stock_code_pattern, clean_name.strip('_'))
        
        if stock_match:
            # æ¨™æº–åŒ–æ ¼å¼
            stock_code = stock_match.group(1)
            company_name = stock_match.group(2)
            print(f"   ğŸ“Š æ¨™æº–åŒ–æ ¼å¼: {stock_code} - {company_name}")
        else:
            # èˆŠæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å…¬å¸åç¨±
            company_name = clean_name.strip('_')
            print(f"   ğŸ“„ èˆŠæ ¼å¼: {company_name}")
        
        # æ¸…ç†å…¬å¸åç¨±
        if company_name:
            # ç§»é™¤å¸¸è¦‹å¾Œç¶´
            suffixes_to_remove = [
                "è‚¡ä»½æœ‰é™å…¬å¸", "æœ‰é™å…¬å¸", "å…¬å¸", 
                "å·¥æ¥­", "åŒ–å­¸", "å¡‘è† ", "ç§‘æŠ€"
            ]
            for suffix in suffixes_to_remove:
                if company_name.endswith(suffix):
                    company_name = company_name[:-len(suffix)].strip()
                    break
        
        return stock_code, company_name, year
    
    def _parse_file_info(self, excel_files: List[Path]) -> List[Dict]:
        """è§£ææª”æ¡ˆä¿¡æ¯ï¼Œå„ªå…ˆä½¿ç”¨æª”åä¸­çš„å…¬å¸è³‡è¨Š"""
        parsed_files = []
        
        for file_path in excel_files:
            try:
                filename = file_path.stem
                
                print(f"ğŸ“„ è§£ææª”æ¡ˆ: {filename}")
                
                # å¾æª”åæå–å…¬å¸è³‡è¨Š
                stock_code, filename_company, filename_year = self._extract_company_from_filename(filename)
                
                # è§£æç‰ˆæœ¬
                if "å¹³è¡¡ç‰ˆ" in filename:
                    version = "å¹³è¡¡ç‰ˆ"
                elif "é«˜ç²¾åº¦" in filename:
                    version = "é«˜ç²¾åº¦ç‰ˆ"
                else:
                    version = "æ¨™æº–ç‰ˆ"
                
                # å˜—è©¦å¾Excelå…§å®¹ä¸­è®€å–æ›´è©³ç´°çš„ä¿¡æ¯ä½œç‚ºå‚™ç”¨
                excel_company, excel_year = self._extract_company_info_from_excel(file_path)
                
                # æ±ºå®šæœ€çµ‚ä½¿ç”¨çš„å…¬å¸åç¨±å’Œå¹´åº¦
                final_company = filename_company if filename_company else excel_company
                final_year = filename_year if filename_year else excel_year
                
                # å¦‚æœæœ‰è‚¡ç¥¨ä»£è™Ÿï¼ŒåŠ å…¥åˆ°å…¬å¸åç¨±ä¸­
                if stock_code:
                    display_company = f"{stock_code} {final_company}"
                else:
                    display_company = final_company
                
                parsed_files.append({
                    'file_path': file_path,
                    'filename': filename,
                    'stock_code': stock_code,
                    'company_name': display_company,  # ç”¨æ–¼é¡¯ç¤ºçš„å®Œæ•´åç¨±
                    'company_name_only': final_company,  # åƒ…å…¬å¸åç¨±
                    'report_year': final_year,
                    'version': version,
                    'file_time': datetime.fromtimestamp(file_path.stat().st_mtime),
                    'source': 'filename' if filename_company else 'excel_content'
                })
                
                print(f"   âœ“ {display_company} - {final_year} ({version}) [ä¾†æº: {'æª”å' if filename_company else 'Excelå…§å®¹'}]")
                
            except Exception as e:
                print(f"   âš ï¸ è§£æå¤±æ•— {file_path.name}: {e}")
                continue
        
        return parsed_files
    
    def _extract_company_info_from_excel(self, file_path: Path) -> Tuple[str, str]:
        """å¾Excelæª”æ¡ˆä¸­æå–å…¬å¸åç¨±å’Œå¹´åº¦ï¼ˆä½œç‚ºå‚™ç”¨ï¼‰"""
        try:
            # è®€å–ç¬¬ä¸€å€‹å·¥ä½œè¡¨çš„å‰å¹¾è¡Œ
            df = pd.read_excel(file_path, nrows=5)
            
            company_name = "æœªçŸ¥å…¬å¸"
            report_year = ""
            
            # æŸ¥æ‰¾å…¬å¸ä¿¡æ¯
            for col in df.columns:
                for idx, row in df.iterrows():
                    cell_value = str(row[col])
                    
                    # æå–å…¬å¸åç¨±
                    if "å…¬å¸:" in cell_value:
                        company_match = re.search(r'å…¬å¸:\s*(.+)', cell_value)
                        if company_match:
                            company_name = company_match.group(1).strip()
                    
                    # æå–å ±å‘Šå¹´åº¦
                    if "å ±å‘Šå¹´åº¦:" in cell_value:
                        year_match = re.search(r'å ±å‘Šå¹´åº¦:\s*(202[0-9])', cell_value)
                        if year_match:
                            report_year = year_match.group(1)
            
            return company_name, report_year
            
        except Exception as e:
            print(f"   âš ï¸ è®€å–Excelå¤±æ•—: {e}")
            return "æœªçŸ¥å…¬å¸", ""
    
    def _load_all_data(self, parsed_files: List[Dict]) -> List[Dict]:
        """è¼‰å…¥æ‰€æœ‰è³‡æ–™"""
        all_data = []
        
        for file_info in parsed_files:
            try:
                file_path = file_info['file_path']
                
                # å˜—è©¦è®€å–ä¸åŒçš„å·¥ä½œè¡¨åç¨±
                sheet_names_to_try = [
                    'å¹³è¡¡ç‰ˆæå–çµæœ', 'æå–çµæœ', 'Sheet1', 0
                ]
                
                df = None
                for sheet_name in sheet_names_to_try:
                    try:
                        df = pd.read_excel(file_path, sheet_name=sheet_name)
                        break
                    except:
                        continue
                
                if df is None:
                    print(f"   âš ï¸ ç„¡æ³•è®€å– {file_path.name}")
                    continue
                
                # è·³éæ¨™é¡Œè¡Œï¼ˆå‰2è¡Œé€šå¸¸æ˜¯å…¬å¸ä¿¡æ¯å’Œç©ºè¡Œï¼‰
                data_start_row = 0
                for idx, row in df.iterrows():
                    if idx < 5:  # æª¢æŸ¥å‰5è¡Œ
                        first_cell = str(row.iloc[0]) if len(row) > 0 else ""
                        if "å…¬å¸:" not in first_cell and first_cell.strip() and first_cell != "nan":
                            data_start_row = idx
                            break
                
                if data_start_row < len(df):
                    df = df.iloc[data_start_row:]
                
                # ç‚ºæ¯ä¸€è¡Œæ·»åŠ æª”æ¡ˆä¿¡æ¯
                for idx, row in df.iterrows():
                    if len(row) > 0 and str(row.iloc[0]).strip() and str(row.iloc[0]) != "nan":
                        data_row = {
                            'stock_code': file_info['stock_code'],
                            'company_name': file_info['company_name'],  # å®Œæ•´é¡¯ç¤ºåç¨±
                            'company_name_only': file_info['company_name_only'],  # åƒ…å…¬å¸åç¨±
                            'report_year': file_info['report_year'],
                            'version': file_info['version'],
                            'file_name': file_info['filename'],
                            'source_file': file_path.name,
                            'info_source': file_info['source']
                        }
                        
                        # æ·»åŠ åŸå§‹æ•¸æ“šåˆ—
                        for col_idx, col_name in enumerate(df.columns):
                            if col_idx < len(row):
                                data_row[col_name] = row.iloc[col_idx]
                        
                        all_data.append(data_row)
                
                print(f"   âœ“ è¼‰å…¥ {file_info['company_name']} - {file_info['report_year']} ({len(df)} ç­†)")
                
            except Exception as e:
                print(f"   âŒ è¼‰å…¥å¤±æ•— {file_info['file_path'].name}: {e}")
                continue
        
        return all_data
    
    def _create_consolidated_excel(self, all_data: List[Dict], parsed_files: List[Dict]) -> str:
        """å‰µå»ºå½™æ•´çš„Excelæª”æ¡ˆ"""
        output_filename = f"ESGå½™æ•´å ±å‘Š.xlsx"
        output_path = self.results_path / output_filename
        
        print(f"ğŸ“Š ç”Ÿæˆå½™æ•´Excel: {output_filename}")
        
        # è½‰æ›ç‚ºDataFrame
        df_all = pd.DataFrame(all_data)
        
        if df_all.empty:
            print("âŒ æ²’æœ‰æœ‰æ•ˆæ•¸æ“šå¯å½™æ•´")
            return None
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # æŒ‰å¹´åº¦åˆ†çµ„çš„å·¥ä½œè¡¨
            years = sorted(set(item['report_year'] for item in all_data if item['report_year'] and item['report_year'] != "æœªçŸ¥å¹´åº¦"), reverse=True)
            
            for year in years:
                year_data = [item for item in all_data if item['report_year'] == year]
                if year_data:
                    year_df = pd.DataFrame(year_data)
                    sheet_name = f"{year}å¹´ç¸½è¦½"
                    year_df.to_excel(writer, sheet_name=sheet_name, index=False)
                    print(f"   âœ“ å‰µå»ºå·¥ä½œè¡¨: {sheet_name} ({len(year_data)} ç­†)")
            
            # æŒ‰å…¬å¸åˆ†çµ„çš„å·¥ä½œè¡¨ï¼ˆä½¿ç”¨å®Œæ•´é¡¯ç¤ºåç¨±ï¼‰
            companies = sorted(set(item['company_name'] for item in all_data if item['company_name'] and item['company_name'] != "æœªçŸ¥å…¬å¸"))
            
            for company in companies:
                company_data = [item for item in all_data if item['company_name'] == company]
                if company_data:
                    company_df = pd.DataFrame(company_data)
                    # æŒ‰å¹´åº¦æ’åº
                    company_df = company_df.sort_values('report_year', ascending=False)
                    
                    # æ¸…ç†å…¬å¸åç¨±ä½œç‚ºå·¥ä½œè¡¨åç¨±ï¼ˆç§»é™¤è‚¡ç¥¨ä»£è™Ÿä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼‰
                    safe_company_name = re.sub(r'[^\w\s-]', '', company).strip()[:25]  # Excelå·¥ä½œè¡¨åç¨±é™åˆ¶
                    sheet_name = f"{safe_company_name}ç¸½è¦½"
                    
                    company_df.to_excel(writer, sheet_name=sheet_name, index=False)
                    print(f"   âœ“ å‰µå»ºå·¥ä½œè¡¨: {sheet_name} ({len(company_data)} ç­†)")
            
            # ç¸½è¦½æ‘˜è¦å·¥ä½œè¡¨
            summary_data = self._create_summary_data(parsed_files, all_data)
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='å½™æ•´æ‘˜è¦', index=False)
            print(f"   âœ“ å‰µå»ºå·¥ä½œè¡¨: å½™æ•´æ‘˜è¦")
        
        # ç¾åŒ–Excelæ ¼å¼
        self._format_excel(output_path)
        
        return str(output_path)
    
    def _create_summary_data(self, parsed_files: List[Dict], all_data: List[Dict]) -> List[Dict]:
        """å‰µå»ºæ‘˜è¦æ•¸æ“š"""
        summary_data = []
        
        # ç¸½é«”çµ±è¨ˆ
        total_files = len(parsed_files)
        total_records = len(all_data)
        companies = set(item['company_name'] for item in all_data if item['company_name'] and item['company_name'] != "æœªçŸ¥å…¬å¸")
        years = set(item['report_year'] for item in all_data if item['report_year'] and item['report_year'] != "æœªçŸ¥å¹´åº¦")
        
        # æª”åä¾†æºçµ±è¨ˆ
        filename_source_count = len([f for f in parsed_files if f['source'] == 'filename'])
        excel_source_count = len([f for f in parsed_files if f['source'] == 'excel_content'])
        
        # æŒ‰å…¬å¸çµ±è¨ˆ
        company_stats = {}
        for item in all_data:
            company = item['company_name']
            if company and company != "æœªçŸ¥å…¬å¸":
                if company not in company_stats:
                    company_stats[company] = {
                        'years': set(), 
                        'records': 0, 
                        'stock_code': item.get('stock_code', ''),
                        'info_source': item.get('info_source', '')
                    }
                company_stats[company]['years'].add(item['report_year'])
                company_stats[company]['records'] += 1
        
        # æŒ‰å¹´åº¦çµ±è¨ˆ
        year_stats = {}
        for item in all_data:
            year = item['report_year']
            if year and year != "æœªçŸ¥å¹´åº¦":
                if year not in year_stats:
                    year_stats[year] = {'companies': set(), 'records': 0}
                year_stats[year]['companies'].add(item['company_name'])
                year_stats[year]['records'] += 1
        
        # ç”Ÿæˆæ‘˜è¦
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'å½™æ•´ç¸½è¦½',
            'æ•¸å€¼': f'æª”æ¡ˆæ•¸: {total_files}, ç¸½ç­†æ•¸: {total_records}',
            'è©³ç´°èªªæ˜': f'æ¶µè“‹ {len(companies)} å®¶å…¬å¸, {len(years)} å€‹å¹´åº¦',
            'å½™æ•´æ™‚é–“': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
        # è³‡è¨Šä¾†æºçµ±è¨ˆ
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'è³‡è¨Šä¾†æº',
            'æ•¸å€¼': f'æª”å: {filename_source_count}, Excelå…§å®¹: {excel_source_count}',
            'è©³ç´°èªªæ˜': f'æª”åæ¨™æº–åŒ–ç‡: {filename_source_count/total_files*100:.1f}%' if total_files > 0 else '0%',
            'å½™æ•´æ™‚é–“': ''
        })
        
        summary_data.append({'çµ±è¨ˆé …ç›®': '', 'æ•¸å€¼': '', 'è©³ç´°èªªæ˜': '', 'å½™æ•´æ™‚é–“': ''})
        
        # å…¬å¸çµ±è¨ˆï¼ˆé¡¯ç¤ºè‚¡ç¥¨ä»£è™Ÿå’Œè³‡è¨Šä¾†æºï¼‰
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'å…¬å¸çµ±è¨ˆ', 
            'æ•¸å€¼': 'å¹´åº¦ç¯„åœ', 
            'è©³ç´°èªªæ˜': 'æå–ç­†æ•¸', 
            'å½™æ•´æ™‚é–“': 'è‚¡ç¥¨ä»£è™Ÿ/ä¾†æº'
        })
        
        for company, stats in company_stats.items():
            years_range = f"{min(stats['years'])}-{max(stats['years'])}" if len(stats['years']) > 1 else list(stats['years'])[0]
            info_detail = f"{stats['stock_code']}" if stats['stock_code'] else f"ä¾†æº:{stats['info_source']}"
            
            summary_data.append({
                'çµ±è¨ˆé …ç›®': company,
                'æ•¸å€¼': years_range,
                'è©³ç´°èªªæ˜': f"{stats['records']} ç­†",
                'å½™æ•´æ™‚é–“': info_detail
            })
        
        summary_data.append({'çµ±è¨ˆé …ç›®': '', 'æ•¸å€¼': '', 'è©³ç´°èªªæ˜': '', 'å½™æ•´æ™‚é–“': ''})
        
        # å¹´åº¦çµ±è¨ˆ
        summary_data.append({
            'çµ±è¨ˆé …ç›®': 'å¹´åº¦çµ±è¨ˆ', 
            'æ•¸å€¼': 'å…¬å¸æ•¸é‡', 
            'è©³ç´°èªªæ˜': 'æå–ç­†æ•¸', 
            'å½™æ•´æ™‚é–“': 'å…¬å¸æ¸…å–®'
        })
        
        for year in sorted(year_stats.keys(), reverse=True):
            stats = year_stats[year]
            # åªé¡¯ç¤ºå…¬å¸åç¨±çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œä¸åŒ…å«è‚¡ç¥¨ä»£è™Ÿ
            company_names = [item.get('company_name_only', item['company_name']) for item in all_data if item['report_year'] == year]
            company_list = ', '.join(sorted(set(company_names)))
            
            summary_data.append({
                'çµ±è¨ˆé …ç›®': f"{year}å¹´",
                'æ•¸å€¼': f"{len(stats['companies'])} å®¶å…¬å¸",
                'è©³ç´°èªªæ˜': f"{stats['records']} ç­†",
                'å½™æ•´æ™‚é–“': company_list[:100] + ('...' if len(company_list) > 100 else '')
            })
        
        return summary_data
    
    def _format_excel(self, output_path: str):
        """ç¾åŒ–Excelæ ¼å¼"""
        try:
            workbook = openpyxl.load_workbook(output_path)
            
            # å®šç¾©æ¨£å¼
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            for sheet_name in workbook.sheetnames:
                worksheet = workbook[sheet_name]
                
                # è¨­ç½®æ¨™é¡Œè¡Œæ ¼å¼
                if worksheet.max_row > 0:
                    for cell in worksheet[1]:
                        cell.font = header_font
                        cell.fill = header_fill
                        cell.alignment = Alignment(horizontal='center')
                        cell.border = border
                    
                    # è‡ªå‹•èª¿æ•´åˆ—å¯¬
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width
            
            workbook.save(output_path)
            print(f"âœ¨ Excelæ ¼å¼ç¾åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ Excelæ ¼å¼åŒ–å¤±æ•—: {e}")

def consolidate_esg_results(results_path: str) -> str:
    """å½™æ•´ESGçµæœçš„ä¸»å‡½æ•¸"""
    consolidator = ESGDataConsolidator(results_path)
    return consolidator.consolidate_all_results()

# =============================================================================
# æ¸¬è©¦åŠŸèƒ½
# =============================================================================

def test_filename_parsing():
    """æ¸¬è©¦æª”åè§£æåŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦Excelæª”åè§£æ")
    print("=" * 50)
    
    # æ¸¬è©¦æª”å
    test_filenames = [
        "ESGæå–çµæœ_4303_ä¿¡ç«‹_2024.xlsx",
        "ESGæå–çµæœ_1303_å—äº_2023.xlsx",
        "ESGæå–çµæœ_4306_ç‚æ´²_2024.xlsx",
        "ESGæå–çµæœ_ä¿¡ç«‹_2024.xlsx",  # èˆŠæ ¼å¼
        "ESGæå–çµæœ_å—äºå¡‘è† å·¥æ¥­_2023.xlsx",  # èˆŠæ ¼å¼
        "ESGæå–çµæœ_å¹³è¡¡ç‰ˆ_å°å¡‘_2024.xlsx",
    ]
    
    consolidator = ESGDataConsolidator("./test")
    
    for filename in test_filenames:
        print(f"\nğŸ“„ æ¸¬è©¦æª”å: {filename}")
        stock_code, company_name, year = consolidator._extract_company_from_filename(filename)
        
        if stock_code:
            display_name = f"{stock_code} {company_name}"
        else:
            display_name = company_name
            
        print(f"   çµæœ: {display_name} - {year}")

def test_consolidation():
    """æ¸¬è©¦å½™æ•´åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦ESGè³‡æ–™å½™æ•´åŠŸèƒ½")
    
    # å‡è¨­æœ‰ä¸€äº›æ¸¬è©¦æª”æ¡ˆ
    test_results_path = "./test_results"
    
    try:
        consolidator = ESGDataConsolidator(test_results_path)
        result_path = consolidator.consolidate_all_results()
        
        if result_path:
            print(f"âœ… æ¸¬è©¦æˆåŠŸ: {result_path}")
        else:
            print("âŒ æ¸¬è©¦å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éŒ¯èª¤: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--test-parsing":
            test_filename_parsing()
        elif sys.argv[1] == "--test-consolidation":
            test_consolidation()
        else:
            print("ç”¨æ³•:")
            print("  python consolidator.py --test-parsing       # æ¸¬è©¦æª”åè§£æ")
            print("  python consolidator.py --test-consolidation # æ¸¬è©¦å½™æ•´åŠŸèƒ½")
    else:
        test_filename_parsing()