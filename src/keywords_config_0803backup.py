# =============================================================================
# æ•´åˆç‰ˆé—œéµå­—é…ç½®æ–‡ä»¶ - æ”¯æ´é€£çºŒå’Œä¸é€£çºŒé—œéµå­—
# =============================================================================

import re
from typing import List, Dict, Tuple, Union

# å¢å¼·çš„é—œéµå­—é…ç½®
ESG_KEYWORDS_CONFIG = {
    "å†ç”Ÿå¡‘è† ææ–™ä½¿ç”¨": {
        "description": "å†ç”Ÿå¡‘è† ææ–™çš„ä½¿ç”¨æƒ…æ³å’Œæ•¸æ“š",
        "type": "percentage_or_number",
        "keywords": [
            # ===== é€£çºŒé—œéµå­— =====
            "å†ç”Ÿå¡‘è† ",
            "å†ç”Ÿå¡‘æ–™", 
            "å†ç”Ÿæ–™",
            "å†ç”Ÿpp",
            
            # ===== ä¸é€£çºŒé—œéµå­—çµ„åˆ (å…ƒçµ„æ ¼å¼) =====
            ("PP", "æ£§æ¿", "å›æ”¶"),      # PPæ£§æ¿å›æ”¶
            ("PP", "å›æ”¶"),             # PP...å›æ”¶
            ("PP", "å†ç”Ÿ"),             # PPå†ç”Ÿææ–™  
            ("å¡‘è† ", "å›æ”¶"),           # å¡‘è† ...å›æ”¶
            ("å¡‘æ–™", "å†ç”Ÿ"),           # å¡‘æ–™å†ç”ŸæŠ€è¡“
            ("å†ç”Ÿ", "ææ–™"),           # å†ç”Ÿ...ææ–™
            ("å›æ”¶", "å¡‘è† "),           # å›æ”¶å¡‘è† è£½å“
            ("å›æ”¶", "å¡‘æ–™"),           # å›æ”¶å¡‘æ–™ç”¢å“
            ("PCR", "ææ–™"),            # PCRææ–™ä½¿ç”¨
            ("rPET", "å«é‡"),           # rPETå«é‡æ¯”ä¾‹
            ("å›æ”¶", "ç”¢èƒ½"),           # å›æ”¶ç”¢èƒ½æ•¸æ“š
            ("MLCC", "å›æ”¶"),           # MLCCå›æ”¶ç›¸é—œ
        ]
    }
}

def smart_keyword_match(text: str, keyword: Union[str, tuple], max_distance: int = 100) -> Tuple[bool, float]:
    """
    æ™ºèƒ½é—œéµå­—åŒ¹é…å‡½æ•¸
    
    Args:
        text: è¦æœç´¢çš„æ–‡æœ¬
        keyword: é—œéµå­—ï¼ˆå­—ç¬¦ä¸²æˆ–å…ƒçµ„ï¼‰
        max_distance: ä¸é€£çºŒé—œéµå­—çµ„ä»¶é–“çš„æœ€å¤§è·é›¢
    
    Returns:
        Tuple[bool, float]: (æ˜¯å¦åŒ¹é…, ä¿¡å¿ƒåˆ†æ•¸)
    """
    text_lower = text.lower()
    
    if isinstance(keyword, str):
        # é€£çºŒé—œéµå­—åŒ¹é…
        if keyword.lower() in text_lower:
            return True, 1.0
        return False, 0.0
    
    elif isinstance(keyword, tuple):
        # ä¸é€£çºŒé—œéµå­—åŒ¹é…
        components = [comp.lower() for comp in keyword]
        positions = []
        
        # æ‰¾åˆ°æ¯å€‹çµ„ä»¶çš„ä½ç½®
        for comp in components:
            pos = text_lower.find(comp)
            if pos == -1:
                return False, 0.0  # å¦‚æœä»»ä½•çµ„ä»¶æœªæ‰¾åˆ°ï¼Œç›´æ¥è¿”å›False
            positions.append(pos)
        
        # è¨ˆç®—çµ„ä»¶é–“çš„è·é›¢
        min_pos = min(positions)
        max_pos = max(positions)
        distance = max_pos - min_pos
        
        # æ ¹æ“šè·é›¢è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
        if distance <= 20:
            return True, 0.95  # éå¸¸è¿‘
        elif distance <= 50:
            return True, 0.85  # è¿‘
        elif distance <= max_distance:
            return True, 0.7   # å¯æ¥å—çš„è·é›¢
        else:
            return True, 0.5   # è·é›¢è¼ƒé ä½†ä»ç„¶ç›¸é—œ
    
    return False, 0.0

def enhanced_first_stage_filter(text_content: str, keywords: list) -> Tuple[bool, List[Dict]]:
    """
    å¢å¼·çš„ç¬¬ä¸€éšæ®µç¯©é¸
    """
    matches = []
    
    for keyword in keywords:
        is_match, confidence = smart_keyword_match(text_content, keyword)
        
        if is_match:
            keyword_str = keyword if isinstance(keyword, str) else " + ".join(keyword)
            matches.append({
                'keyword': keyword_str,
                'original_keyword': keyword,
                'confidence': confidence,
                'match_type': 'continuous' if isinstance(keyword, str) else 'discontinuous'
            })
    
    return len(matches) > 0, matches

def enhanced_second_stage_filter(text_content: str, keywords: list) -> list:
    """
    å¢å¼·çš„ç¬¬äºŒéšæ®µç¯©é¸
    """
    # æ›´å…¨é¢çš„æ•¸å€¼å’Œç™¾åˆ†æ¯”æ­£å‰‡è¡¨é”å¼
    number_patterns = [
        r'\d+(?:,\d{3})*(?:\.\d+)?(?:\s*(?:kg|KG|å…¬æ–¤|å™¸|å…‹|g|G|å…¬å…‹|è¬å™¸|åƒå™¸|è¬|åƒ|ç™¾|å€‹|ä»¶|æ‰¹|å°|å¥—))',
        r'\d+(?:,\d{3})*(?:\.\d+)?(?:\s*å™¸/æœˆ)',  # ç‰¹æ®Šæ ¼å¼ï¼šå™¸/æœˆ
        r'\d+(?:,\d{3})*(?:\.\d+)?\s*(?:è¬|åƒ)?(?:å™¸|å…¬æ–¤|kg)',  # å¸¶è¬ã€åƒçš„æ•¸é‡
    ]
    
    percentage_patterns = [
        r'\d+(?:\.\d+)?(?:\s*%|ç™¾åˆ†æ¯”|æˆ)',
        r'\d+(?:\.\d+)?(?:\s*ï¼…)',  # å…¨è§’ç™¾åˆ†è™Ÿ
    ]
    
    results = []
    
    # åˆ†å‰²æˆæ®µè½ï¼ˆæ”¯æ´å¤šç¨®åˆ†å‰²ç¬¦ï¼‰
    paragraphs = re.split(r'\n+|\r+|ã€‚{2,}', text_content)
    
    for i, paragraph in enumerate(paragraphs):
        if len(paragraph.strip()) < 10:
            continue
        
        # ä½¿ç”¨å¢å¼·åŒ¹é…æª¢æŸ¥æ®µè½
        has_keyword, matches = enhanced_first_stage_filter(paragraph, keywords)
        
        if has_keyword:
            # æª¢æŸ¥æ‰€æœ‰æ•¸å€¼æ¨¡å¼
            all_numbers = []
            for pattern in number_patterns:
                numbers = re.findall(pattern, paragraph, re.IGNORECASE)
                all_numbers.extend(numbers)
            
            # æª¢æŸ¥æ‰€æœ‰ç™¾åˆ†æ¯”æ¨¡å¼
            all_percentages = []
            for pattern in percentage_patterns:
                percentages = re.findall(pattern, paragraph, re.IGNORECASE)
                all_percentages.extend(percentages)
            
            if all_numbers or all_percentages:
                for match in matches:
                    results.append({
                        'keyword': match['keyword'],
                        'original_keyword': match['original_keyword'],
                        'paragraph': paragraph.strip(),
                        'paragraph_number': i + 1,
                        'numbers': all_numbers,
                        'percentages': all_percentages,
                        'page_info': f"æ®µè½{i+1}",
                        'match_confidence': match['confidence'],
                        'match_type': match['match_type']
                    })
    
    return results

def get_all_keywords():
    """ç²å–æ‰€æœ‰é—œéµå­—ï¼ˆåŒ…å«é€£çºŒå’Œä¸é€£çºŒï¼‰"""
    all_keywords = []
    for config in ESG_KEYWORDS_CONFIG.values():
        all_keywords.extend(config["keywords"])
    return all_keywords

# =============================================================================
# æ¸¬è©¦å’Œé©—è­‰å‡½æ•¸
# =============================================================================

def test_with_real_data():
    """ä½¿ç”¨çœŸå¯¦æ•¸æ“šæ¸¬è©¦ï¼ˆåŸºæ–¼ä¸Šå‚³çš„åœ–ç‰‡å…§å®¹ï¼‰"""
    
    test_text = """
    PPæ£§æ¿å›æ”¶
    å°å…¥ä½¿ç”¨å¤–æ¡å›æ”¶PPç²’åŠä¼æ¥­å…§ç”Ÿç”¢ä¹‹å»¢æ–™ç‚ºä¸»ï¼Œç”Ÿç”¢å„ªæ¿æä¹‹ç’°ä¿å‹å¡‘è† æ¿ï¼Œ2023å¹´åº¦ç”¢é‡ç‚º12,809å™¸
    ï¼ˆå…¶ä¸­å«æœ‰88.4%ï¼‰ï¼Œå…·ç’°ä¿ç”¢å“æ¨™ç« èªè­‰ï¼Œè¼ƒä¸€èˆ¬ç”¢å“æ¸›æœ‰76%ä¹‹æ¸›ç¢³æ•ˆç›Šã€‚
    
    çº–ç‰©å›æ”¶
    å·²å…·æœ‰ç¶ PETåŸå¸ƒã€æˆå¸ƒåŠèšç¾¥ä¹™çƒ¯å›æ”¶é‡ç”¢æŠ€è¡“ï¼Œä¸¦å·²é”æˆæ—¥ç”¢1,000å™¸ä¹‹å‰ç½®ç†åŠæª¢è¦–ç”¢èƒ½ã€‚ä¸¦å·²
    é–‹ç™¼é«˜ç«¯æœå‹™BHETåŒ–å­¸é–“æ”¶æŠ€è¡“ï¼Œä¸¦å»ºè¨­åœ¨åœ°å»¢å·¥å» ï¼Œåšç‚ºæœªä¾†æ”¾å¤§é‡ç”¢ä¹‹åŸºç¤ã€‚
    
    MLCC(ç©å±¤é™¶ç“·é›»å®¹)ç”¨éŠ€è†œé‹å›æ”¶
    å…¨æˆ¶ä½¿ç”¨æ¶²åŸæº¶æ”¶å‹è’™é›†å†ç”Ÿé‡ï¼Œæ¶ˆæˆ¶å·²å¼•é€²æˆåˆ†å¾Œå·²ç”¨æ•ˆæœï¼Œä¸­æ°´å›æ”¶èƒ½åŠ›UPç½®å¯¦æ”¹å–„å ´æ™ºç”¢å“ï¼Œå›
    æ”¶ç”¢èƒ½æ¯600å™¸/æœˆï¼Œå¯å›æ”¶åœ‹å…§MLCCåŠå…‰å­¸ç­‰å­¸å®¢ä½¿ç”¨å¾Œä¹‹å»¢æ–™é—œã€‚
    """
    
    keywords = get_all_keywords()
    
    print("ğŸ§ª çœŸå¯¦æ•¸æ“šæ¸¬è©¦çµæœ")
    print("=" * 60)
    
    # ç¬¬ä¸€éšæ®µç¯©é¸
    passed, matches = enhanced_first_stage_filter(test_text, keywords)
    print(f"ç¬¬ä¸€éšæ®µç¯©é¸: {'âœ… é€šé' if passed else 'âŒ æœªé€šé'}")
    print(f"æ‰¾åˆ°åŒ¹é…: {len(matches)} å€‹\n")
    
    for match in matches:
        print(f"ğŸ¯ é—œéµå­—: {match['keyword']}")
        print(f"   ä¿¡å¿ƒåˆ†æ•¸: {match['confidence']:.2f}")
        print(f"   åŒ¹é…é¡å‹: {match['match_type']}")
        print()
    
    # ç¬¬äºŒéšæ®µç¯©é¸
    results = enhanced_second_stage_filter(test_text, keywords)
    print(f"ç¬¬äºŒéšæ®µç¯©é¸: æ‰¾åˆ° {len(results)} å€‹å«æ•¸å€¼çš„çµæœ")
    print("=" * 60)
    
    for i, result in enumerate(results, 1):
        print(f"\nğŸ“Š çµæœ {i}:")
        print(f"é—œéµå­—: {result['keyword']}")
        print(f"åŒ¹é…é¡å‹: {result['match_type']}")
        print(f"æ•¸å€¼: {result['numbers']}")
        print(f"ç™¾åˆ†æ¯”: {result['percentages']}")
        print(f"ä¿¡å¿ƒåˆ†æ•¸: {result['match_confidence']:.2f}")
        print(f"æ®µè½å…§å®¹: {result['paragraph'][:150]}...")
        print("-" * 40)

def validate_keywords_config():
    """é©—è­‰é—œéµå­—é…ç½®"""
    print("ğŸ” é©—è­‰é—œéµå­—é…ç½®...")
    
    total_keywords = 0
    continuous_count = 0
    discontinuous_count = 0
    
    for indicator, config in ESG_KEYWORDS_CONFIG.items():
        keywords = config["keywords"]
        total_keywords += len(keywords)
        
        for keyword in keywords:
            if isinstance(keyword, str):
                continuous_count += 1
            elif isinstance(keyword, tuple):
                discontinuous_count += 1
    
    print(f"âœ… ç¸½é—œéµå­—æ•¸: {total_keywords}")
    print(f"   é€£çºŒé—œéµå­—: {continuous_count}")
    print(f"   ä¸é€£çºŒé—œéµå­—: {discontinuous_count}")
    print(f"   ä¸é€£çºŒé—œéµå­—æ¯”ä¾‹: {discontinuous_count/total_keywords*100:.1f}%")

if __name__ == "__main__":
    print("ğŸš€ æ•´åˆç‰ˆé—œéµå­—åŒ¹é…ç³»çµ±æ¸¬è©¦")
    print("=" * 60)
    
    validate_keywords_config()
    print()
    test_with_real_data()