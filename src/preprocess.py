import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from tqdm import tqdm
sys.path.append(str(Path(__file__).parent))
from config import *

class DocumentMetadataExtractor:
    """æ–‡æª”å…ƒæ•¸æ“šæå–å™¨ï¼Œç”¨æ–¼æå–å…¬å¸åç¨±å’Œå ±å‘Šå¹´åº¦"""
    
    def __init__(self):
        # å…¬å¸åç¨±åŒ¹é…æ¨¡å¼
        self.company_patterns = [
            r'([^,\n]+?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸.*?(?:å¹´|å¹´åº¦).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([^,\n]+?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸.*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([^,\n\d]+?)å…¬å¸.*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([\u4e00-\u9fff]{2,10})(?:è‚¡ä»½)?æœ‰é™å…¬å¸'
        ]
        
        # å¹´åº¦åŒ¹é…æ¨¡å¼
        self.year_patterns = [
            r'(20\d{2})\s*å¹´(?:åº¦)?.*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š.*?(20\d{2})',
            r'(20\d{2})\s*å¹´(?:åº¦)?å ±å‘Š',
            r'å ±å‘Š.*?æœŸé–“.*?(20\d{2})',
            r'(20\d{2})',  # æœ€å¾Œå‚™ç”¨ï¼šä»»ä½•å››ä½æ•¸å¹´ä»½
        ]
    
    def extract_metadata(self, pdf_path: str) -> Dict[str, str]:
        """
        å¾PDFæ–‡ä»¶ä¸­æå–å…¬å¸åç¨±å’Œå ±å‘Šå¹´åº¦
        
        Returns:
            DictåŒ…å« 'company_name' å’Œ 'report_year'
        """
        print(f"ğŸ“‹ æå–æ–‡æª”å…ƒæ•¸æ“š: {Path(pdf_path).name}")
        
        try:
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            
            # ä¸»è¦å¾å‰å¹¾é æå–ä¿¡æ¯
            text_for_extraction = ""
            for page in pages[:5]:  # åªæª¢æŸ¥å‰5é 
                text_for_extraction += page.page_content + "\n"
            
            # æå–å…¬å¸åç¨±
            company_name = self._extract_company_name(text_for_extraction)
            
            # æå–å ±å‘Šå¹´åº¦
            report_year = self._extract_report_year(text_for_extraction)
            
            # å¦‚æœç„¡æ³•å¾æ–‡æª”ä¸­æå–ï¼Œå˜—è©¦å¾æ–‡ä»¶åæå–
            if not company_name or not report_year:
                filename_metadata = self._extract_from_filename(Path(pdf_path).name)
                if not company_name:
                    company_name = filename_metadata.get('company_name', 'æœªçŸ¥å…¬å¸')
                if not report_year:
                    report_year = filename_metadata.get('report_year', 'æœªçŸ¥å¹´åº¦')
            
            result = {
                'company_name': company_name,
                'report_year': report_year
            }
            
            print(f"âœ… æå–åˆ°ï¼š{company_name} - {report_year}")
            return result
            
        except Exception as e:
            print(f"âš ï¸ å…ƒæ•¸æ“šæå–å¤±æ•—: {e}")
            return {
                'company_name': Path(pdf_path).stem,
                'report_year': 'æœªçŸ¥å¹´åº¦'
            }
    
    def _extract_company_name(self, text: str) -> str:
        """æå–å…¬å¸åç¨±"""
        text_clean = re.sub(r'\s+', ' ', text[:2000])  # åªæª¢æŸ¥å‰2000å­—ç¬¦
        
        for pattern in self.company_patterns:
            matches = re.findall(pattern, text_clean, re.IGNORECASE)
            if matches:
                company_name = matches[0].strip()
                # æ¸…ç†å…¬å¸åç¨±
                company_name = re.sub(r'^[\s\d\-\.]+', '', company_name)
                company_name = re.sub(r'[\s\-\.]+$', '', company_name)
                if len(company_name) >= 2 and len(company_name) <= 20:
                    return company_name
        
        return ""
    
    def _extract_report_year(self, text: str) -> str:
        """æå–å ±å‘Šå¹´åº¦"""
        text_clean = re.sub(r'\s+', ' ', text[:2000])
        
        for pattern in self.year_patterns:
            matches = re.findall(pattern, text_clean)
            if matches:
                year = matches[0]
                # é©—è­‰å¹´ä»½åˆç†æ€§
                if 2015 <= int(year) <= 2030:
                    return year
        
        return ""
    
    def _extract_from_filename(self, filename: str) -> Dict[str, str]:
        """å¾æ–‡ä»¶åæå–å…ƒæ•¸æ“šä½œç‚ºå‚™ç”¨"""
        result = {'company_name': '', 'report_year': ''}
        
        # æå–å¹´ä»½
        year_match = re.search(r'(20\d{2})', filename)
        if year_match:
            result['report_year'] = year_match.group(1)
        
        # ç°¡å–®çš„å…¬å¸åç¨±æå–ï¼ˆå»é™¤å¹´ä»½ã€å‰¯æª”åç­‰ï¼‰
        company_part = re.sub(r'(20\d{2}|ESG|æ°¸çºŒ|å ±å‘Š|\.pdf)', '', filename, flags=re.IGNORECASE)
        company_part = re.sub(r'[_\-\s]+', '', company_part).strip()
        if company_part:
            result['company_name'] = company_part
        
        return result

def preprocess_documents(pdf_path: str, output_db_path: str = None, metadata: Dict[str, str] = None):
    """é è™•ç†PDFæ–‡æª”ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«"""
    
    if output_db_path is None:
        output_db_path = VECTOR_DB_PATH
    
    print(f"é–‹å§‹è™•ç†PDF: {pdf_path}")
    
    # 1. è¼‰å…¥PDF
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°PDFæ–‡ä»¶: {pdf_path}")
    
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    print(f"æˆåŠŸè¼‰å…¥ {len(pages)} é ")
    
    # 2. ç‚ºæ¯å€‹æ–‡æª”æ·»åŠ å…ƒæ•¸æ“š
    if metadata:
        for page in pages:
            page.metadata.update(metadata)
            page.metadata['source_file'] = Path(pdf_path).name
    
    # 3. æ–‡æœ¬åˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", ".", "ã€‚", "ï¼Œ", " ", ""]
    )
    
    print("æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
    chunks = text_splitter.split_documents(pages)
    print(f"åˆ†å‰²æˆ {len(chunks)} å€‹æ–‡æœ¬å¡Š")
    
    # 4. åˆå§‹åŒ–embeddingæ¨¡å‹
    print(f"è¼‰å…¥embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'}
    )
    
    # 5. å»ºç«‹å‘é‡è³‡æ–™åº«
    print("å»ºç«‹å‘é‡è³‡æ–™åº«...")
    db = FAISS.from_documents(chunks, embedding_model)
    
    # 6. ä¿å­˜è³‡æ–™åº«
    os.makedirs(os.path.dirname(output_db_path), exist_ok=True)
    db.save_local(output_db_path)
    print(f"å‘é‡è³‡æ–™åº«å·²ä¿å­˜åˆ°: {output_db_path}")
    
    return db

def preprocess_multiple_documents(pdf_paths: List[str]) -> Dict[str, Dict]:
    """
    æ‰¹é‡é è™•ç†å¤šå€‹PDFæ–‡æª”
    
    Returns:
        Dict: {pdf_path: {'db_path': str, 'metadata': dict}}
    """
    print(f"ğŸš€ é–‹å§‹æ‰¹é‡é è™•ç† {len(pdf_paths)} å€‹PDFæ–‡ä»¶")
    print("=" * 60)
    
    metadata_extractor = DocumentMetadataExtractor()
    results = {}
    
    for pdf_path in pdf_paths:
        try:
            print(f"\nğŸ“„ è™•ç†æ–‡ä»¶: {Path(pdf_path).name}")
            
            # 1. æå–å…ƒæ•¸æ“š
            metadata = metadata_extractor.extract_metadata(pdf_path)
            
            # 2. ç‚ºæ¯å€‹æ–‡ä»¶å‰µå»ºç¨ç«‹çš„å‘é‡è³‡æ–™åº«
            pdf_name = Path(pdf_path).stem
            db_path = os.path.join(
                os.path.dirname(VECTOR_DB_PATH),
                f"esg_db_{pdf_name}"
            )
            
            # 3. é è™•ç†æ–‡æª”
            preprocess_documents(pdf_path, db_path, metadata)
            
            results[pdf_path] = {
                'db_path': db_path,
                'metadata': metadata,
                'pdf_name': pdf_name
            }
            
            print(f"âœ… å®Œæˆ: {metadata['company_name']} - {metadata['report_year']}")
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•— {Path(pdf_path).name}: {e}")
            continue
    
    print(f"\nğŸ‰ æ‰¹é‡é è™•ç†å®Œæˆï¼æˆåŠŸè™•ç† {len(results)}/{len(pdf_paths)} å€‹æ–‡ä»¶")
    return results

def main():
    """ä¸»å‡½æ•¸"""
    # æª¢æŸ¥dataç›®éŒ„ä¸­çš„PDFæ–‡ä»¶
    data_dir = Path(DATA_PATH)
    pdf_files = list(data_dir.glob("*.pdf"))
    
    if not pdf_files:
        print(f"éŒ¯èª¤: åœ¨ {DATA_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
        print("è«‹å°‡ESGå ±å‘ŠPDFæ–‡ä»¶æ”¾å…¥dataç›®éŒ„ä¸­")
        return
    
    print(f"æ‰¾åˆ° {len(pdf_files)} å€‹PDFæ–‡ä»¶:")
    for pdf_file in pdf_files:
        print(f"  - {pdf_file.name}")
    
    # è©¢å•è™•ç†æ¨¡å¼
    if len(pdf_files) == 1:
        # å–®æ–‡ä»¶æ¨¡å¼
        pdf_path = pdf_files[0]
        print(f"\nå–®æ–‡ä»¶æ¨¡å¼ï¼šè™•ç† {pdf_path.name}")
        
        try:
            metadata_extractor = DocumentMetadataExtractor()
            metadata = metadata_extractor.extract_metadata(str(pdf_path))
            preprocess_documents(str(pdf_path), metadata=metadata)
            print("âœ… é è™•ç†å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ é è™•ç†å¤±æ•—: {e}")
    else:
        # å¤šæ–‡ä»¶æ¨¡å¼
        print(f"\nå¤šæ–‡ä»¶æ¨¡å¼ï¼šè™•ç† {len(pdf_files)} å€‹æ–‡ä»¶")
        confirm = input("ç¢ºå®šè¦æ‰¹é‡è™•ç†æ‰€æœ‰æ–‡ä»¶å—ï¼Ÿ(y/n): ").strip().lower()
        
        if confirm == 'y':
            try:
                results = preprocess_multiple_documents([str(f) for f in pdf_files])
                print(f"âœ… æ‰¹é‡é è™•ç†å®Œæˆï¼")
                
                # é¡¯ç¤ºè™•ç†çµæœæ‘˜è¦
                print("\nğŸ“‹ è™•ç†æ‘˜è¦:")
                for pdf_path, result in results.items():
                    metadata = result['metadata']
                    print(f"  âœ“ {Path(pdf_path).name}: {metadata['company_name']} - {metadata['report_year']}")
                    
            except Exception as e:
                print(f"âŒ æ‰¹é‡é è™•ç†å¤±æ•—: {e}")

if __name__ == "__main__":
    main()