#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESGå ±å‘Šæ›¸é è™•ç†æ¨¡çµ„ v1.0
è™•ç†PDFæ–‡ä»¶ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from tqdm import tqdm
sys.path.append(str(Path(__file__).parent))
from config import *

class DocumentMetadataExtractor:
    """æ–‡æª”å…ƒæ•¸æ“šæå–å™¨"""
    
    def __init__(self):
        # å…¬å¸åç¨±åŒ¹é…æ¨¡å¼
        self.company_patterns = [
            # é«˜å„ªå…ˆç´šï¼šåŒ…å«å®Œæ•´å ±å‘Šæ¨™é¡Œçš„æ¨¡å¼
            r'([^,\n\d]{2,25}?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸\s*(202[0-9])\s*å¹´(?:åº¦)?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([^,\n\d]{2,25}?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸.*?(202[0-9]).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            
            # ä¸­å„ªå…ˆç´šï¼šå…¬å¸åç¨±+å ±å‘Šé¡å‹
            r'([^,\n\d]{2,25}?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸.*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([^,\n\d]{2,25}?)å…¬å¸.*?(?:202[0-9]).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            
            # ä½å„ªå…ˆç´šï¼šåƒ…å…¬å¸åç¨±
            r'([\u4e00-\u9fff]{2,15})(?:è‚¡ä»½)?æœ‰é™å…¬å¸',
            r'([\u4e00-\u9fff]{2,15})å…¬å¸(?:[^\u4e00-\u9fff]|$)',
        ]
        
        # å¹´åº¦åŒ¹é…æ¨¡å¼
        self.year_patterns = [
            # é«˜ç²¾ç¢ºåº¦ï¼šæ˜ç¢ºçš„å ±å‘Šå¹´åº¦è¡¨é”
            r'(202[0-9])\s*å¹´(?:åº¦)?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?',
            r'(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?.*?(202[0-9])\s*å¹´(?:åº¦)?',
            
            # ä¸­ç²¾ç¢ºåº¦ï¼šå ±å‘Šæ¨™é¡Œä¸­çš„å¹´åº¦
            r'(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?.*?(202[0-9])',
            r'(202[0-9]).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?',
            
            # åŒ…å«"å¹´å ±"çš„æ¨¡å¼
            r'(202[0-9])\s*å¹´(?:åº¦)?å¹´å ±',
            r'å¹´å ±.*?(202[0-9])',
            
            # å…¶ä»–å¯èƒ½çš„å¹´åº¦è¡¨é”
            r'å ±å‘Š(?:æ›¸)?æœŸé–“.*?(202[0-9])',
            r'è²¡æ”¿å¹´åº¦.*?(202[0-9])',
            r'æœƒè¨ˆå¹´åº¦.*?(202[0-9])',
            
            # æœ€ä½å„ªå…ˆç´šï¼šä»»ä½•å››ä½æ•¸å¹´ä»½
            r'(202[0-9])',
        ]
    
    def extract_metadata(self, pdf_path: str) -> Dict[str, str]:
        """
        æå–æ–‡æª”å…ƒæ•¸æ“š
        
        Returns:
            DictåŒ…å« 'company_name' å’Œ 'report_year'
        """
        print(f"ğŸ“‹ æå–æ–‡æª”å…ƒæ•¸æ“š: {Path(pdf_path).name}")
        
        try:
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            
            # æª¢æŸ¥å‰8é 
            text_for_extraction = ""
            pages_to_check = min(8, len(pages))
            
            for page in pages[:pages_to_check]:
                text_for_extraction += page.page_content + "\n"
            
            # å…ˆå˜—è©¦å¾æ–‡ä»¶åæå–ä½œç‚ºåƒè€ƒ
            filename_metadata = self._extract_from_filename(Path(pdf_path).name)
            
            # æå–å…¬å¸åç¨±å’Œå ±å‘Šå¹´åº¦
            company_name = self._extract_company_name(text_for_extraction, filename_metadata.get('company_name', ''))
            report_year = self._extract_report_year(text_for_extraction, filename_metadata.get('report_year', ''))
            
            # å¦‚æœä»ç„¡æ³•æå–åˆ°æœ‰æ•ˆä¿¡æ¯ï¼Œä½¿ç”¨æ–‡ä»¶åä½œç‚ºå‚™ç”¨
            if not company_name or company_name == "æœªçŸ¥å…¬å¸":
                company_name = filename_metadata.get('company_name', Path(pdf_path).stem)
            
            if not report_year or report_year == "æœªçŸ¥å¹´åº¦":
                report_year = filename_metadata.get('report_year', 'æœªçŸ¥å¹´åº¦')
            
            result = {
                'company_name': company_name,
                'report_year': report_year
            }
            
            print(f"âœ… æå–åˆ°ï¼š{company_name} - {report_year}")
            return result
            
        except Exception as e:
            print(f"âš ï¸ å…ƒæ•¸æ“šæå–å¤±æ•—: {e}")
            return {
                'company_name': Path(pdf_path).stem,
                'report_year': 'æœªçŸ¥å¹´åº¦'
            }
    
    def _extract_company_name(self, text: str, filename_hint: str = "") -> str:
        """æå–å…¬å¸åç¨±"""
        text_clean = re.sub(r'\s+', ' ', text[:3000])
        
        best_match = ""
        best_confidence = 0
        
        for i, pattern in enumerate(self.company_patterns):
            matches = re.findall(pattern, text_clean, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        company_candidate = match[0].strip()
                    else:
                        company_candidate = match.strip()
                    
                    # æ¸…ç†å…¬å¸åç¨±
                    company_candidate = self._clean_company_name(company_candidate)
                    
                    if self._is_valid_company_name(company_candidate):
                        # è¨ˆç®—ä¿¡å¿ƒåº¦
                        confidence = (len(self.company_patterns) - i) / len(self.company_patterns)
                        
                        # å¦‚æœèˆ‡æª”åæç¤ºåŒ¹é…ï¼ŒåŠ åˆ†
                        if filename_hint and filename_hint in company_candidate:
                            confidence += 0.2
                        
                        if confidence > best_confidence:
                            best_match = company_candidate
                            best_confidence = confidence
        
        return best_match if best_match else ""
    
    def _extract_report_year(self, text: str, filename_hint: str = "") -> str:
        """æå–å ±å‘Šå¹´åº¦"""
        text_clean = re.sub(r'\s+', ' ', text[:3000])
        
        best_year = ""
        best_confidence = 0
        
        for i, pattern in enumerate(self.year_patterns):
            matches = re.findall(pattern, text_clean, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                for match in matches:
                    year_candidate = match if isinstance(match, str) else match[0]
                    
                    # é©—è­‰å¹´ä»½åˆç†æ€§
                    if self._is_valid_year(year_candidate):
                        # è¨ˆç®—ä¿¡å¿ƒåº¦
                        confidence = (len(self.year_patterns) - i) / len(self.year_patterns)
                        
                        # ç‰¹åˆ¥åŠ åˆ†ï¼šå¦‚æœæ˜¯æ˜ç¢ºçš„å ±å‘Šæ›¸å¹´åº¦è¡¨é”
                        if i < 4:
                            confidence += 0.3
                        
                        # å¦‚æœèˆ‡æª”åæç¤ºåŒ¹é…ï¼ŒåŠ åˆ†
                        if filename_hint and year_candidate == filename_hint:
                            confidence += 0.2
                        
                        # å„ªå…ˆé¸æ“‡è¼ƒæ–°çš„å¹´åº¦
                        if confidence > best_confidence or (confidence == best_confidence and int(year_candidate) > int(best_year or "0")):
                            best_year = year_candidate
                            best_confidence = confidence
        
        return best_year if best_year else ""
    
    def _clean_company_name(self, raw_name: str) -> str:
        """æ¸…ç†å…¬å¸åç¨±"""
        if not raw_name:
            return ""
        
        # å»é™¤å‰å¾Œçš„ç©ºç™½ã€æ•¸å­—ã€ç‰¹æ®Šç¬¦è™Ÿ
        cleaned = re.sub(r'^[\s\d\-\.ã€‚ï¼Œ,\(\)ï¼ˆï¼‰ã€ã€‘]+', '', raw_name)
        cleaned = re.sub(r'[\s\-\.ã€‚ï¼Œ,\(\)ï¼ˆï¼‰ã€ã€‘]+$', '', cleaned)
        
        # å»é™¤å¸¸è¦‹çš„ç„¡é—œè©å½™
        noise_words = [
            'å ±å‘Š', 'æ›¸', 'æ°¸çºŒ', 'ESG', 'ä¼æ¥­ç¤¾æœƒè²¬ä»»', 
            'ç¬¬', 'ç« ', 'ç¯€', 'é ', 'é™„éŒ„', 'ç›®éŒ„'
        ]
        for word in noise_words:
            cleaned = re.sub(f'^{word}', '', cleaned)
            cleaned = re.sub(f'{word}$', '', cleaned)
        
        return cleaned.strip()
    
    def _is_valid_company_name(self, name: str) -> bool:
        """é©—è­‰å…¬å¸åç¨±çš„æœ‰æ•ˆæ€§"""
        if not name or len(name) < 2 or len(name) > 25:
            return False
        
        # æ’é™¤æ˜é¡¯ä¸æ˜¯å…¬å¸åç¨±çš„è©å½™
        invalid_patterns = [
            r'^[0-9\.\-\s]+$',  # ç´”æ•¸å­—æˆ–ç¬¦è™Ÿ
            r'^[a-zA-Z\s]+$',   # ç´”è‹±æ–‡
            r'ç¬¬.*?ç« |ç¬¬.*?ç¯€|é .*?ç¢¼',  # ç« ç¯€é ç¢¼
        ]
        
        for pattern in invalid_patterns:
            if re.match(pattern, name):
                return False
        
        return True
    
    def _is_valid_year(self, year: str) -> bool:
        """é©—è­‰å¹´ä»½çš„æœ‰æ•ˆæ€§"""
        try:
            year_int = int(year)
            return 2015 <= year_int <= 2030
        except ValueError:
            return False
    
    def _extract_from_filename(self, filename: str) -> Dict[str, str]:
        """å¾æ–‡ä»¶åæå–å…ƒæ•¸æ“šä½œç‚ºè¼”åŠ©ä¿¡æ¯"""
        result = {'company_name': '', 'report_year': ''}
        
        # æå–å¹´ä»½
        year_patterns = [
            r'(202[0-9])',
            r'(20[12][0-9])',
        ]
        
        for pattern in year_patterns:
            year_match = re.search(pattern, filename)
            if year_match:
                result['report_year'] = year_match.group(1)
                break
        
        # æå–å…¬å¸åç¨±
        company_part = filename
        
        # å»é™¤å‰¯æª”å
        company_part = re.sub(r'\.pdf$', '', company_part, flags=re.IGNORECASE)
        
        # å»é™¤å¹´ä»½
        company_part = re.sub(r'202[0-9]', '', company_part)
        company_part = re.sub(r'20[12][0-9]', '', company_part)
        
        # å»é™¤å¸¸è¦‹é—œéµè©
        keywords_to_remove = [
            'ESG', 'esg', 'æ°¸çºŒ', 'å ±å‘Š', 'æ›¸', 'ä¼æ¥­ç¤¾æœƒè²¬ä»»', 
            '_', '-', 'æå–', 'çµæœ'
        ]
        for keyword in keywords_to_remove:
            company_part = re.sub(keyword, '', company_part, flags=re.IGNORECASE)
        
        # æ¸…ç†å‰©é¤˜çš„ç¬¦è™Ÿå’Œç©ºç™½
        company_part = re.sub(r'[_\-\s]+', ' ', company_part).strip()
        
        if company_part and len(company_part) >= 2:
            result['company_name'] = company_part
        
        return result

def preprocess_documents(pdf_path: str, output_db_path: str = None, metadata: Dict[str, str] = None):
    """é è™•ç†PDFæ–‡æª”ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«"""
    
    if output_db_path is None:
        output_db_path = VECTOR_DB_PATH
    
    print(f"é–‹å§‹è™•ç†PDF: {pdf_path}")
    
    # 1. è¼‰å…¥PDF
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°PDFæ–‡ä»¶: {pdf_path}")
    
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    print(f"æˆåŠŸè¼‰å…¥ {len(pages)} é ")
    
    # 2. ç‚ºæ¯å€‹æ–‡æª”æ·»åŠ å…ƒæ•¸æ“š
    if metadata:
        for page in pages:
            page.metadata.update(metadata)
            page.metadata['source_file'] = Path(pdf_path).name
            
            # æ·»åŠ é ç¢¼ä¿¡æ¯ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
            if 'page' not in page.metadata:
                page.metadata['page'] = pages.index(page) + 1
    
    # 3. æ–‡æœ¬åˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=180,
        separators=["\n\n", "\n", ".", "ã€‚", "ï¼Œ", " ", ""]
    )
    
    print("æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
    chunks = text_splitter.split_documents(pages)
    print(f"åˆ†å‰²æˆ {len(chunks)} å€‹æ–‡æœ¬å¡Š")
    
    # 4. åˆå§‹åŒ–embeddingæ¨¡å‹
    print(f"è¼‰å…¥embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'}
    )
    
    # 5. å»ºç«‹å‘é‡è³‡æ–™åº«
    print("å»ºç«‹å‘é‡è³‡æ–™åº«...")
    db = FAISS.from_documents(chunks, embedding_model)
    
    # 6. ä¿å­˜è³‡æ–™åº«
    os.makedirs(os.path.dirname(output_db_path), exist_ok=True)
    db.save_local(output_db_path)
    print(f"å‘é‡è³‡æ–™åº«å·²ä¿å­˜åˆ°: {output_db_path}")
    
    return db

def preprocess_multiple_documents(pdf_paths: List[str]) -> Dict[str, Dict]:
    """
    æ‰¹é‡é è™•ç†å¤šå€‹PDFæ–‡æª”
    
    Returns:
        Dict: {pdf_path: {'db_path': str, 'metadata': dict}}
    """
    print(f"ğŸš€ é–‹å§‹æ‰¹é‡é è™•ç† {len(pdf_paths)} å€‹PDFæ–‡ä»¶")
    print("=" * 60)
    
    metadata_extractor = DocumentMetadataExtractor()
    results = {}
    
    for pdf_path in pdf_paths:
        try:
            print(f"\nğŸ“„ è™•ç†æ–‡ä»¶: {Path(pdf_path).name}")
            
            # 1. å…ƒæ•¸æ“šæå–
            metadata = metadata_extractor.extract_metadata(pdf_path)
            
            # 2. ç‚ºæ¯å€‹æ–‡ä»¶å‰µå»ºç¨ç«‹çš„å‘é‡è³‡æ–™åº«
            pdf_name = Path(pdf_path).stem
            db_path = os.path.join(
                os.path.dirname(VECTOR_DB_PATH),
                f"esg_db_{pdf_name}"
            )
            
            # 3. é è™•ç†æ–‡æª”
            preprocess_documents(pdf_path, db_path, metadata)
            
            results[pdf_path] = {
                'db_path': db_path,
                'metadata': metadata,
                'pdf_name': pdf_name
            }
            
            print(f"âœ… å®Œæˆ: {metadata['company_name']} - {metadata['report_year']}")
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•— {Path(pdf_path).name}: {e}")
            continue
    
    print(f"\nğŸ‰ æ‰¹é‡é è™•ç†å®Œæˆï¼æˆåŠŸè™•ç† {len(results)}/{len(pdf_paths)} å€‹æ–‡ä»¶")
    
    # é¡¯ç¤ºæå–çµæœæ‘˜è¦
    print(f"\nğŸ“‹ æå–æ‘˜è¦:")
    companies_years = {}
    for pdf_path, result in results.items():
        metadata = result['metadata']
        company = metadata['company_name']
        year = metadata['report_year']
        
        if company not in companies_years:
            companies_years[company] = []
        companies_years[company].append(year)
    
    for company, years in companies_years.items():
        years_str = ', '.join(sorted(set(years), reverse=True))
        print(f"   ğŸ¢ {company}: {years_str}")
    
    return results

# ============================================================================= 
# åœ¨ preprocess.py æ–‡ä»¶æœ«å°¾ï¼ˆdef main(): ä¹‹å‰ï¼‰æ·»åŠ ä»¥ä¸‹ä»£ç¢¼
# =============================================================================

# å°ç£ä¸Šå¸‚æ«ƒå¡‘è† å·¥æ¥­å…¬å¸ä»£è™Ÿæ˜ å°„è¡¨
# æ›´æ–°çš„å®Œæ•´å…¬å¸æ˜ å°„è¡¨
TAIWAN_COMPANIES_EXTENDED = {
    # 13é–‹é ­å¡‘è† å·¥æ¥­
    "å°å¡‘": ("1301", "å°å¡‘"),
    "å°ç£å¡‘è† ": ("1301", "å°å¡‘"),
    "å°ç£å¡‘è† å·¥æ¥­": ("1301", "å°å¡‘"),
    "å°å¡‘å·¥æ¥­": ("1301", "å°å¡‘"),
    "å°å¡‘é›†åœ˜": ("1301", "å°å¡‘"),
    
    "å—äº": ("1303", "å—äº"),
    "å—äºå¡‘è† ": ("1303", "å—äº"),
    "å—äºå¡‘è† å·¥æ¥­": ("1303", "å—äº"),
    "å—äºå…¬å¸": ("1303", "å—äº"),
    
    "å°èš": ("1304", "å°èš"),
    "å°ç£èšåˆ": ("1304", "å°èš"),
    "å°ç£èšåˆåŒ–å­¸": ("1304", "å°èš"),
    
    "è¯å¤": ("1305", "è¯å¤"),
    "è¯å¤æµ·ç£": ("1305", "è¯å¤"),
    "è¯å¤æµ·ç£å¡‘è† ": ("1305", "è¯å¤"),
    "å°ç£æ°¯ä¹™çƒ¯å·¥æ¥­": ("1305", "è¯å¤"),
    
    "ä¸‰èŠ³": ("1307", "ä¸‰èŠ³"),
    "ä¸‰èŠ³åŒ–å­¸": ("1307", "ä¸‰èŠ³"),
    "ä¸‰èŠ³åŒ–å­¸å·¥æ¥­": ("1307", "ä¸‰èŠ³"),
    "ä¸‰èŠ³åŒ–å·¥": ("1307", "ä¸‰èŠ³"),
    
    "äºèš": ("1308", "äºèš"),
    "äºæ´²èšåˆ": ("1308", "äºèš"),
    
    "å°é”åŒ–": ("1309", "å°é”åŒ–"),
    "å°ç£é”åŒ–": ("1309", "å°é”åŒ–"),
    
    "å°è‹¯": ("1310", "å°è‹¯"),
    "å°ç£è‹¯ä¹™çƒ¯": ("1310", "å°è‹¯"),
    
    "åœ‹å–¬": ("1312", "åœ‹å–¬"),
    "åœ‹å–¬çŸ³åŒ–": ("1312", "åœ‹å–¬"),
    "åœ‹æ©‹": ("1312", "åœ‹å–¬"),  # å¸¸è¦‹å¯«æ³•
    
    "åœ‹å–¬ç‰¹": ("1312A", "åœ‹å–¬ç‰¹"),
    
    "è¯æˆ": ("1313", "è¯æˆ"),
    "è¯æˆåŒ–å­¸": ("1313", "è¯æˆ"),
    "è¯æˆåŒ–ç§‘": ("1313", "è¯æˆ"),
    "å¾·åœ‹èŠå› æŠ€è¡“ç›£è­·é¡§å•": ("1313", "è¯æˆ"),
    
    "ä¸­çŸ³åŒ–": ("1314", "ä¸­çŸ³åŒ–"),
    "ä¸­åœ‹çŸ³æ²¹åŒ–å­¸": ("1314", "ä¸­çŸ³åŒ–"),
    
    "é”æ–°": ("1315", "é”æ–°"),
    "é”æ–°å·¥æ¥­": ("1315", "é”æ–°"),
    
    "ä¸Šæ›œ": ("1316", "ä¸Šæ›œ"),
    
    "æ±é™½": ("1319", "æ±é™½"),
    "æ±é™½å¯¦æ¥­": ("1319", "æ±é™½"),
    
    "å¤§æ´‹": ("1321", "å¤§æ´‹"),
    "å¤§æ´‹å¡‘è† ": ("1321", "å¤§æ´‹"),
    
    "æ°¸è£•": ("1323", "æ°¸è£•"),
    "æ°¸è£•å¡‘è† ": ("1323", "æ°¸è£•"),
    
    "åœ°çƒ": ("1324", "åœ°çƒ"),
    "åœ°çƒç¶œåˆ": ("1324", "åœ°çƒ"),
    "åœ°çƒåŒ–å­¸": ("1324", "åœ°çƒ"),
    
    "æ†å¤§": ("1325", "æ†å¤§"),
    
    "å°åŒ–": ("1326", "å°åŒ–"),
    "å°ç£åŒ–å­¸": ("1326", "å°åŒ–"),
    "å°ç£åŒ–å­¸çº–ç¶­": ("1326", "å°åŒ–"),
    
    "å°ç¿°": ("1336", "å°ç¿°"),
    
    "å†ç”Ÿ": ("1337", "å†ç”Ÿ-KY"),
    "å†ç”Ÿ-KY": ("1337", "å†ç”Ÿ-KY"),
    "äºæ´²å¡‘è† å†ç”Ÿ": ("1337", "å†ç”Ÿ-KY"),
    
    "å»£è¯": ("1338", "å»£è¯-KY"),
    "å»£è¯-KY": ("1338", "å»£è¯-KY"),
    
    "æ˜­è¼": ("1339", "æ˜­è¼"),
    
    "å‹æ‚…": ("1340", "å‹æ‚…-KY"),
    "å‹æ‚…æ–°ææ–™": ("1340", "å‹æ‚…-KY"),
    "å‹æ‚…-KY": ("1340", "å‹æ‚…-KY"),
    
    "å¯Œæ—": ("1341", "å¯Œæ—-KY"),
    "å¯Œæ—-KY": ("1341", "å¯Œæ—-KY"),
    
    "å…«è²«": ("1342", "å…«è²«"),
    
    # 43é–‹é ­åŒ–å­¸ç”ŸæŠ€é†«ç™‚
    "ä¿¡ç«‹": ("4303", "ä¿¡ç«‹"),
    "ä¿¡ç«‹åŒ–å­¸": ("4303", "ä¿¡ç«‹"),
    
    "å‹æ˜±": ("4304", "å‹æ˜±"),
    "å‹æ˜±ç²¾å¯†": ("4304", "å‹æ˜±"),
    
    "ä¸–å ƒ": ("4305", "ä¸–å¤"),
    "ä¸–å ƒå¡‘è† ": ("4305", "ä¸–å¤"),
    
    "ç‚æ´²": ("4306", "ç‚æ´²"),  # æ›´æ­£ä»£è™Ÿ
    "ç‚æ´²è‚¡ä»½": ("4306", "ç‚æ´²"),  # æ›´æ­£ä»£è™Ÿ
    "ç‚æ´²ç§‘æŠ€": ("4306", "ç‚æ´²"),
    
    # 99é–‹é ­å…¶ä»–
    "è¬åœ‹é€š": ("9950", "è¬åœ‹é€š"),
    "è¬åœ‹é€šè·¯": ("9950", "è¬åœ‹é€š"),
    
    # æ·»åŠ å¸¸è¦‹çš„ç°¡ç¨±å’Œè®Šé«”
    "ä¿¡ç«‹åŒ–": ("4303", "ä¿¡ç«‹"),
    "å‹æ˜±ç²¾": ("4304", "å‹æ˜±"),
    "ä¸–å¤ç§‘": ("4305", "ä¸–å¤"),
    "ç‚æ´²ç§‘": ("4306", "ç‚æ´²"),
    "è¬åœ‹é€šè·¯è‚¡ä»½æœ‰é™å…¬å¸": ("9950", "è¬åœ‹é€š"),
}

def extract_company_from_filename(filename: str) -> str:
    """å¾æª”åä¸­æå–å…¬å¸åç¨±"""
    # ç§»é™¤å‰¯æª”å
    name_without_ext = filename.replace('.pdf', '').replace('.PDF', '')
    
    # å¸¸è¦‹çš„åˆ†éš”ç¬¦
    separators = ['_', '-', ' ', 'å¹´', '2024', '2023', '2022', 'esg', 'ESG', 'å ±å‘Š', 'æ›¸']
    
    # å˜—è©¦ä¸åŒçš„åˆ†å‰²æ–¹å¼
    possible_names = [name_without_ext]
    
    for sep in separators:
        parts = name_without_ext.split(sep)
        for part in parts:
            clean_part = part.strip()
            if len(clean_part) >= 2 and not clean_part.isdigit():
                possible_names.append(clean_part)
    
    # è¿”å›æœ€é•·çš„å¯èƒ½åç¨±
    valid_names = [name for name in possible_names if len(name) >= 2 and not name.isdigit()]
    return max(valid_names, key=len) if valid_names else ""

def enhanced_find_company_code_and_name(extracted_company_name: str, filename: str = "") -> Tuple[str, str, str]:
    """
    å¢å¼·ç‰ˆå…¬å¸ä»£è™Ÿå’Œåç¨±æŸ¥æ‰¾
    
    Returns:
        Tuple: (è‚¡ç¥¨ä»£è™Ÿ, æ¨™æº–å…¬å¸å, ä¾†æº)
    """
    
    def try_match_company(name: str) -> Tuple[str, str]:
        if not name:
            return "", ""
        
        # æ¸…ç†åç¨±
        clean_name = name.strip()
        
        # ç§»é™¤å¸¸è¦‹å¾Œç¶´é€²è¡ŒåŒ¹é…
        suffixes_to_remove = [
            "è‚¡ä»½æœ‰é™å…¬å¸", "æœ‰é™å…¬å¸", "è‚¡ä»½", "å…¬å¸",
            "å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "å·¥æ¥­æœ‰é™å…¬å¸", "å·¥æ¥­è‚¡ä»½", "å·¥æ¥­",
            "åŒ–å­¸å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "åŒ–å­¸å·¥æ¥­æœ‰é™å…¬å¸", "åŒ–å­¸å·¥æ¥­è‚¡ä»½", "åŒ–å­¸å·¥æ¥­", "åŒ–å­¸",
            "å¡‘è† å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸", "å¡‘è† å·¥æ¥­æœ‰é™å…¬å¸", "å¡‘è† å·¥æ¥­è‚¡ä»½", "å¡‘è† å·¥æ¥­", "å¡‘è† ",
        ]
        
        # ç”Ÿæˆåç¨±è®Šé«”
        name_variants = [clean_name]
        
        for suffix in suffixes_to_remove:
            if clean_name.endswith(suffix):
                core_name = clean_name[:-len(suffix)].strip()
                if core_name:
                    name_variants.append(core_name)
        
        # ç²¾ç¢ºåŒ¹é…
        for variant in name_variants:
            if variant in TAIWAN_COMPANIES_EXTENDED:
                code, standard_name = TAIWAN_COMPANIES_EXTENDED[variant]
                return code, standard_name
        
        # æ¨¡ç³ŠåŒ¹é…
        for variant in name_variants:
            for known_name, (code, standard_name) in TAIWAN_COMPANIES_EXTENDED.items():
                if len(known_name) >= 2:
                    # æª¢æŸ¥åŒ…å«é—œä¿‚
                    if (known_name in variant or variant in known_name) and len(known_name) >= 3:
                        return code, standard_name
                    # æª¢æŸ¥é–‹é ­åŒ¹é…
                    if variant.startswith(known_name) or known_name.startswith(variant):
                        if len(known_name) >= 2:
                            return code, standard_name
        
        return "", ""
    
    # ç­–ç•¥1ï¼šä½¿ç”¨PDFæå–çš„å…¬å¸åç¨±
    if extracted_company_name and extracted_company_name != "æœªçŸ¥å…¬å¸":
        code, name = try_match_company(extracted_company_name)
        if code and name:
            return code, name, "PDFå…§å®¹"
    
    # ç­–ç•¥2ï¼šä½¿ç”¨æª”åæå–çš„å…¬å¸åç¨±
    if filename:
        filename_company = extract_company_from_filename(filename)
        if filename_company:
            code, name = try_match_company(filename_company)
            if code and name:
                return code, name, "æª”ååˆ†æ"
    
    # ç­–ç•¥3ï¼šç›´æ¥åˆ†ææª”åä¸­çš„é—œéµå­—
    if filename:
        filename_lower = filename.lower()
        for known_name, (code, standard_name) in TAIWAN_COMPANIES_EXTENDED.items():
            if known_name.lower() in filename_lower and len(known_name) >= 2:
                return code, standard_name, "æª”åé—œéµå­—"
    
    return "", "", "æœªè­˜åˆ¥"

def standardize_pdf_filenames_enhanced(data_path: str = None) -> Dict[str, str]:
    """
    å¢å¼·ç‰ˆPDFæª”åæ¨™æº–åŒ–
    """
    if data_path is None:
        data_path = DATA_PATH
    
    data_dir = Path(data_path)
    pdf_files = list(data_dir.glob("*.pdf"))
    
    if not pdf_files:
        print(f"âŒ åœ¨ {data_path} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
        return {}
    
    print(f"ğŸ“ é–‹å§‹æ¨™æº–åŒ– {len(pdf_files)} å€‹PDFæª”å...")
    print("ğŸ“‹ æ”¯æ´å°ç£ä¸Šå¸‚æ«ƒå…¬å¸ä»£è™Ÿè­˜åˆ¥ï¼ˆå¢å¼·ç‰ˆï¼‰")
    print("ğŸ” å¤šç­–ç•¥åŒ¹é…ï¼šPDFå…§å®¹ + æª”ååˆ†æ + é—œéµå­—åŒ¹é…")
    print("=" * 70)
    
    metadata_extractor = DocumentMetadataExtractor()
    rename_mapping = {}
    
    for pdf_file in pdf_files:
        try:
            print(f"ğŸ“„ è™•ç†: {pdf_file.name}")
            
            # æå–å…ƒæ•¸æ“š
            metadata = metadata_extractor.extract_metadata(str(pdf_file))
            extracted_company = metadata['company_name']
            report_year = metadata['report_year']
            
            print(f"   ğŸ¢ PDFæå–å…¬å¸åç¨±: {extracted_company}")
            print(f"   ğŸ“… PDFæå–å¹´åº¦: {report_year}")
            
            # å¾æª”åæå–å…¬å¸åç¨±ä½œç‚ºå‚™é¸
            filename_company = extract_company_from_filename(pdf_file.name)
            print(f"   ğŸ“ æª”ååˆ†æå…¬å¸åç¨±: {filename_company}")
            
            # å¢å¼·ç‰ˆå…¬å¸è­˜åˆ¥
            stock_code, standard_company_name, source = enhanced_find_company_code_and_name(
                extracted_company, pdf_file.name
            )
            
            # æ±ºå®šä½¿ç”¨çš„å…¬å¸åç¨±å’Œå‰ç¶´
            if stock_code and standard_company_name:
                print(f"   âœ… è­˜åˆ¥ç‚º: {stock_code} {standard_company_name} (ä¾†æº: {source})")
                company_for_filename = standard_company_name
                prefix = stock_code
            else:
                print(f"   âš ï¸ æœªè­˜åˆ¥ç‚ºå·²çŸ¥å…¬å¸ï¼Œä½¿ç”¨åŸåç¨±")
                # é¸æ“‡æœ€ä½³çš„å…¬å¸åç¨±
                if filename_company and len(filename_company) > len(extracted_company):
                    company_for_filename = filename_company
                    print(f"   ğŸ“ ä½¿ç”¨æª”åæå–çš„åç¨±: {filename_company}")
                else:
                    safe_company_name = re.sub(r'[^\w\s-]', '', extracted_company)
                    safe_company_name = re.sub(r'\s+', '', safe_company_name)
                    company_for_filename = safe_company_name
                    print(f"   ğŸ“„ ä½¿ç”¨PDFæå–çš„åç¨±: {safe_company_name}")
                prefix = ""
            
            # æå–å¹´åº¦ï¼ˆå„ªå…ˆä½¿ç”¨PDFæå–çš„ï¼Œå…¶æ¬¡å¾æª”åæå–ï¼‰
            final_year = report_year
            if not final_year or final_year == "æœªçŸ¥å¹´åº¦":
                # å¾æª”åæå–å¹´åº¦
                year_match = re.search(r'(202[0-9])', pdf_file.name)
                if year_match:
                    final_year = year_match.group(1)
                    print(f"   ğŸ“… å¾æª”åæå–å¹´åº¦: {final_year}")
            
            # ç”Ÿæˆæ–°æª”å
            if prefix:
                if final_year and final_year != "æœªçŸ¥å¹´åº¦":
                    new_filename = f"{prefix}_{company_for_filename}_{final_year}_esgå ±å‘Šæ›¸.pdf"
                else:
                    new_filename = f"{prefix}_{company_for_filename}_esgå ±å‘Šæ›¸.pdf"
            else:
                if final_year and final_year != "æœªçŸ¥å¹´åº¦":
                    new_filename = f"{company_for_filename}_{final_year}_esgå ±å‘Šæ›¸.pdf"
                else:
                    new_filename = f"{company_for_filename}_esgå ±å‘Šæ›¸.pdf"
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
            if pdf_file.name == new_filename:
                print(f"   âœ“ æª”åå·²æ¨™æº–åŒ–: {new_filename}")
                continue
            
            # æª¢æŸ¥æ–°æª”åæ˜¯å¦å·²å­˜åœ¨
            new_path = data_dir / new_filename
            counter = 1
            original_new_filename = new_filename
            
            while new_path.exists():
                print(f"   âš ï¸ ç›®æ¨™æª”åå·²å­˜åœ¨: {new_filename}")
                name_without_ext = original_new_filename.replace('.pdf', '')
                new_filename = f"{name_without_ext}_{counter}.pdf"
                new_path = data_dir / new_filename
                counter += 1
            
            if counter > 1:
                print(f"   ğŸ“ ä½¿ç”¨æ›¿ä»£æª”å: {new_filename}")
            
            # åŸ·è¡Œé‡å‘½å
            pdf_file.rename(new_path)
            rename_mapping[pdf_file.name] = new_filename
            
            print(f"   âœ… é‡å‘½åæˆåŠŸ:")
            print(f"      {pdf_file.name}")
            print(f"      â†’ {new_filename}")
            
        except Exception as e:
            print(f"   âŒ è™•ç†å¤±æ•—: {e}")
            continue
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    print(f"ğŸ‰ æª”åæ¨™æº–åŒ–å®Œæˆï¼")
    print(f"âœ… æˆåŠŸé‡å‘½å: {len(rename_mapping)} å€‹æª”æ¡ˆ")
    
    if rename_mapping:
        print(f"\nğŸ“‹ é‡å‘½åæ¸…å–®:")
        for old_name, new_name in rename_mapping.items():
            print(f"   â€¢ {old_name}")
            print(f"     â†’ {new_name}")
    
    return rename_mapping

# ç‚ºäº†ä¿æŒå‘å¾Œå…¼å®¹ï¼Œä¿ç•™åŸå‡½æ•¸å
def standardize_pdf_filenames(data_path: str = None) -> Dict[str, str]:
    """å‘å¾Œå…¼å®¹çš„å‡½æ•¸å"""
    return standardize_pdf_filenames_enhanced(data_path)

def main():
    """ä¸»å‡½æ•¸"""
    # æª¢æŸ¥dataç›®éŒ„ä¸­çš„PDFæ–‡ä»¶
    data_dir = Path(DATA_PATH)
    pdf_files = list(data_dir.glob("*.pdf"))
    
    if not pdf_files:
        print(f"éŒ¯èª¤: åœ¨ {DATA_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
        print("è«‹å°‡ESGå ±å‘ŠPDFæ–‡ä»¶æ”¾å…¥dataç›®éŒ„ä¸­")
        return
    
    print(f"æ‰¾åˆ° {len(pdf_files)} å€‹PDFæ–‡ä»¶:")
    for pdf_file in pdf_files:
        print(f"  - {pdf_file.name}")
    
    # åŸ·è¡Œé è™•ç†
    if len(pdf_files) == 1:
        # å–®æ–‡ä»¶æ¨¡å¼
        pdf_path = pdf_files[0]
        print(f"\nå–®æ–‡ä»¶æ¨¡å¼ï¼šè™•ç† {pdf_path.name}")
        
        try:
            metadata_extractor = DocumentMetadataExtractor()
            metadata = metadata_extractor.extract_metadata(str(pdf_path))
            preprocess_documents(str(pdf_path), metadata=metadata)
            print("âœ… é è™•ç†å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ é è™•ç†å¤±æ•—: {e}")
    else:
        # å¤šæ–‡ä»¶æ¨¡å¼
        print(f"\nå¤šæ–‡ä»¶æ¨¡å¼ï¼šè™•ç† {len(pdf_files)} å€‹æ–‡ä»¶")
        confirm = input("ç¢ºå®šè¦æ‰¹é‡è™•ç†æ‰€æœ‰æ–‡ä»¶å—ï¼Ÿ(y/n): ").strip().lower()
        
        if confirm == 'y':
            try:
                results = preprocess_multiple_documents([str(f) for f in pdf_files])
                print(f"âœ… æ‰¹é‡é è™•ç†å®Œæˆï¼")
                
            except Exception as e:
                print(f"âŒ æ‰¹é‡é è™•ç†å¤±æ•—: {e}")

if __name__ == "__main__":
    main()