#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹é€²çš„é è™•ç†æ¨¡çµ„ v2.5
æé«˜å¹´åº¦æå–æº–ç¢ºåº¦ï¼Œå„ªåŒ–å…¬å¸åç¨±è­˜åˆ¥
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from tqdm import tqdm
sys.path.append(str(Path(__file__).parent))
from config import *

class EnhancedDocumentMetadataExtractor:
    """å¢å¼·çš„æ–‡æª”å…ƒæ•¸æ“šæå–å™¨ï¼Œæé«˜å¹´åº¦å’Œå…¬å¸åç¨±è­˜åˆ¥æº–ç¢ºåº¦"""
    
    def __init__(self):
        # å¢å¼·çš„å…¬å¸åç¨±åŒ¹é…æ¨¡å¼ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰
        self.company_patterns = [
            # é«˜å„ªå…ˆç´šï¼šåŒ…å«å®Œæ•´å ±å‘Šæ¨™é¡Œçš„æ¨¡å¼
            r'([^,\n\d]{2,25}?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸\s*(202[0-9])\s*å¹´(?:åº¦)?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([^,\n\d]{2,25}?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸.*?(202[0-9]).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            
            # ä¸­å„ªå…ˆç´šï¼šå…¬å¸åç¨±+å ±å‘Šé¡å‹
            r'([^,\n\d]{2,25}?)(?:è‚¡ä»½)?æœ‰é™å…¬å¸.*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            r'([^,\n\d]{2,25}?)å…¬å¸.*?(?:202[0-9]).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š',
            
            # ä½å„ªå…ˆç´šï¼šåƒ…å…¬å¸åç¨±
            r'([\u4e00-\u9fff]{2,15})(?:è‚¡ä»½)?æœ‰é™å…¬å¸',
            r'([\u4e00-\u9fff]{2,15})å…¬å¸(?:[^\u4e00-\u9fff]|$)',
        ]
        
        # å¢å¼·çš„å¹´åº¦åŒ¹é…æ¨¡å¼ï¼ˆæŒ‰ç²¾ç¢ºåº¦æ’åºï¼‰
        self.year_patterns = [
            # é«˜ç²¾ç¢ºåº¦ï¼šæ˜ç¢ºçš„å ±å‘Šå¹´åº¦è¡¨é”
            r'(202[0-9])\s*å¹´(?:åº¦)?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?',
            r'(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?.*?(202[0-9])\s*å¹´(?:åº¦)?',
            
            # ä¸­ç²¾ç¢ºåº¦ï¼šå ±å‘Šæ¨™é¡Œä¸­çš„å¹´åº¦
            r'(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?.*?(202[0-9])',
            r'(202[0-9]).*?(?:æ°¸çºŒ|ESG|ä¼æ¥­ç¤¾æœƒè²¬ä»»)å ±å‘Š(?:æ›¸)?',
            
            # åŒ…å«"å¹´å ±"çš„æ¨¡å¼
            r'(202[0-9])\s*å¹´(?:åº¦)?å¹´å ±',
            r'å¹´å ±.*?(202[0-9])',
            
            # å…¶ä»–å¯èƒ½çš„å¹´åº¦è¡¨é”
            r'å ±å‘Š(?:æ›¸)?æœŸé–“.*?(202[0-9])',
            r'è²¡æ”¿å¹´åº¦.*?(202[0-9])',
            r'æœƒè¨ˆå¹´åº¦.*?(202[0-9])',
            
            # æœ€ä½å„ªå…ˆç´šï¼šä»»ä½•å››ä½æ•¸å¹´ä»½ï¼ˆ2020-2030ç¯„åœï¼‰
            r'(202[0-9])',
        ]
    
    def extract_metadata(self, pdf_path: str) -> Dict[str, str]:
        """
        å¢å¼·çš„å…ƒæ•¸æ“šæå–ï¼Œæé«˜å¹´åº¦è­˜åˆ¥æº–ç¢ºåº¦
        
        Returns:
            DictåŒ…å« 'company_name' å’Œ 'report_year'
        """
        print(f"ğŸ“‹ æå–æ–‡æª”å…ƒæ•¸æ“š: {Path(pdf_path).name}")
        
        try:
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            
            # æ“´å¤§æª¢æŸ¥ç¯„åœï¼ŒåŒ…å«æ›´å¤šé é¢
            text_for_extraction = ""
            pages_to_check = min(8, len(pages))  # æª¢æŸ¥å‰8é è€Œä¸æ˜¯5é 
            
            for page in pages[:pages_to_check]:
                text_for_extraction += page.page_content + "\n"
            
            # å…ˆå˜—è©¦å¾æ–‡ä»¶åæå–ä½œç‚ºåƒè€ƒ
            filename_metadata = self._extract_from_filename(Path(pdf_path).name)
            
            # å¢å¼·çš„å…¬å¸åç¨±æå–
            company_name = self._extract_company_name_enhanced(text_for_extraction, filename_metadata.get('company_name', ''))
            
            # å¢å¼·çš„å ±å‘Šå¹´åº¦æå–
            report_year = self._extract_report_year_enhanced(text_for_extraction, filename_metadata.get('report_year', ''))
            
            # å¦‚æœä»ç„¡æ³•æå–åˆ°æœ‰æ•ˆä¿¡æ¯ï¼Œä½¿ç”¨æ–‡ä»¶åä½œç‚ºå‚™ç”¨
            if not company_name or company_name == "æœªçŸ¥å…¬å¸":
                company_name = filename_metadata.get('company_name', Path(pdf_path).stem)
            
            if not report_year or report_year == "æœªçŸ¥å¹´åº¦":
                report_year = filename_metadata.get('report_year', 'æœªçŸ¥å¹´åº¦')
            
            result = {
                'company_name': company_name,
                'report_year': report_year
            }
            
            print(f"âœ… æå–åˆ°ï¼š{company_name} - {report_year}")
            return result
            
        except Exception as e:
            print(f"âš ï¸ å…ƒæ•¸æ“šæå–å¤±æ•—: {e}")
            return {
                'company_name': Path(pdf_path).stem,
                'report_year': 'æœªçŸ¥å¹´åº¦'
            }
    
    def _extract_company_name_enhanced(self, text: str, filename_hint: str = "") -> str:
        """å¢å¼·çš„å…¬å¸åç¨±æå–"""
        text_clean = re.sub(r'\s+', ' ', text[:3000])  # æª¢æŸ¥å‰3000å­—ç¬¦
        
        best_match = ""
        best_confidence = 0
        
        for i, pattern in enumerate(self.company_patterns):
            matches = re.findall(pattern, text_clean, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        company_candidate = match[0].strip()
                    else:
                        company_candidate = match.strip()
                    
                    # æ¸…ç†å…¬å¸åç¨±
                    company_candidate = self._clean_company_name(company_candidate)
                    
                    if self._is_valid_company_name(company_candidate):
                        # è¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆæ¨¡å¼è¶Šå‰é¢ä¿¡å¿ƒåº¦è¶Šé«˜ï¼‰
                        confidence = (len(self.company_patterns) - i) / len(self.company_patterns)
                        
                        # å¦‚æœèˆ‡æª”åæç¤ºåŒ¹é…ï¼ŒåŠ åˆ†
                        if filename_hint and filename_hint in company_candidate:
                            confidence += 0.2
                        
                        if confidence > best_confidence:
                            best_match = company_candidate
                            best_confidence = confidence
        
        return best_match if best_match else ""
    
    def _extract_report_year_enhanced(self, text: str, filename_hint: str = "") -> str:
        """å¢å¼·çš„å ±å‘Šå¹´åº¦æå–"""
        text_clean = re.sub(r'\s+', ' ', text[:3000])  # æª¢æŸ¥å‰3000å­—ç¬¦
        
        best_year = ""
        best_confidence = 0
        
        for i, pattern in enumerate(self.year_patterns):
            matches = re.findall(pattern, text_clean, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                for match in matches:
                    year_candidate = match if isinstance(match, str) else match[0]
                    
                    # é©—è­‰å¹´ä»½åˆç†æ€§
                    if self._is_valid_year(year_candidate):
                        # è¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆæ¨¡å¼è¶Šå‰é¢ä¸”è¶Šå…·é«”ä¿¡å¿ƒåº¦è¶Šé«˜ï¼‰
                        confidence = (len(self.year_patterns) - i) / len(self.year_patterns)
                        
                        # ç‰¹åˆ¥åŠ åˆ†ï¼šå¦‚æœæ˜¯æ˜ç¢ºçš„å ±å‘Šæ›¸å¹´åº¦è¡¨é”
                        if i < 4:  # å‰4å€‹æ˜¯é«˜ç²¾ç¢ºåº¦æ¨¡å¼
                            confidence += 0.3
                        
                        # å¦‚æœèˆ‡æª”åæç¤ºåŒ¹é…ï¼ŒåŠ åˆ†
                        if filename_hint and year_candidate == filename_hint:
                            confidence += 0.2
                        
                        # å„ªå…ˆé¸æ“‡è¼ƒæ–°çš„å¹´åº¦ï¼ˆåœ¨åŒç­‰ä¿¡å¿ƒåº¦ä¸‹ï¼‰
                        if confidence > best_confidence or (confidence == best_confidence and int(year_candidate) > int(best_year or "0")):
                            best_year = year_candidate
                            best_confidence = confidence
        
        return best_year if best_year else ""
    
    def _clean_company_name(self, raw_name: str) -> str:
        """æ¸…ç†å…¬å¸åç¨±"""
        if not raw_name:
            return ""
        
        # å»é™¤å‰å¾Œçš„ç©ºç™½ã€æ•¸å­—ã€ç‰¹æ®Šç¬¦è™Ÿ
        cleaned = re.sub(r'^[\s\d\-\.ã€‚ï¼Œ,\(\)ï¼ˆï¼‰ã€ã€‘]+', '', raw_name)
        cleaned = re.sub(r'[\s\-\.ã€‚ï¼Œ,\(\)ï¼ˆï¼‰ã€ã€‘]+$', '', cleaned)
        
        # å»é™¤å¸¸è¦‹çš„ç„¡é—œè©å½™
        noise_words = [
            'å ±å‘Š', 'æ›¸', 'æ°¸çºŒ', 'ESG', 'ä¼æ¥­ç¤¾æœƒè²¬ä»»', 
            'ç¬¬', 'ç« ', 'ç¯€', 'é ', 'é™„éŒ„', 'ç›®éŒ„'
        ]
        for word in noise_words:
            cleaned = re.sub(f'^{word}', '', cleaned)
            cleaned = re.sub(f'{word}$', '', cleaned)
        
        return cleaned.strip()
    
    def _is_valid_company_name(self, name: str) -> bool:
        """é©—è­‰å…¬å¸åç¨±çš„æœ‰æ•ˆæ€§"""
        if not name or len(name) < 2 or len(name) > 25:
            return False
        
        # æ’é™¤æ˜é¡¯ä¸æ˜¯å…¬å¸åç¨±çš„è©å½™
        invalid_patterns = [
            r'^[0-9\.\-\s]+$',  # ç´”æ•¸å­—æˆ–ç¬¦è™Ÿ
            r'^[a-zA-Z\s]+$',   # ç´”è‹±æ–‡ï¼ˆé™¤éæ˜¯çŸ¥åå¤–ä¼ï¼‰
            r'ç¬¬.*?ç« |ç¬¬.*?ç¯€|é .*?ç¢¼',  # ç« ç¯€é ç¢¼
        ]
        
        for pattern in invalid_patterns:
            if re.match(pattern, name):
                return False
        
        return True
    
    def _is_valid_year(self, year: str) -> bool:
        """é©—è­‰å¹´ä»½çš„æœ‰æ•ˆæ€§"""
        try:
            year_int = int(year)
            return 2015 <= year_int <= 2030  # åˆç†çš„ESGå ±å‘Šå¹´åº¦ç¯„åœ
        except ValueError:
            return False
    
    def _extract_from_filename(self, filename: str) -> Dict[str, str]:
        """å¾æ–‡ä»¶åæå–å…ƒæ•¸æ“šä½œç‚ºè¼”åŠ©ä¿¡æ¯"""
        result = {'company_name': '', 'report_year': ''}
        
        # æå–å¹´ä»½ï¼ˆå„ªå…ˆåŒ¹é…202xæ ¼å¼ï¼‰
        year_patterns = [
            r'(202[0-9])',  # 2020-2029
            r'(20[12][0-9])', # 2010-2019å‚™ç”¨
        ]
        
        for pattern in year_patterns:
            year_match = re.search(pattern, filename)
            if year_match:
                result['report_year'] = year_match.group(1)
                break
        
        # æå–å…¬å¸åç¨±ï¼ˆå»é™¤å¹´ä»½ã€ESGã€æ°¸çºŒç­‰è©å½™ï¼‰
        company_part = filename
        
        # å»é™¤å‰¯æª”å
        company_part = re.sub(r'\.pdf$', '', company_part, flags=re.IGNORECASE)
        
        # å»é™¤å¹´ä»½
        company_part = re.sub(r'202[0-9]', '', company_part)
        company_part = re.sub(r'20[12][0-9]', '', company_part)
        
        # å»é™¤å¸¸è¦‹é—œéµè©
        keywords_to_remove = [
            'ESG', 'esg', 'æ°¸çºŒ', 'å ±å‘Š', 'æ›¸', 'ä¼æ¥­ç¤¾æœƒè²¬ä»»', 
            '_', '-', 'æå–', 'çµæœ', 'å¹³è¡¡ç‰ˆ', 'é«˜ç²¾åº¦'
        ]
        for keyword in keywords_to_remove:
            company_part = re.sub(keyword, '', company_part, flags=re.IGNORECASE)
        
        # æ¸…ç†å‰©é¤˜çš„ç¬¦è™Ÿå’Œç©ºç™½
        company_part = re.sub(r'[_\-\s]+', ' ', company_part).strip()
        
        if company_part and len(company_part) >= 2:
            result['company_name'] = company_part
        
        return result

# ç‚ºäº†ä¿æŒå‘å¾Œå…¼å®¹æ€§ï¼Œä¿ç•™åŸæœ‰çš„é¡å
class DocumentMetadataExtractor(EnhancedDocumentMetadataExtractor):
    """å‘å¾Œå…¼å®¹çš„åˆ¥å"""
    pass

def preprocess_documents(pdf_path: str, output_db_path: str = None, metadata: Dict[str, str] = None):
    """é è™•ç†PDFæ–‡æª”ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆå¢å¼·ç‰ˆï¼‰"""
    
    if output_db_path is None:
        output_db_path = VECTOR_DB_PATH
    
    print(f"é–‹å§‹è™•ç†PDF: {pdf_path}")
    
    # 1. è¼‰å…¥PDF
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°PDFæ–‡ä»¶: {pdf_path}")
    
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    print(f"æˆåŠŸè¼‰å…¥ {len(pages)} é ")
    
    # 2. ç‚ºæ¯å€‹æ–‡æª”æ·»åŠ å¢å¼·çš„å…ƒæ•¸æ“š
    if metadata:
        for page in pages:
            page.metadata.update(metadata)
            page.metadata['source_file'] = Path(pdf_path).name
            
            # æ·»åŠ é ç¢¼ä¿¡æ¯ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
            if 'page' not in page.metadata:
                page.metadata['page'] = pages.index(page) + 1
    
    # 3. å¢å¼·çš„æ–‡æœ¬åˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,  # ç¨å¾®å¢åŠ å¡Šå¤§å°ä»¥ä¿æŒæ›´å¤šä¸Šä¸‹æ–‡
        chunk_overlap=180,  # å¢åŠ é‡ç–Šä»¥ç¢ºä¿ä¸éºæ¼é‚Šç•Œå…§å®¹
        separators=["\n\n", "\n", ".", "ã€‚", "ï¼Œ", " ", ""]
    )
    
    print("æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
    chunks = text_splitter.split_documents(pages)
    print(f"åˆ†å‰²æˆ {len(chunks)} å€‹æ–‡æœ¬å¡Š")
    
    # 4. åˆå§‹åŒ–embeddingæ¨¡å‹
    print(f"è¼‰å…¥embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'}
    )
    
    # 5. å»ºç«‹å‘é‡è³‡æ–™åº«
    print("å»ºç«‹å‘é‡è³‡æ–™åº«...")
    db = FAISS.from_documents(chunks, embedding_model)
    
    # 6. ä¿å­˜è³‡æ–™åº«
    os.makedirs(os.path.dirname(output_db_path), exist_ok=True)
    db.save_local(output_db_path)
    print(f"å‘é‡è³‡æ–™åº«å·²ä¿å­˜åˆ°: {output_db_path}")
    
    return db

def preprocess_multiple_documents(pdf_paths: List[str]) -> Dict[str, Dict]:
    """
    æ‰¹é‡é è™•ç†å¤šå€‹PDFæ–‡æª”ï¼ˆå¢å¼·ç‰ˆï¼‰
    
    Returns:
        Dict: {pdf_path: {'db_path': str, 'metadata': dict}}
    """
    print(f"ğŸš€ é–‹å§‹å¢å¼·æ‰¹é‡é è™•ç† {len(pdf_paths)} å€‹PDFæ–‡ä»¶")
    print("=" * 60)
    
    metadata_extractor = EnhancedDocumentMetadataExtractor()
    results = {}
    
    for pdf_path in pdf_paths:
        try:
            print(f"\nğŸ“„ è™•ç†æ–‡ä»¶: {Path(pdf_path).name}")
            
            # 1. å¢å¼·çš„å…ƒæ•¸æ“šæå–
            metadata = metadata_extractor.extract_metadata(pdf_path)
            
            # 2. ç‚ºæ¯å€‹æ–‡ä»¶å‰µå»ºç¨ç«‹çš„å‘é‡è³‡æ–™åº«
            pdf_name = Path(pdf_path).stem
            db_path = os.path.join(
                os.path.dirname(VECTOR_DB_PATH),
                f"esg_db_{pdf_name}"
            )
            
            # 3. å¢å¼·çš„é è™•ç†æ–‡æª”
            preprocess_documents(pdf_path, db_path, metadata)
            
            results[pdf_path] = {
                'db_path': db_path,
                'metadata': metadata,
                'pdf_name': pdf_name
            }
            
            print(f"âœ… å®Œæˆ: {metadata['company_name']} - {metadata['report_year']}")
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•— {Path(pdf_path).name}: {e}")
            continue
    
    print(f"\nğŸ‰ å¢å¼·æ‰¹é‡é è™•ç†å®Œæˆï¼æˆåŠŸè™•ç† {len(results)}/{len(pdf_paths)} å€‹æ–‡ä»¶")
    
    # é¡¯ç¤ºæå–çµæœæ‘˜è¦
    print(f"\nğŸ“‹ æå–æ‘˜è¦:")
    companies_years = {}
    for pdf_path, result in results.items():
        metadata = result['metadata']
        company = metadata['company_name']
        year = metadata['report_year']
        
        if company not in companies_years:
            companies_years[company] = []
        companies_years[company].append(year)
    
    for company, years in companies_years.items():
        years_str = ', '.join(sorted(set(years), reverse=True))
        print(f"   ğŸ¢ {company}: {years_str}")
    
    return results

def test_enhanced_extraction():
    """æ¸¬è©¦å¢å¼·æå–åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦å¢å¼·å¹´åº¦æå–åŠŸèƒ½")
    print("=" * 50)
    
    # æ¸¬è©¦æ¡ˆä¾‹ï¼ˆåŸºæ–¼å¸¸è¦‹çš„ESGå ±å‘Šæ¨™é¡Œæ ¼å¼ï¼‰
    test_cases = [
        {
            "text": "å—äºå¡‘è† å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸2023å¹´æ°¸çºŒå ±å‘Šæ›¸",
            "expected_company": "å—äºå¡‘è† å·¥æ¥­",
            "expected_year": "2023"
        },
        {
            "text": "å°ç£ç©é«”é›»è·¯è£½é€ è‚¡ä»½æœ‰é™å…¬å¸ 2022å¹´ESGå ±å‘Š",
            "expected_company": "å°ç£ç©é«”é›»è·¯è£½é€ ",
            "expected_year": "2022"
        },
        {
            "text": "ä¸­è¯é›»ä¿¡è‚¡ä»½æœ‰é™å…¬å¸ä¼æ¥­ç¤¾æœƒè²¬ä»»å ±å‘Šæ›¸ 2024å¹´åº¦",
            "expected_company": "ä¸­è¯é›»ä¿¡",
            "expected_year": "2024"
        },
        {
            "text": "æ°¸çºŒå ±å‘Šæ›¸2021 å¤§ç«‹å…‰é›»è‚¡ä»½æœ‰é™å…¬å¸",
            "expected_company": "å¤§ç«‹å…‰é›»",
            "expected_year": "2021"
        }
    ]
    
    extractor = EnhancedDocumentMetadataExtractor()
    
    print("æ¸¬è©¦çµæœ:")
    for i, case in enumerate(test_cases, 1):
        print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i}:")
        print(f"æ–‡æœ¬: {case['text']}")
        
        company = extractor._extract_company_name_enhanced(case['text'])
        year = extractor._extract_report_year_enhanced(case['text'])
        
        print(f"æå–åˆ°å…¬å¸: {company} (é æœŸ: {case['expected_company']})")
        print(f"æå–åˆ°å¹´åº¦: {year} (é æœŸ: {case['expected_year']})")
        
        company_match = case['expected_company'] in company if company else False
        year_match = year == case['expected_year']
        
        status = "âœ…" if company_match and year_match else "âš ï¸"
        print(f"çµæœ: {status}")

def main():
    """ä¸»å‡½æ•¸"""
    # æª¢æŸ¥dataç›®éŒ„ä¸­çš„PDFæ–‡ä»¶
    data_dir = Path(DATA_PATH)
    pdf_files = list(data_dir.glob("*.pdf"))
    
    if not pdf_files:
        print(f"éŒ¯èª¤: åœ¨ {DATA_PATH} ç›®éŒ„ä¸­æ‰¾ä¸åˆ°PDFæ–‡ä»¶")
        print("è«‹å°‡ESGå ±å‘ŠPDFæ–‡ä»¶æ”¾å…¥dataç›®éŒ„ä¸­")
        return
    
    print(f"æ‰¾åˆ° {len(pdf_files)} å€‹PDFæ–‡ä»¶:")
    for pdf_file in pdf_files:
        print(f"  - {pdf_file.name}")
    
    # æä¾›é¸é …
    print("\né¸é …:")
    print("1. åŸ·è¡Œå¢å¼·é è™•ç†")
    print("2. æ¸¬è©¦å¹´åº¦æå–åŠŸèƒ½")
    
    choice = input("è«‹é¸æ“‡ (1-2): ").strip()
    
    if choice == "1":
        # åŸ·è¡Œå¢å¼·é è™•ç†
        if len(pdf_files) == 1:
            # å–®æ–‡ä»¶æ¨¡å¼
            pdf_path = pdf_files[0]
            print(f"\nå–®æ–‡ä»¶å¢å¼·æ¨¡å¼ï¼šè™•ç† {pdf_path.name}")
            
            try:
                metadata_extractor = EnhancedDocumentMetadataExtractor()
                metadata = metadata_extractor.extract_metadata(str(pdf_path))
                preprocess_documents(str(pdf_path), metadata=metadata)
                print("âœ… å¢å¼·é è™•ç†å®Œæˆï¼")
            except Exception as e:
                print(f"âŒ å¢å¼·é è™•ç†å¤±æ•—: {e}")
        else:
            # å¤šæ–‡ä»¶æ¨¡å¼
            print(f"\nå¤šæ–‡ä»¶å¢å¼·æ¨¡å¼ï¼šè™•ç† {len(pdf_files)} å€‹æ–‡ä»¶")
            confirm = input("ç¢ºå®šè¦æ‰¹é‡å¢å¼·è™•ç†æ‰€æœ‰æ–‡ä»¶å—ï¼Ÿ(y/n): ").strip().lower()
            
            if confirm == 'y':
                try:
                    results = preprocess_multiple_documents([str(f) for f in pdf_files])
                    print(f"âœ… å¢å¼·æ‰¹é‡é è™•ç†å®Œæˆï¼")
                    
                except Exception as e:
                    print(f"âŒ å¢å¼·æ‰¹é‡é è™•ç†å¤±æ•—: {e}")
    
    elif choice == "2":
        # æ¸¬è©¦å¹´åº¦æå–åŠŸèƒ½
        test_enhanced_extraction()
    
    else:
        print("âŒ ç„¡æ•ˆé¸æ“‡")

if __name__ == "__main__":
    main()